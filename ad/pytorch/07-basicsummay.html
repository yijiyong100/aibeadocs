<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Pytorch-基础精华总结 | 智能后端和架构</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="智能后端和架构的文档">
    <meta name="icon" content="">
    <meta name="author" content="landry -- seo 选项">
    <meta name="keywords" content="后端 java 架构 面试 -- seo 选项">
    
    <link rel="preload" href="/assets/css/0.styles.183d1d00.css" as="style"><link rel="preload" href="/assets/js/app.db30138a.js" as="script"><link rel="preload" href="/assets/js/5.df8bf371.js" as="script"><link rel="preload" href="/assets/js/1.60d99fe1.js" as="script"><link rel="preload" href="/assets/js/78.f56b2037.js" as="script"><link rel="prefetch" href="/assets/js/10.034bcceb.js"><link rel="prefetch" href="/assets/js/100.bc78c9c9.js"><link rel="prefetch" href="/assets/js/101.fc021eba.js"><link rel="prefetch" href="/assets/js/102.44f58839.js"><link rel="prefetch" href="/assets/js/103.cd3ce876.js"><link rel="prefetch" href="/assets/js/104.ece12d4f.js"><link rel="prefetch" href="/assets/js/105.e0ef0178.js"><link rel="prefetch" href="/assets/js/106.f8113fb8.js"><link rel="prefetch" href="/assets/js/107.7af90320.js"><link rel="prefetch" href="/assets/js/108.a76af7ab.js"><link rel="prefetch" href="/assets/js/109.ae7dfcbe.js"><link rel="prefetch" href="/assets/js/11.22d5654f.js"><link rel="prefetch" href="/assets/js/110.829dbd72.js"><link rel="prefetch" href="/assets/js/111.2612d028.js"><link rel="prefetch" href="/assets/js/112.381ba79f.js"><link rel="prefetch" href="/assets/js/113.52309728.js"><link rel="prefetch" href="/assets/js/114.afd46270.js"><link rel="prefetch" href="/assets/js/115.cfff1785.js"><link rel="prefetch" href="/assets/js/116.b9e85eed.js"><link rel="prefetch" href="/assets/js/117.c88c3ceb.js"><link rel="prefetch" href="/assets/js/118.0cfd8d46.js"><link rel="prefetch" href="/assets/js/119.972e6fcd.js"><link rel="prefetch" href="/assets/js/12.a1fbf449.js"><link rel="prefetch" href="/assets/js/120.c4d0fa30.js"><link rel="prefetch" href="/assets/js/121.a05fb7c8.js"><link rel="prefetch" href="/assets/js/122.84bc99e8.js"><link rel="prefetch" href="/assets/js/123.6e40db8b.js"><link rel="prefetch" href="/assets/js/124.679f60f0.js"><link rel="prefetch" href="/assets/js/125.7b983b12.js"><link rel="prefetch" href="/assets/js/126.c6529e34.js"><link rel="prefetch" href="/assets/js/127.62896466.js"><link rel="prefetch" href="/assets/js/128.11cadf09.js"><link rel="prefetch" href="/assets/js/129.a2c6007b.js"><link rel="prefetch" href="/assets/js/13.773a30c0.js"><link rel="prefetch" href="/assets/js/130.cd51d586.js"><link rel="prefetch" href="/assets/js/131.5d81a3a4.js"><link rel="prefetch" href="/assets/js/132.c062c43a.js"><link rel="prefetch" href="/assets/js/133.94b50107.js"><link rel="prefetch" href="/assets/js/134.e787c6f2.js"><link rel="prefetch" href="/assets/js/135.514b39b8.js"><link rel="prefetch" href="/assets/js/136.2209902a.js"><link rel="prefetch" href="/assets/js/137.8ee62050.js"><link rel="prefetch" href="/assets/js/138.30076406.js"><link rel="prefetch" href="/assets/js/139.153f79f0.js"><link rel="prefetch" href="/assets/js/14.a010702c.js"><link rel="prefetch" href="/assets/js/140.c22ae524.js"><link rel="prefetch" href="/assets/js/141.03388ce3.js"><link rel="prefetch" href="/assets/js/142.be052d72.js"><link rel="prefetch" href="/assets/js/143.86f4f723.js"><link rel="prefetch" href="/assets/js/144.58a81178.js"><link rel="prefetch" href="/assets/js/145.b6065cbb.js"><link rel="prefetch" href="/assets/js/146.a7d48393.js"><link rel="prefetch" href="/assets/js/147.1f5a2c27.js"><link rel="prefetch" href="/assets/js/148.e545c932.js"><link rel="prefetch" href="/assets/js/149.b7f633ea.js"><link rel="prefetch" href="/assets/js/15.6612b8a7.js"><link rel="prefetch" href="/assets/js/150.0c633255.js"><link rel="prefetch" href="/assets/js/151.7518fca9.js"><link rel="prefetch" href="/assets/js/152.85ebf0bb.js"><link rel="prefetch" href="/assets/js/153.6696affd.js"><link rel="prefetch" href="/assets/js/154.a488a746.js"><link rel="prefetch" href="/assets/js/155.b1285b65.js"><link rel="prefetch" href="/assets/js/156.c7d65add.js"><link rel="prefetch" href="/assets/js/157.95b667f4.js"><link rel="prefetch" href="/assets/js/158.36dcae64.js"><link rel="prefetch" href="/assets/js/159.5ab4607b.js"><link rel="prefetch" href="/assets/js/16.9728f201.js"><link rel="prefetch" href="/assets/js/160.f31c31c5.js"><link rel="prefetch" href="/assets/js/161.7faa6f5b.js"><link rel="prefetch" href="/assets/js/162.8bed1a3e.js"><link rel="prefetch" href="/assets/js/163.bccb4b94.js"><link rel="prefetch" href="/assets/js/164.d019f9f6.js"><link rel="prefetch" href="/assets/js/165.4ea2fcec.js"><link rel="prefetch" href="/assets/js/166.937ae33a.js"><link rel="prefetch" href="/assets/js/167.63bf2a10.js"><link rel="prefetch" href="/assets/js/168.8501b450.js"><link rel="prefetch" href="/assets/js/169.52064ac2.js"><link rel="prefetch" href="/assets/js/17.01684033.js"><link rel="prefetch" href="/assets/js/170.bc536396.js"><link rel="prefetch" href="/assets/js/171.5c44671a.js"><link rel="prefetch" href="/assets/js/172.cbc9f01e.js"><link rel="prefetch" href="/assets/js/173.036cc49c.js"><link rel="prefetch" href="/assets/js/174.7900267f.js"><link rel="prefetch" href="/assets/js/175.7f350261.js"><link rel="prefetch" href="/assets/js/176.abfbdc57.js"><link rel="prefetch" href="/assets/js/177.679877f2.js"><link rel="prefetch" href="/assets/js/178.87fc5aba.js"><link rel="prefetch" href="/assets/js/179.26c9f0a4.js"><link rel="prefetch" href="/assets/js/18.e64f0610.js"><link rel="prefetch" href="/assets/js/180.bd2cdacc.js"><link rel="prefetch" href="/assets/js/181.3ad737a4.js"><link rel="prefetch" href="/assets/js/182.3e7faf1a.js"><link rel="prefetch" href="/assets/js/183.4d65d295.js"><link rel="prefetch" href="/assets/js/184.460482ae.js"><link rel="prefetch" href="/assets/js/185.46d4a7fe.js"><link rel="prefetch" href="/assets/js/186.61235089.js"><link rel="prefetch" href="/assets/js/187.397bcfe8.js"><link rel="prefetch" href="/assets/js/188.060a1cb7.js"><link rel="prefetch" href="/assets/js/189.e3995463.js"><link rel="prefetch" href="/assets/js/19.f8b70585.js"><link rel="prefetch" href="/assets/js/190.dcaa16c4.js"><link rel="prefetch" href="/assets/js/191.f4c5aa96.js"><link rel="prefetch" href="/assets/js/192.8b10742f.js"><link rel="prefetch" href="/assets/js/193.64a40b9c.js"><link rel="prefetch" href="/assets/js/194.2ea34c9f.js"><link rel="prefetch" href="/assets/js/195.6bb470df.js"><link rel="prefetch" href="/assets/js/196.a0f55724.js"><link rel="prefetch" href="/assets/js/197.493d62fe.js"><link rel="prefetch" href="/assets/js/198.285ec3f4.js"><link rel="prefetch" href="/assets/js/199.c26664a8.js"><link rel="prefetch" href="/assets/js/20.c407011e.js"><link rel="prefetch" href="/assets/js/200.e172c025.js"><link rel="prefetch" href="/assets/js/201.88cbb622.js"><link rel="prefetch" href="/assets/js/202.da403177.js"><link rel="prefetch" href="/assets/js/203.6eb14b41.js"><link rel="prefetch" href="/assets/js/204.2ddae4bf.js"><link rel="prefetch" href="/assets/js/205.0a89efc1.js"><link rel="prefetch" href="/assets/js/206.480a66d3.js"><link rel="prefetch" href="/assets/js/207.bf5c1d60.js"><link rel="prefetch" href="/assets/js/208.b187dc67.js"><link rel="prefetch" href="/assets/js/209.20c99616.js"><link rel="prefetch" href="/assets/js/21.7edc8b1b.js"><link rel="prefetch" href="/assets/js/210.e4f1f766.js"><link rel="prefetch" href="/assets/js/211.1ed7b354.js"><link rel="prefetch" href="/assets/js/212.7e1243ab.js"><link rel="prefetch" href="/assets/js/213.6daddd4b.js"><link rel="prefetch" href="/assets/js/214.e548b00f.js"><link rel="prefetch" href="/assets/js/215.5e7f305a.js"><link rel="prefetch" href="/assets/js/216.d02d9a10.js"><link rel="prefetch" href="/assets/js/217.4ee282a4.js"><link rel="prefetch" href="/assets/js/218.d95d737e.js"><link rel="prefetch" href="/assets/js/219.fab5907a.js"><link rel="prefetch" href="/assets/js/22.fdbd00d3.js"><link rel="prefetch" href="/assets/js/220.56c6f7cc.js"><link rel="prefetch" href="/assets/js/221.3ee9e8ae.js"><link rel="prefetch" href="/assets/js/222.30c2d9ac.js"><link rel="prefetch" href="/assets/js/223.d6f5a1ce.js"><link rel="prefetch" href="/assets/js/224.b964e9b3.js"><link rel="prefetch" href="/assets/js/225.4f7cdb7b.js"><link rel="prefetch" href="/assets/js/226.34f5bc46.js"><link rel="prefetch" href="/assets/js/227.0c1d6c32.js"><link rel="prefetch" href="/assets/js/228.5c4850fa.js"><link rel="prefetch" href="/assets/js/229.0e83acaa.js"><link rel="prefetch" href="/assets/js/23.714595d5.js"><link rel="prefetch" href="/assets/js/230.d56ff6f6.js"><link rel="prefetch" href="/assets/js/231.19e033e0.js"><link rel="prefetch" href="/assets/js/232.b020bd32.js"><link rel="prefetch" href="/assets/js/233.19037210.js"><link rel="prefetch" href="/assets/js/234.10d14014.js"><link rel="prefetch" href="/assets/js/235.91bc5ad5.js"><link rel="prefetch" href="/assets/js/236.e9193180.js"><link rel="prefetch" href="/assets/js/237.e9be28a3.js"><link rel="prefetch" href="/assets/js/238.d1ac2fd8.js"><link rel="prefetch" href="/assets/js/239.44f2f146.js"><link rel="prefetch" href="/assets/js/24.2611c0d6.js"><link rel="prefetch" href="/assets/js/240.c8fe20cb.js"><link rel="prefetch" href="/assets/js/241.b232c3db.js"><link rel="prefetch" href="/assets/js/242.5bacdca9.js"><link rel="prefetch" href="/assets/js/243.bc85e605.js"><link rel="prefetch" href="/assets/js/244.975158d1.js"><link rel="prefetch" href="/assets/js/245.a139b48a.js"><link rel="prefetch" href="/assets/js/246.3138e906.js"><link rel="prefetch" href="/assets/js/247.070da83a.js"><link rel="prefetch" href="/assets/js/248.a1d8ac56.js"><link rel="prefetch" href="/assets/js/249.aadb0dca.js"><link rel="prefetch" href="/assets/js/25.2272f92f.js"><link rel="prefetch" href="/assets/js/250.c9cbf057.js"><link rel="prefetch" href="/assets/js/251.e8ddac0a.js"><link rel="prefetch" href="/assets/js/252.47894d0d.js"><link rel="prefetch" href="/assets/js/253.38f4c081.js"><link rel="prefetch" href="/assets/js/254.73808710.js"><link rel="prefetch" href="/assets/js/255.19234ae1.js"><link rel="prefetch" href="/assets/js/256.dbd6b6af.js"><link rel="prefetch" href="/assets/js/257.c16eae54.js"><link rel="prefetch" href="/assets/js/258.89a54cc9.js"><link rel="prefetch" href="/assets/js/259.ff8893b9.js"><link rel="prefetch" href="/assets/js/26.4d1df400.js"><link rel="prefetch" href="/assets/js/260.da83ef3e.js"><link rel="prefetch" href="/assets/js/261.39869cb6.js"><link rel="prefetch" href="/assets/js/262.6df31a71.js"><link rel="prefetch" href="/assets/js/263.a98eab49.js"><link rel="prefetch" href="/assets/js/264.1204725e.js"><link rel="prefetch" href="/assets/js/265.b6ce2d26.js"><link rel="prefetch" href="/assets/js/266.0c03e783.js"><link rel="prefetch" href="/assets/js/267.d686ec0e.js"><link rel="prefetch" href="/assets/js/268.e7c76c63.js"><link rel="prefetch" href="/assets/js/269.9ec0a34d.js"><link rel="prefetch" href="/assets/js/27.a88ca8bc.js"><link rel="prefetch" href="/assets/js/270.99f54d10.js"><link rel="prefetch" href="/assets/js/271.b9e143e2.js"><link rel="prefetch" href="/assets/js/272.1c93e968.js"><link rel="prefetch" href="/assets/js/273.7235d019.js"><link rel="prefetch" href="/assets/js/274.fbed798d.js"><link rel="prefetch" href="/assets/js/275.0006136b.js"><link rel="prefetch" href="/assets/js/276.8fc094f0.js"><link rel="prefetch" href="/assets/js/277.20e11e67.js"><link rel="prefetch" href="/assets/js/278.f8dc8f8f.js"><link rel="prefetch" href="/assets/js/279.651a9f88.js"><link rel="prefetch" href="/assets/js/28.69be6cc7.js"><link rel="prefetch" href="/assets/js/280.94aed3df.js"><link rel="prefetch" href="/assets/js/281.b9e4a0c1.js"><link rel="prefetch" href="/assets/js/282.fcbf917d.js"><link rel="prefetch" href="/assets/js/283.4b9335f2.js"><link rel="prefetch" href="/assets/js/284.a2748605.js"><link rel="prefetch" href="/assets/js/285.75119aca.js"><link rel="prefetch" href="/assets/js/286.a4a0abc2.js"><link rel="prefetch" href="/assets/js/287.0e10db49.js"><link rel="prefetch" href="/assets/js/288.540945f8.js"><link rel="prefetch" href="/assets/js/289.65991a71.js"><link rel="prefetch" href="/assets/js/29.3d144449.js"><link rel="prefetch" href="/assets/js/290.3cda3c0a.js"><link rel="prefetch" href="/assets/js/291.a7c9d6a2.js"><link rel="prefetch" href="/assets/js/292.2ce3fd5f.js"><link rel="prefetch" href="/assets/js/293.6572edb6.js"><link rel="prefetch" href="/assets/js/294.2a04291f.js"><link rel="prefetch" href="/assets/js/295.9a0fdf51.js"><link rel="prefetch" href="/assets/js/296.76bf15e5.js"><link rel="prefetch" href="/assets/js/297.ca22f9e0.js"><link rel="prefetch" href="/assets/js/298.dfd560c6.js"><link rel="prefetch" href="/assets/js/299.ea6a076f.js"><link rel="prefetch" href="/assets/js/3.19255846.js"><link rel="prefetch" href="/assets/js/30.c9924233.js"><link rel="prefetch" href="/assets/js/300.08ab4a0a.js"><link rel="prefetch" href="/assets/js/301.493634b6.js"><link rel="prefetch" href="/assets/js/302.088b770b.js"><link rel="prefetch" href="/assets/js/303.fdda8763.js"><link rel="prefetch" href="/assets/js/304.6e6a4a01.js"><link rel="prefetch" href="/assets/js/305.a3a1ae34.js"><link rel="prefetch" href="/assets/js/306.5835726c.js"><link rel="prefetch" href="/assets/js/307.0fce17cb.js"><link rel="prefetch" href="/assets/js/308.1e172ca3.js"><link rel="prefetch" href="/assets/js/309.80af26f3.js"><link rel="prefetch" href="/assets/js/31.f9f57568.js"><link rel="prefetch" href="/assets/js/310.b5f3ed6f.js"><link rel="prefetch" href="/assets/js/311.82c7e552.js"><link rel="prefetch" href="/assets/js/312.a48280c0.js"><link rel="prefetch" href="/assets/js/313.7c31693f.js"><link rel="prefetch" href="/assets/js/314.307f9eda.js"><link rel="prefetch" href="/assets/js/315.9f1e1099.js"><link rel="prefetch" href="/assets/js/316.7d255d6d.js"><link rel="prefetch" href="/assets/js/317.ef013a1a.js"><link rel="prefetch" href="/assets/js/318.64d24469.js"><link rel="prefetch" href="/assets/js/319.59c19af0.js"><link rel="prefetch" href="/assets/js/32.b29dc01b.js"><link rel="prefetch" href="/assets/js/320.add9fa10.js"><link rel="prefetch" href="/assets/js/321.22b199c2.js"><link rel="prefetch" href="/assets/js/322.ad9a2dff.js"><link rel="prefetch" href="/assets/js/323.b4183fc2.js"><link rel="prefetch" href="/assets/js/324.cf1aca23.js"><link rel="prefetch" href="/assets/js/325.83a4f1cf.js"><link rel="prefetch" href="/assets/js/326.f5c26436.js"><link rel="prefetch" href="/assets/js/327.16102be7.js"><link rel="prefetch" href="/assets/js/328.da84fbb0.js"><link rel="prefetch" href="/assets/js/329.4bdbc8ed.js"><link rel="prefetch" href="/assets/js/33.961516b8.js"><link rel="prefetch" href="/assets/js/330.0a98e84a.js"><link rel="prefetch" href="/assets/js/331.36e66e80.js"><link rel="prefetch" href="/assets/js/332.1b010d76.js"><link rel="prefetch" href="/assets/js/333.bf2def9d.js"><link rel="prefetch" href="/assets/js/334.373631c9.js"><link rel="prefetch" href="/assets/js/335.68121e51.js"><link rel="prefetch" href="/assets/js/336.49a94ea2.js"><link rel="prefetch" href="/assets/js/337.661abdcc.js"><link rel="prefetch" href="/assets/js/338.389c4be2.js"><link rel="prefetch" href="/assets/js/339.098329ed.js"><link rel="prefetch" href="/assets/js/34.7cb1f223.js"><link rel="prefetch" href="/assets/js/340.5c400f4d.js"><link rel="prefetch" href="/assets/js/341.41d84f2d.js"><link rel="prefetch" href="/assets/js/342.ef356713.js"><link rel="prefetch" href="/assets/js/343.d1e1952a.js"><link rel="prefetch" href="/assets/js/344.1980f7cc.js"><link rel="prefetch" href="/assets/js/345.0f7d9b9f.js"><link rel="prefetch" href="/assets/js/346.c3878425.js"><link rel="prefetch" href="/assets/js/347.dd74c55a.js"><link rel="prefetch" href="/assets/js/348.89584af8.js"><link rel="prefetch" href="/assets/js/349.c7bc7bc1.js"><link rel="prefetch" href="/assets/js/35.51ade70c.js"><link rel="prefetch" href="/assets/js/350.d2df1d20.js"><link rel="prefetch" href="/assets/js/351.a1b78a34.js"><link rel="prefetch" href="/assets/js/352.08ae09fd.js"><link rel="prefetch" href="/assets/js/353.aced76b3.js"><link rel="prefetch" href="/assets/js/354.f033ee07.js"><link rel="prefetch" href="/assets/js/355.95831785.js"><link rel="prefetch" href="/assets/js/356.893584e1.js"><link rel="prefetch" href="/assets/js/357.5f070ca5.js"><link rel="prefetch" href="/assets/js/358.35f2ade5.js"><link rel="prefetch" href="/assets/js/359.e45099bd.js"><link rel="prefetch" href="/assets/js/36.82c64b8f.js"><link rel="prefetch" href="/assets/js/360.59aa32f9.js"><link rel="prefetch" href="/assets/js/361.bd3c2fdd.js"><link rel="prefetch" href="/assets/js/362.3566e79d.js"><link rel="prefetch" href="/assets/js/363.b4ab82f7.js"><link rel="prefetch" href="/assets/js/364.7f50d299.js"><link rel="prefetch" href="/assets/js/365.4f8e93f6.js"><link rel="prefetch" href="/assets/js/366.8fd91814.js"><link rel="prefetch" href="/assets/js/367.0d47f5a8.js"><link rel="prefetch" href="/assets/js/368.fb7814d2.js"><link rel="prefetch" href="/assets/js/369.d6d8c504.js"><link rel="prefetch" href="/assets/js/37.5165b622.js"><link rel="prefetch" href="/assets/js/370.00a807a6.js"><link rel="prefetch" href="/assets/js/371.867a9db3.js"><link rel="prefetch" href="/assets/js/372.decca4ce.js"><link rel="prefetch" href="/assets/js/373.98b37511.js"><link rel="prefetch" href="/assets/js/374.6313e71a.js"><link rel="prefetch" href="/assets/js/375.f2e2fa05.js"><link rel="prefetch" href="/assets/js/376.7103c034.js"><link rel="prefetch" href="/assets/js/377.9bf388c9.js"><link rel="prefetch" href="/assets/js/378.57ae31cf.js"><link rel="prefetch" href="/assets/js/379.739ee8d7.js"><link rel="prefetch" href="/assets/js/38.563ce632.js"><link rel="prefetch" href="/assets/js/380.6256f3c8.js"><link rel="prefetch" href="/assets/js/381.38f7eb5a.js"><link rel="prefetch" href="/assets/js/382.ae035904.js"><link rel="prefetch" href="/assets/js/383.2d1b99c3.js"><link rel="prefetch" href="/assets/js/384.094517c8.js"><link rel="prefetch" href="/assets/js/385.62ddf499.js"><link rel="prefetch" href="/assets/js/386.8315cf9d.js"><link rel="prefetch" href="/assets/js/387.2bef00d3.js"><link rel="prefetch" href="/assets/js/388.178f867f.js"><link rel="prefetch" href="/assets/js/389.d893ba15.js"><link rel="prefetch" href="/assets/js/39.29556252.js"><link rel="prefetch" href="/assets/js/390.1b85f452.js"><link rel="prefetch" href="/assets/js/391.12fe014e.js"><link rel="prefetch" href="/assets/js/392.8c88755d.js"><link rel="prefetch" href="/assets/js/393.72aa7675.js"><link rel="prefetch" href="/assets/js/394.df13d1f7.js"><link rel="prefetch" href="/assets/js/395.8f8d96d9.js"><link rel="prefetch" href="/assets/js/396.aa362f3c.js"><link rel="prefetch" href="/assets/js/397.cca49694.js"><link rel="prefetch" href="/assets/js/398.d9fd0617.js"><link rel="prefetch" href="/assets/js/399.96f3fede.js"><link rel="prefetch" href="/assets/js/4.623783fc.js"><link rel="prefetch" href="/assets/js/40.0330d609.js"><link rel="prefetch" href="/assets/js/400.a1472f96.js"><link rel="prefetch" href="/assets/js/401.3d4e1a6b.js"><link rel="prefetch" href="/assets/js/402.0a8a7162.js"><link rel="prefetch" href="/assets/js/403.b1393b0f.js"><link rel="prefetch" href="/assets/js/404.7e485063.js"><link rel="prefetch" href="/assets/js/405.1037d751.js"><link rel="prefetch" href="/assets/js/406.ae7d83bb.js"><link rel="prefetch" href="/assets/js/407.cb9ade38.js"><link rel="prefetch" href="/assets/js/408.a105752d.js"><link rel="prefetch" href="/assets/js/409.a56202e0.js"><link rel="prefetch" href="/assets/js/41.dcb7a3f5.js"><link rel="prefetch" href="/assets/js/410.f615dd75.js"><link rel="prefetch" href="/assets/js/411.29882ac4.js"><link rel="prefetch" href="/assets/js/412.ed8e6abb.js"><link rel="prefetch" href="/assets/js/413.2a212c18.js"><link rel="prefetch" href="/assets/js/414.9717c94d.js"><link rel="prefetch" href="/assets/js/415.ad521b94.js"><link rel="prefetch" href="/assets/js/416.981646b8.js"><link rel="prefetch" href="/assets/js/417.3bcf1a86.js"><link rel="prefetch" href="/assets/js/418.d6d8bc33.js"><link rel="prefetch" href="/assets/js/419.79a736e3.js"><link rel="prefetch" href="/assets/js/42.61434728.js"><link rel="prefetch" href="/assets/js/420.bd2fe57b.js"><link rel="prefetch" href="/assets/js/421.040b2b27.js"><link rel="prefetch" href="/assets/js/422.5cc63c45.js"><link rel="prefetch" href="/assets/js/423.9d447e90.js"><link rel="prefetch" href="/assets/js/424.51734eb2.js"><link rel="prefetch" href="/assets/js/425.f6a00d75.js"><link rel="prefetch" href="/assets/js/426.896f7a5b.js"><link rel="prefetch" href="/assets/js/427.e099dd6a.js"><link rel="prefetch" href="/assets/js/428.beef8eb2.js"><link rel="prefetch" href="/assets/js/429.266ed61e.js"><link rel="prefetch" href="/assets/js/43.667a4108.js"><link rel="prefetch" href="/assets/js/430.cd857ec2.js"><link rel="prefetch" href="/assets/js/431.cb5550b2.js"><link rel="prefetch" href="/assets/js/432.3a31614c.js"><link rel="prefetch" href="/assets/js/433.c9f73ea8.js"><link rel="prefetch" href="/assets/js/434.c3d546a3.js"><link rel="prefetch" href="/assets/js/435.6a5558d5.js"><link rel="prefetch" href="/assets/js/436.fac0cdde.js"><link rel="prefetch" href="/assets/js/437.858e2dbc.js"><link rel="prefetch" href="/assets/js/438.4f6fd7f1.js"><link rel="prefetch" href="/assets/js/439.d823d6d5.js"><link rel="prefetch" href="/assets/js/44.2e051a69.js"><link rel="prefetch" href="/assets/js/440.8d4edefe.js"><link rel="prefetch" href="/assets/js/441.806f144c.js"><link rel="prefetch" href="/assets/js/442.56b1ae7b.js"><link rel="prefetch" href="/assets/js/443.0c9c92ed.js"><link rel="prefetch" href="/assets/js/444.4484d097.js"><link rel="prefetch" href="/assets/js/445.6e68718d.js"><link rel="prefetch" href="/assets/js/446.5bdd4ab4.js"><link rel="prefetch" href="/assets/js/447.6202d37b.js"><link rel="prefetch" href="/assets/js/448.88ae6dd3.js"><link rel="prefetch" href="/assets/js/449.2e911cca.js"><link rel="prefetch" href="/assets/js/45.08ce102a.js"><link rel="prefetch" href="/assets/js/450.16bda76e.js"><link rel="prefetch" href="/assets/js/451.ee603a5b.js"><link rel="prefetch" href="/assets/js/452.ff4a503b.js"><link rel="prefetch" href="/assets/js/453.f4bf543d.js"><link rel="prefetch" href="/assets/js/454.fb1e37fa.js"><link rel="prefetch" href="/assets/js/455.55467fe9.js"><link rel="prefetch" href="/assets/js/456.c1ccc8ef.js"><link rel="prefetch" href="/assets/js/457.aaeaefa6.js"><link rel="prefetch" href="/assets/js/458.f59b0607.js"><link rel="prefetch" href="/assets/js/459.201f603d.js"><link rel="prefetch" href="/assets/js/46.074adfe9.js"><link rel="prefetch" href="/assets/js/460.4e283c1a.js"><link rel="prefetch" href="/assets/js/461.c2492681.js"><link rel="prefetch" href="/assets/js/462.9362354d.js"><link rel="prefetch" href="/assets/js/463.a4087f38.js"><link rel="prefetch" href="/assets/js/464.e5828e7e.js"><link rel="prefetch" href="/assets/js/465.e95594b5.js"><link rel="prefetch" href="/assets/js/466.7b75c1f4.js"><link rel="prefetch" href="/assets/js/467.8e9d9c24.js"><link rel="prefetch" href="/assets/js/468.b87a6973.js"><link rel="prefetch" href="/assets/js/469.3411b392.js"><link rel="prefetch" href="/assets/js/47.8175158f.js"><link rel="prefetch" href="/assets/js/470.95363b28.js"><link rel="prefetch" href="/assets/js/471.21a1606b.js"><link rel="prefetch" href="/assets/js/472.f9687e9c.js"><link rel="prefetch" href="/assets/js/473.64f85306.js"><link rel="prefetch" href="/assets/js/474.8a9f362d.js"><link rel="prefetch" href="/assets/js/475.5d6399de.js"><link rel="prefetch" href="/assets/js/476.70d49b7b.js"><link rel="prefetch" href="/assets/js/477.7e3e21a3.js"><link rel="prefetch" href="/assets/js/478.67387462.js"><link rel="prefetch" href="/assets/js/479.a239eaa0.js"><link rel="prefetch" href="/assets/js/48.f20bc2b0.js"><link rel="prefetch" href="/assets/js/480.6f0b953b.js"><link rel="prefetch" href="/assets/js/481.b3ec6e3e.js"><link rel="prefetch" href="/assets/js/482.ef931c32.js"><link rel="prefetch" href="/assets/js/483.e2271a83.js"><link rel="prefetch" href="/assets/js/484.544c1072.js"><link rel="prefetch" href="/assets/js/485.d8a5505a.js"><link rel="prefetch" href="/assets/js/486.1ea2510a.js"><link rel="prefetch" href="/assets/js/487.e954f3bc.js"><link rel="prefetch" href="/assets/js/488.dbfe8c7c.js"><link rel="prefetch" href="/assets/js/489.92152c72.js"><link rel="prefetch" href="/assets/js/49.f4b7dc24.js"><link rel="prefetch" href="/assets/js/490.8ea88875.js"><link rel="prefetch" href="/assets/js/491.d1e2d1b6.js"><link rel="prefetch" href="/assets/js/492.217b7fd1.js"><link rel="prefetch" href="/assets/js/493.6d188156.js"><link rel="prefetch" href="/assets/js/494.adcca4bf.js"><link rel="prefetch" href="/assets/js/495.13cdbf74.js"><link rel="prefetch" href="/assets/js/496.53a4b758.js"><link rel="prefetch" href="/assets/js/497.0763c40d.js"><link rel="prefetch" href="/assets/js/498.debcfb1b.js"><link rel="prefetch" href="/assets/js/499.7d3cf6eb.js"><link rel="prefetch" href="/assets/js/50.41ac06fd.js"><link rel="prefetch" href="/assets/js/500.28473fb4.js"><link rel="prefetch" href="/assets/js/501.90241d8d.js"><link rel="prefetch" href="/assets/js/502.a096c362.js"><link rel="prefetch" href="/assets/js/503.539676ba.js"><link rel="prefetch" href="/assets/js/504.39d8e399.js"><link rel="prefetch" href="/assets/js/505.2b2a130b.js"><link rel="prefetch" href="/assets/js/506.7811ad79.js"><link rel="prefetch" href="/assets/js/507.2817d33b.js"><link rel="prefetch" href="/assets/js/508.89b8d712.js"><link rel="prefetch" href="/assets/js/509.80dcd2b5.js"><link rel="prefetch" href="/assets/js/51.3ef6cdbe.js"><link rel="prefetch" href="/assets/js/510.a8f28525.js"><link rel="prefetch" href="/assets/js/511.e890924a.js"><link rel="prefetch" href="/assets/js/512.9a073fe1.js"><link rel="prefetch" href="/assets/js/513.0a302efb.js"><link rel="prefetch" href="/assets/js/514.6b43f3e7.js"><link rel="prefetch" href="/assets/js/515.c7b0284a.js"><link rel="prefetch" href="/assets/js/516.5daf0566.js"><link rel="prefetch" href="/assets/js/517.67f7c508.js"><link rel="prefetch" href="/assets/js/518.7854e40b.js"><link rel="prefetch" href="/assets/js/519.dcb88d39.js"><link rel="prefetch" href="/assets/js/52.840d0f74.js"><link rel="prefetch" href="/assets/js/520.6f40c4e7.js"><link rel="prefetch" href="/assets/js/521.3c0a006c.js"><link rel="prefetch" href="/assets/js/522.ed57f1a7.js"><link rel="prefetch" href="/assets/js/523.39d637e2.js"><link rel="prefetch" href="/assets/js/524.acd5ee1f.js"><link rel="prefetch" href="/assets/js/525.0836647e.js"><link rel="prefetch" href="/assets/js/526.9e2af36c.js"><link rel="prefetch" href="/assets/js/527.9337d948.js"><link rel="prefetch" href="/assets/js/528.cacbd480.js"><link rel="prefetch" href="/assets/js/529.21a67f8f.js"><link rel="prefetch" href="/assets/js/53.fb86a936.js"><link rel="prefetch" href="/assets/js/530.3373ac51.js"><link rel="prefetch" href="/assets/js/531.1b371c24.js"><link rel="prefetch" href="/assets/js/532.64685d6d.js"><link rel="prefetch" href="/assets/js/533.d3344f80.js"><link rel="prefetch" href="/assets/js/534.1adcd2e2.js"><link rel="prefetch" href="/assets/js/535.cf0f4bbe.js"><link rel="prefetch" href="/assets/js/536.f3cadbc2.js"><link rel="prefetch" href="/assets/js/537.d2071727.js"><link rel="prefetch" href="/assets/js/538.b700925e.js"><link rel="prefetch" href="/assets/js/539.a5de8601.js"><link rel="prefetch" href="/assets/js/54.e8d5a023.js"><link rel="prefetch" href="/assets/js/540.525e8630.js"><link rel="prefetch" href="/assets/js/541.0b14ac8a.js"><link rel="prefetch" href="/assets/js/542.fc96e578.js"><link rel="prefetch" href="/assets/js/543.53cf25d0.js"><link rel="prefetch" href="/assets/js/544.f9b3e911.js"><link rel="prefetch" href="/assets/js/545.b353670e.js"><link rel="prefetch" href="/assets/js/546.5ed48a56.js"><link rel="prefetch" href="/assets/js/547.9843edce.js"><link rel="prefetch" href="/assets/js/548.f8eb7890.js"><link rel="prefetch" href="/assets/js/549.990650c2.js"><link rel="prefetch" href="/assets/js/55.b268240f.js"><link rel="prefetch" href="/assets/js/550.c7ba17a1.js"><link rel="prefetch" href="/assets/js/551.2ea79a07.js"><link rel="prefetch" href="/assets/js/552.950843bd.js"><link rel="prefetch" href="/assets/js/553.d1f94516.js"><link rel="prefetch" href="/assets/js/554.873b4336.js"><link rel="prefetch" href="/assets/js/555.12e7f37d.js"><link rel="prefetch" href="/assets/js/556.c84abfa5.js"><link rel="prefetch" href="/assets/js/557.76108e15.js"><link rel="prefetch" href="/assets/js/558.ad0caf91.js"><link rel="prefetch" href="/assets/js/559.efc5fcaa.js"><link rel="prefetch" href="/assets/js/56.862368c6.js"><link rel="prefetch" href="/assets/js/560.82032a52.js"><link rel="prefetch" href="/assets/js/561.b776e2e3.js"><link rel="prefetch" href="/assets/js/562.8f48c34e.js"><link rel="prefetch" href="/assets/js/563.1916b1f0.js"><link rel="prefetch" href="/assets/js/564.89eef1bf.js"><link rel="prefetch" href="/assets/js/565.2ca43acb.js"><link rel="prefetch" href="/assets/js/566.6caf93e6.js"><link rel="prefetch" href="/assets/js/567.1888604a.js"><link rel="prefetch" href="/assets/js/568.c909a75b.js"><link rel="prefetch" href="/assets/js/569.6862733a.js"><link rel="prefetch" href="/assets/js/57.d93cbd65.js"><link rel="prefetch" href="/assets/js/570.ce0e3115.js"><link rel="prefetch" href="/assets/js/571.0da49310.js"><link rel="prefetch" href="/assets/js/572.c34ca3fd.js"><link rel="prefetch" href="/assets/js/573.895c8f8d.js"><link rel="prefetch" href="/assets/js/574.e59b6191.js"><link rel="prefetch" href="/assets/js/575.842ef1ff.js"><link rel="prefetch" href="/assets/js/576.9b5dd540.js"><link rel="prefetch" href="/assets/js/577.2d0e6020.js"><link rel="prefetch" href="/assets/js/578.2e49a333.js"><link rel="prefetch" href="/assets/js/579.005171f1.js"><link rel="prefetch" href="/assets/js/58.10ca5b0d.js"><link rel="prefetch" href="/assets/js/580.74d9d14e.js"><link rel="prefetch" href="/assets/js/581.404aa6ad.js"><link rel="prefetch" href="/assets/js/582.4c756647.js"><link rel="prefetch" href="/assets/js/583.84f8db17.js"><link rel="prefetch" href="/assets/js/584.0c4307db.js"><link rel="prefetch" href="/assets/js/585.9cbe1c6c.js"><link rel="prefetch" href="/assets/js/586.94d5912f.js"><link rel="prefetch" href="/assets/js/587.08073e55.js"><link rel="prefetch" href="/assets/js/588.a4cb5da6.js"><link rel="prefetch" href="/assets/js/589.ff2423ac.js"><link rel="prefetch" href="/assets/js/59.3eb351e6.js"><link rel="prefetch" href="/assets/js/590.1a498879.js"><link rel="prefetch" href="/assets/js/591.eb8d6c20.js"><link rel="prefetch" href="/assets/js/592.850eee03.js"><link rel="prefetch" href="/assets/js/593.12b28022.js"><link rel="prefetch" href="/assets/js/594.9c805b81.js"><link rel="prefetch" href="/assets/js/595.e9119b0e.js"><link rel="prefetch" href="/assets/js/596.6b641a7e.js"><link rel="prefetch" href="/assets/js/597.77bf95f8.js"><link rel="prefetch" href="/assets/js/598.da53697e.js"><link rel="prefetch" href="/assets/js/599.281b72be.js"><link rel="prefetch" href="/assets/js/6.8773fb47.js"><link rel="prefetch" href="/assets/js/60.1c1a9cd1.js"><link rel="prefetch" href="/assets/js/600.4aa56a28.js"><link rel="prefetch" href="/assets/js/601.93029330.js"><link rel="prefetch" href="/assets/js/602.3dee7fe6.js"><link rel="prefetch" href="/assets/js/603.cdc313ee.js"><link rel="prefetch" href="/assets/js/604.965166a0.js"><link rel="prefetch" href="/assets/js/605.7c70961f.js"><link rel="prefetch" href="/assets/js/606.a9f02486.js"><link rel="prefetch" href="/assets/js/607.73baa5d1.js"><link rel="prefetch" href="/assets/js/608.e8fa09f4.js"><link rel="prefetch" href="/assets/js/609.ac51d009.js"><link rel="prefetch" href="/assets/js/61.9683ebee.js"><link rel="prefetch" href="/assets/js/610.644de93e.js"><link rel="prefetch" href="/assets/js/611.4435581a.js"><link rel="prefetch" href="/assets/js/612.27640be2.js"><link rel="prefetch" href="/assets/js/613.5010499b.js"><link rel="prefetch" href="/assets/js/614.cf985a78.js"><link rel="prefetch" href="/assets/js/615.175e2d87.js"><link rel="prefetch" href="/assets/js/616.c034e53d.js"><link rel="prefetch" href="/assets/js/617.fe843932.js"><link rel="prefetch" href="/assets/js/618.17ffbf18.js"><link rel="prefetch" href="/assets/js/619.c968374b.js"><link rel="prefetch" href="/assets/js/62.2276e6d3.js"><link rel="prefetch" href="/assets/js/620.f34c0fa0.js"><link rel="prefetch" href="/assets/js/621.815b8624.js"><link rel="prefetch" href="/assets/js/622.d534821e.js"><link rel="prefetch" href="/assets/js/623.936ac4e3.js"><link rel="prefetch" href="/assets/js/624.68e1aa29.js"><link rel="prefetch" href="/assets/js/625.07b94155.js"><link rel="prefetch" href="/assets/js/626.96720feb.js"><link rel="prefetch" href="/assets/js/627.6c0097f7.js"><link rel="prefetch" href="/assets/js/628.1b01c525.js"><link rel="prefetch" href="/assets/js/629.6b7b7051.js"><link rel="prefetch" href="/assets/js/63.21657e0e.js"><link rel="prefetch" href="/assets/js/630.5e364b4e.js"><link rel="prefetch" href="/assets/js/631.1dbc5bc2.js"><link rel="prefetch" href="/assets/js/632.26cf0433.js"><link rel="prefetch" href="/assets/js/633.f5940046.js"><link rel="prefetch" href="/assets/js/634.631e139f.js"><link rel="prefetch" href="/assets/js/635.dcb1483c.js"><link rel="prefetch" href="/assets/js/636.99b6e8c3.js"><link rel="prefetch" href="/assets/js/637.ac8ad035.js"><link rel="prefetch" href="/assets/js/638.5782cc19.js"><link rel="prefetch" href="/assets/js/639.1db80fe2.js"><link rel="prefetch" href="/assets/js/64.02fb1ddb.js"><link rel="prefetch" href="/assets/js/640.bc54f7f5.js"><link rel="prefetch" href="/assets/js/641.cdff8819.js"><link rel="prefetch" href="/assets/js/642.df23e220.js"><link rel="prefetch" href="/assets/js/643.89df1b3c.js"><link rel="prefetch" href="/assets/js/644.5f0031ba.js"><link rel="prefetch" href="/assets/js/645.f7daa126.js"><link rel="prefetch" href="/assets/js/646.d47a3e0e.js"><link rel="prefetch" href="/assets/js/647.d1c8f3ae.js"><link rel="prefetch" href="/assets/js/648.0506ce23.js"><link rel="prefetch" href="/assets/js/649.6cf2a641.js"><link rel="prefetch" href="/assets/js/65.b4028009.js"><link rel="prefetch" href="/assets/js/650.89785dee.js"><link rel="prefetch" href="/assets/js/651.8b6fa105.js"><link rel="prefetch" href="/assets/js/652.5e42ce8f.js"><link rel="prefetch" href="/assets/js/653.eddc84e1.js"><link rel="prefetch" href="/assets/js/654.48762cb9.js"><link rel="prefetch" href="/assets/js/655.7bcd5aa3.js"><link rel="prefetch" href="/assets/js/656.bf91b745.js"><link rel="prefetch" href="/assets/js/657.332eec27.js"><link rel="prefetch" href="/assets/js/658.9e9b31c8.js"><link rel="prefetch" href="/assets/js/659.b469808c.js"><link rel="prefetch" href="/assets/js/66.33d6767a.js"><link rel="prefetch" href="/assets/js/660.25843c88.js"><link rel="prefetch" href="/assets/js/661.ca1a9580.js"><link rel="prefetch" href="/assets/js/662.cd6fe6ce.js"><link rel="prefetch" href="/assets/js/663.dddb87c3.js"><link rel="prefetch" href="/assets/js/664.c4d2b9b4.js"><link rel="prefetch" href="/assets/js/665.e26ea7fd.js"><link rel="prefetch" href="/assets/js/666.918a92c2.js"><link rel="prefetch" href="/assets/js/667.5f06fa05.js"><link rel="prefetch" href="/assets/js/668.7b783af2.js"><link rel="prefetch" href="/assets/js/669.efe734b4.js"><link rel="prefetch" href="/assets/js/67.0737d4e2.js"><link rel="prefetch" href="/assets/js/670.70a7afa1.js"><link rel="prefetch" href="/assets/js/671.d82e7481.js"><link rel="prefetch" href="/assets/js/672.f4e33cf4.js"><link rel="prefetch" href="/assets/js/673.f3b26cca.js"><link rel="prefetch" href="/assets/js/674.d5327fdb.js"><link rel="prefetch" href="/assets/js/675.06e1587e.js"><link rel="prefetch" href="/assets/js/676.b81eab7c.js"><link rel="prefetch" href="/assets/js/677.65c1f157.js"><link rel="prefetch" href="/assets/js/678.dd3c35f4.js"><link rel="prefetch" href="/assets/js/679.1b3371c6.js"><link rel="prefetch" href="/assets/js/68.ff08cac1.js"><link rel="prefetch" href="/assets/js/680.4c431b6d.js"><link rel="prefetch" href="/assets/js/681.4b4df97f.js"><link rel="prefetch" href="/assets/js/682.daa28558.js"><link rel="prefetch" href="/assets/js/683.019ac4bf.js"><link rel="prefetch" href="/assets/js/684.72942987.js"><link rel="prefetch" href="/assets/js/685.b232df8f.js"><link rel="prefetch" href="/assets/js/686.27dc24b3.js"><link rel="prefetch" href="/assets/js/687.4a8ef826.js"><link rel="prefetch" href="/assets/js/688.0ba25fdf.js"><link rel="prefetch" href="/assets/js/689.be8172ba.js"><link rel="prefetch" href="/assets/js/69.516fa4ee.js"><link rel="prefetch" href="/assets/js/690.88418e50.js"><link rel="prefetch" href="/assets/js/691.1d8c222b.js"><link rel="prefetch" href="/assets/js/692.85d9e426.js"><link rel="prefetch" href="/assets/js/693.a78b6c7b.js"><link rel="prefetch" href="/assets/js/694.8348e02c.js"><link rel="prefetch" href="/assets/js/695.0bbdae98.js"><link rel="prefetch" href="/assets/js/696.f9dcc8bf.js"><link rel="prefetch" href="/assets/js/697.1c6c7982.js"><link rel="prefetch" href="/assets/js/698.fa867a93.js"><link rel="prefetch" href="/assets/js/699.5ad98f0b.js"><link rel="prefetch" href="/assets/js/7.e86883c6.js"><link rel="prefetch" href="/assets/js/70.d7c0b02d.js"><link rel="prefetch" href="/assets/js/700.da097ba8.js"><link rel="prefetch" href="/assets/js/701.8f40c007.js"><link rel="prefetch" href="/assets/js/702.2ac7cfc8.js"><link rel="prefetch" href="/assets/js/703.e4f83f34.js"><link rel="prefetch" href="/assets/js/704.3230d5d3.js"><link rel="prefetch" href="/assets/js/705.9f2ac56e.js"><link rel="prefetch" href="/assets/js/706.479ef752.js"><link rel="prefetch" href="/assets/js/707.12907b99.js"><link rel="prefetch" href="/assets/js/708.a54c005e.js"><link rel="prefetch" href="/assets/js/709.2f084e72.js"><link rel="prefetch" href="/assets/js/71.c9ef60a6.js"><link rel="prefetch" href="/assets/js/710.992d9298.js"><link rel="prefetch" href="/assets/js/711.3dec9e74.js"><link rel="prefetch" href="/assets/js/712.fbba000f.js"><link rel="prefetch" href="/assets/js/713.644be223.js"><link rel="prefetch" href="/assets/js/714.20e703bd.js"><link rel="prefetch" href="/assets/js/715.7ac51064.js"><link rel="prefetch" href="/assets/js/716.5f8c7487.js"><link rel="prefetch" href="/assets/js/717.cdd46244.js"><link rel="prefetch" href="/assets/js/718.7b7a44e2.js"><link rel="prefetch" href="/assets/js/719.ed06b003.js"><link rel="prefetch" href="/assets/js/72.c23e24e9.js"><link rel="prefetch" href="/assets/js/720.202718be.js"><link rel="prefetch" href="/assets/js/721.1426ef3c.js"><link rel="prefetch" href="/assets/js/722.79f56663.js"><link rel="prefetch" href="/assets/js/723.6dcfa3ed.js"><link rel="prefetch" href="/assets/js/724.4c098acf.js"><link rel="prefetch" href="/assets/js/725.381dd189.js"><link rel="prefetch" href="/assets/js/726.baa6dcfe.js"><link rel="prefetch" href="/assets/js/727.f893500e.js"><link rel="prefetch" href="/assets/js/728.977ee9a0.js"><link rel="prefetch" href="/assets/js/729.3dc27591.js"><link rel="prefetch" href="/assets/js/73.d2b5812c.js"><link rel="prefetch" href="/assets/js/730.e62b3efb.js"><link rel="prefetch" href="/assets/js/731.8b21fd00.js"><link rel="prefetch" href="/assets/js/732.0e4b5daf.js"><link rel="prefetch" href="/assets/js/733.1cc505b4.js"><link rel="prefetch" href="/assets/js/734.55c0fe79.js"><link rel="prefetch" href="/assets/js/735.4eb02d3a.js"><link rel="prefetch" href="/assets/js/736.40c2728a.js"><link rel="prefetch" href="/assets/js/737.73c562f3.js"><link rel="prefetch" href="/assets/js/738.6dd69adf.js"><link rel="prefetch" href="/assets/js/739.af66a4dc.js"><link rel="prefetch" href="/assets/js/74.408525bc.js"><link rel="prefetch" href="/assets/js/740.eff57d99.js"><link rel="prefetch" href="/assets/js/741.7c9b1745.js"><link rel="prefetch" href="/assets/js/742.87bf09be.js"><link rel="prefetch" href="/assets/js/743.fd587ae7.js"><link rel="prefetch" href="/assets/js/744.b207d76b.js"><link rel="prefetch" href="/assets/js/745.5da05a37.js"><link rel="prefetch" href="/assets/js/746.05f0fcc4.js"><link rel="prefetch" href="/assets/js/747.8afc4f80.js"><link rel="prefetch" href="/assets/js/748.a6328657.js"><link rel="prefetch" href="/assets/js/749.488acffe.js"><link rel="prefetch" href="/assets/js/75.d6223e36.js"><link rel="prefetch" href="/assets/js/750.b778f9b2.js"><link rel="prefetch" href="/assets/js/751.046fb057.js"><link rel="prefetch" href="/assets/js/752.4fa1c3ec.js"><link rel="prefetch" href="/assets/js/753.2023ccf5.js"><link rel="prefetch" href="/assets/js/754.68df0df4.js"><link rel="prefetch" href="/assets/js/755.7289134a.js"><link rel="prefetch" href="/assets/js/756.bce7616e.js"><link rel="prefetch" href="/assets/js/757.3403e5f9.js"><link rel="prefetch" href="/assets/js/758.8f0d0bdf.js"><link rel="prefetch" href="/assets/js/759.cdd31702.js"><link rel="prefetch" href="/assets/js/76.f65eed64.js"><link rel="prefetch" href="/assets/js/760.9bfe29ed.js"><link rel="prefetch" href="/assets/js/761.e23339c6.js"><link rel="prefetch" href="/assets/js/762.db375c5b.js"><link rel="prefetch" href="/assets/js/763.8b16c3fe.js"><link rel="prefetch" href="/assets/js/764.f1f4f712.js"><link rel="prefetch" href="/assets/js/765.23e53b3a.js"><link rel="prefetch" href="/assets/js/766.3d3bb3ff.js"><link rel="prefetch" href="/assets/js/767.35ad7cea.js"><link rel="prefetch" href="/assets/js/768.295d1f7a.js"><link rel="prefetch" href="/assets/js/769.2f8fe776.js"><link rel="prefetch" href="/assets/js/77.ec9614b4.js"><link rel="prefetch" href="/assets/js/770.a89ea5e2.js"><link rel="prefetch" href="/assets/js/771.0d2cf3ee.js"><link rel="prefetch" href="/assets/js/772.a10354a4.js"><link rel="prefetch" href="/assets/js/773.ee60e68b.js"><link rel="prefetch" href="/assets/js/774.ba4aad28.js"><link rel="prefetch" href="/assets/js/775.7d35f9cc.js"><link rel="prefetch" href="/assets/js/776.b3ec764c.js"><link rel="prefetch" href="/assets/js/777.c124aefe.js"><link rel="prefetch" href="/assets/js/778.325cfc0e.js"><link rel="prefetch" href="/assets/js/779.d2b575a6.js"><link rel="prefetch" href="/assets/js/780.218c6b47.js"><link rel="prefetch" href="/assets/js/781.0eac52b7.js"><link rel="prefetch" href="/assets/js/782.79965326.js"><link rel="prefetch" href="/assets/js/783.60892b73.js"><link rel="prefetch" href="/assets/js/784.b8f79fd0.js"><link rel="prefetch" href="/assets/js/785.0528258e.js"><link rel="prefetch" href="/assets/js/786.1dbadb12.js"><link rel="prefetch" href="/assets/js/787.f247b164.js"><link rel="prefetch" href="/assets/js/788.3dd93a34.js"><link rel="prefetch" href="/assets/js/789.7b97a48d.js"><link rel="prefetch" href="/assets/js/79.ed5ad905.js"><link rel="prefetch" href="/assets/js/790.8ceeb0b3.js"><link rel="prefetch" href="/assets/js/791.e926d9a8.js"><link rel="prefetch" href="/assets/js/792.3e5a323a.js"><link rel="prefetch" href="/assets/js/793.43419085.js"><link rel="prefetch" href="/assets/js/794.b8c22345.js"><link rel="prefetch" href="/assets/js/795.7370ff3c.js"><link rel="prefetch" href="/assets/js/796.9509e009.js"><link rel="prefetch" href="/assets/js/797.4a4202c2.js"><link rel="prefetch" href="/assets/js/798.3961cf47.js"><link rel="prefetch" href="/assets/js/799.69707d57.js"><link rel="prefetch" href="/assets/js/8.3fe9535a.js"><link rel="prefetch" href="/assets/js/80.202c3322.js"><link rel="prefetch" href="/assets/js/800.f72c31a2.js"><link rel="prefetch" href="/assets/js/801.2372cb79.js"><link rel="prefetch" href="/assets/js/802.3aefd131.js"><link rel="prefetch" href="/assets/js/803.18443761.js"><link rel="prefetch" href="/assets/js/804.301bf327.js"><link rel="prefetch" href="/assets/js/805.e169a32a.js"><link rel="prefetch" href="/assets/js/806.27cbd296.js"><link rel="prefetch" href="/assets/js/807.b0443249.js"><link rel="prefetch" href="/assets/js/808.91924bc7.js"><link rel="prefetch" href="/assets/js/809.865e8932.js"><link rel="prefetch" href="/assets/js/81.9d064e1c.js"><link rel="prefetch" href="/assets/js/810.28dafb2c.js"><link rel="prefetch" href="/assets/js/811.9248d0a5.js"><link rel="prefetch" href="/assets/js/812.8bb147f8.js"><link rel="prefetch" href="/assets/js/813.57a8a982.js"><link rel="prefetch" href="/assets/js/814.f80c73c9.js"><link rel="prefetch" href="/assets/js/815.2b3d99fc.js"><link rel="prefetch" href="/assets/js/816.4a05e284.js"><link rel="prefetch" href="/assets/js/817.6c8508c2.js"><link rel="prefetch" href="/assets/js/818.c72f5330.js"><link rel="prefetch" href="/assets/js/819.35126624.js"><link rel="prefetch" href="/assets/js/82.210310b3.js"><link rel="prefetch" href="/assets/js/820.d5254c3c.js"><link rel="prefetch" href="/assets/js/821.c69c6b2c.js"><link rel="prefetch" href="/assets/js/822.1ccbb204.js"><link rel="prefetch" href="/assets/js/823.0436449a.js"><link rel="prefetch" href="/assets/js/824.a9d3c6f0.js"><link rel="prefetch" href="/assets/js/825.f9bf8329.js"><link rel="prefetch" href="/assets/js/826.e0d5f786.js"><link rel="prefetch" href="/assets/js/827.cf88e320.js"><link rel="prefetch" href="/assets/js/828.67da7389.js"><link rel="prefetch" href="/assets/js/829.21c2eac1.js"><link rel="prefetch" href="/assets/js/83.d74f6f93.js"><link rel="prefetch" href="/assets/js/830.1eb4ea1b.js"><link rel="prefetch" href="/assets/js/831.6b51565e.js"><link rel="prefetch" href="/assets/js/832.07a20675.js"><link rel="prefetch" href="/assets/js/833.0f7823b8.js"><link rel="prefetch" href="/assets/js/834.27bf9c2e.js"><link rel="prefetch" href="/assets/js/835.409429ce.js"><link rel="prefetch" href="/assets/js/836.28de2c29.js"><link rel="prefetch" href="/assets/js/837.5e7df1f1.js"><link rel="prefetch" href="/assets/js/838.5adc5f6e.js"><link rel="prefetch" href="/assets/js/839.11c3bfc2.js"><link rel="prefetch" href="/assets/js/84.4cf98a31.js"><link rel="prefetch" href="/assets/js/840.65d20fee.js"><link rel="prefetch" href="/assets/js/841.1949a396.js"><link rel="prefetch" href="/assets/js/842.f7a8d098.js"><link rel="prefetch" href="/assets/js/843.65694aa6.js"><link rel="prefetch" href="/assets/js/844.7a62cf9b.js"><link rel="prefetch" href="/assets/js/85.22b95924.js"><link rel="prefetch" href="/assets/js/86.a6f80a36.js"><link rel="prefetch" href="/assets/js/87.3b138e3b.js"><link rel="prefetch" href="/assets/js/88.bb56b7a2.js"><link rel="prefetch" href="/assets/js/89.198a78ff.js"><link rel="prefetch" href="/assets/js/9.59b98557.js"><link rel="prefetch" href="/assets/js/90.d743afe3.js"><link rel="prefetch" href="/assets/js/91.3b6d096c.js"><link rel="prefetch" href="/assets/js/92.a61a93f5.js"><link rel="prefetch" href="/assets/js/93.89cc3bad.js"><link rel="prefetch" href="/assets/js/94.fafb4ea3.js"><link rel="prefetch" href="/assets/js/95.52a52f2e.js"><link rel="prefetch" href="/assets/js/96.82379902.js"><link rel="prefetch" href="/assets/js/97.fb013838.js"><link rel="prefetch" href="/assets/js/98.17d2f72a.js"><link rel="prefetch" href="/assets/js/99.b355b28b.js">
    <link rel="stylesheet" href="/assets/css/0.styles.183d1d00.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-17815e06><header class="navbar" data-v-17815e06><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/assets/img/logo.png" alt="智能后端和架构" class="logo"> <span class="site-name can-hide">智能后端和架构</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/readguide.html" class="nav-link">
  导读
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java基础" class="dropdown-title"><span class="title">Java</span> <span class="arrow down"></span></button> <button type="button" aria-label="Java基础" class="mobile-dropdown-title"><span class="title">Java</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          Java语言基础
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/intro/01-java-intro.html" class="nav-link">
  Java入门介绍
</a></li><li class="dropdown-subitem"><a href="/java/intro/03-java-grammer.html" class="nav-link">
  Java基础语法
</a></li></ul></li><li class="dropdown-item"><h4>
          Java面向对象基础
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/basic/01-lan-feature.html" class="nav-link">
  语言基础特性
</a></li><li class="dropdown-subitem"><a href="/java/basic/02-oop-feature.html" class="nav-link">
  面向对象特征
</a></li></ul></li><li class="dropdown-item"><h4>
          Java集合类编程
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/collection/01-intro.html" class="nav-link">
  集合类基础介绍
</a></li><li class="dropdown-subitem"><a href="/java/collection/02-collectionmap.html" class="nav-link">
  集合框架Collction、Map
</a></li></ul></li><li class="dropdown-item"><h4>
          Java文件和网络编程
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/file/01-intro.html" class="nav-link">
  Java文件IO流入门
</a></li><li class="dropdown-subitem"><a href="/java/net/01-intro.html" class="nav-link">
  Java网络编程入门
</a></li></ul></li><li class="dropdown-item"><h4>
          Java并发编程和JUC
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/thread/01-intro.html" class="nav-link">
  Java并发 基础入门
</a></li><li class="dropdown-subitem"><a href="/java/juc/01-intro.html" class="nav-link">
  Java并发 JUC入门
</a></li></ul></li><li class="dropdown-item"><h4>
          Java虚拟机和语言特性
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/jvm/01-intro.html" class="nav-link">
  Java  虚拟机
</a></li><li class="dropdown-subitem"><a href="/java/characteristic/01-java8.html" class="nav-link">
  Java8 语言特性
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">数据库</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">数据库</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          数据库基础和SQL
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/db/intro/01-intro.html" class="nav-link">
  数据库绪论
</a></li><li class="dropdown-subitem"><a href="/db/intro/02-relationdb.html" class="nav-link">
  关系数据库
</a></li><li class="dropdown-subitem"><a href="/db/comsql/01-basicselect.html" class="nav-link">
  基本查询SQL
</a></li><li class="dropdown-subitem"><a href="/db/comsql/02-joinselect.html" class="nav-link">
  连表查询SQL
</a></li></ul></li><li class="dropdown-item"><h4>
          MySQL基础和优化
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/db/mysqlbasic/01-intro.html" class="nav-link">
  入门介绍
</a></li><li class="dropdown-subitem"><a href="/db/mysqlopt1/01-solutionsum.html" class="nav-link">
  性能优化方案
</a></li><li class="dropdown-subitem"><a href="/db/mysqlopt2/01-districtandtable.html" class="nav-link">
  分区和分表
</a></li><li class="dropdown-subitem"><a href="/db/mysqlopt2/05-readwritesepration.html" class="nav-link">
  读写分离介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          NoSQL数据库
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/db/redis/01-intro.html" class="nav-link">
  Redis介绍和总结
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">算法</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          基础概念总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/algorithm/basic/01-basicconcept.html" class="nav-link">
  数据结构基础概念
</a></li><li class="dropdown-subitem"><a href="/algorithm/basic/02-intro.html" class="nav-link">
  算法和数据结构介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/visual/01-commondy.html" class="nav-link">
  常用算法动态展示
</a></li><li class="dropdown-subitem"><a href="/algorithm/visual/04-visualgo.html" class="nav-link">
  visualgo-中文算法展示
</a></li></ul></li><li class="dropdown-item"><h4>
          算法思想总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/algorithm/thought/01-thoughts8intro.html" class="nav-link">
  八种常用算法思想
</a></li><li class="dropdown-subitem"><a href="/algorithm/thought/02-thoughts5intro.html" class="nav-link">
  五种基本算法思想
</a></li></ul></li><li class="dropdown-item"><h4>
          常用算法总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/algorithm/search/01-intro.html" class="nav-link">
  常用查找算法-介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/sort/01-intro.html" class="nav-link">
  常用排序算法-介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/strmatch/01-intro.html" class="nav-link">
  常用字符串匹配-介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/encryption/01-intro.html" class="nav-link">
  常用加密解密算法-介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">大数据</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          基础知识总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/bigdata/intro/01-intro.html" class="nav-link">
  入门知识介绍
</a></li><li class="dropdown-subitem"><a href="/bigdata/techintro/01-intro.html" class="nav-link">
  技术体系介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          数据采集总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dc/intro/01-intro.html" class="nav-link">
  入门知识介绍
</a></li><li class="dropdown-subitem"><a href="/dc/intro/02-diff.html" class="nav-link">
  常用工具比较
</a></li></ul></li><li class="dropdown-item"><h4>
          数据存储总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ds/intro/01-basicintro.html" class="nav-link">
  Hadoop入门介绍
</a></li><li class="dropdown-subitem"><a href="/ds/intro/02-detailintro.html" class="nav-link">
  Hadoop生态介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          数据仓库总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dw/intro/01-intro.html" class="nav-link">
  数据仓库入门介绍
</a></li><li class="dropdown-subitem"><a href="/dw/intro/03-summary.html" class="nav-link">
  数据仓库精华总结
</a></li></ul></li><li class="dropdown-item"><h4>
          数据处理总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dp/mr/01-intro.html" class="nav-link">
  MapReduce-入门介绍
</a></li><li class="dropdown-subitem"><a href="/dp/mr/02-basicprin.html" class="nav-link">
  MapReduce-工作原理
</a></li></ul></li><li class="dropdown-item"><h4>
          数据应用总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/da/intro/01-intro.html" class="nav-link">
  大数据应用场景基础介绍
</a></li><li class="dropdown-subitem"><a href="/dm/intro/01-intro.html" class="nav-link">
  大数据数据挖掘基础介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">人工智能</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">人工智能</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          基础知识总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ai/intro/01-intro.html" class="nav-link">
  人工智能基础介绍
</a></li><li class="dropdown-subitem"><a href="/ai/mlintro/01-intro.html" class="nav-link">
  机器学习基础介绍
</a></li><li class="dropdown-subitem"><a href="/ai/dlintro/01-intro.html" class="nav-link">
  深度学习基础介绍
</a></li><li class="dropdown-subitem"><a href="/ai/nnprin/01-intro.html" class="nav-link">
  神经网络原理介绍
</a></li><li class="dropdown-subitem"><a href="/ai/mlalgorithm/01-intro.html" class="nav-link">
  机器学习算法介绍
</a></li><li class="dropdown-subitem"><a href="/ai/mlmath/01-intro.html" class="nav-link">
  机器学习数学介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          开发框架总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ad/intro/01-intro.html" class="nav-link">
  主流-AI开源开发框架介绍
</a></li><li class="dropdown-subitem"><a href="/ad/dl4jintro/01-intro.html" class="nav-link">
  JAVA-AI开发框架Dl4j介绍
</a></li><li class="dropdown-subitem"><a href="/ad/pytorch/01-intro.html" class="nav-link">
  AI开发框架-Pytorch介绍
</a></li><li class="dropdown-subitem"><a href="/ad/tensorflow/01-intro.html" class="nav-link">
  AI开发框架-TensorFlow介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          开发应用案例
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ac/intro/01-intro.html" class="nav-link">
  AI常见案例和趋势介绍
</a></li><li class="dropdown-subitem"><a href="/ac/rsintro/01-intro.html" class="nav-link">
  AI应用案例-推荐系统介绍
</a></li><li class="dropdown-subitem"><a href="/ac/aicity/01-intro.html" class="nav-link">
  AI应用案例-智慧城市介绍
</a></li><li class="dropdown-subitem"><a href="/ac/aibigscreen/01-intro.html" class="nav-link">
  AI应用案例-智慧大屏介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">Spring</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">Spring</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          Spring基础知识
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/basic/01-intro.html" class="nav-link">
  Spring-入门介绍
</a></li><li class="dropdown-subitem"><a href="/spring/basic/02-iocaopintro.html" class="nav-link">
  IOC和AOP-原理介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          SpringMVC总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/springmvc/01-intro.html" class="nav-link">
  SpringMVC-入门介绍
</a></li><li class="dropdown-subitem"><a href="/spring/springmvc/02-prinintro.html" class="nav-link">
  SpringMVC-工作原理介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          SpringBoot总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/springboot/03-workprin.html" class="nav-link">
  SpringBoot-工作原理
</a></li><li class="dropdown-subitem"><a href="/spring/springboot/06-startprincodeanalysis.html" class="nav-link">
  启动原理分析和源码解读
</a></li></ul></li><li class="dropdown-item"><h4>
          Spring注解总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/annotation/03-springannprin.html" class="nav-link">
  Spring注解实现原理
</a></li><li class="dropdown-subitem"><a href="/spring/annotation/04-anntotal1.html" class="nav-link">
  Spring注解大全(一)
</a></li></ul></li><li class="dropdown-item"><h4>
          SpringCloud知识介绍
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/springcloud/01-intro.html" class="nav-link">
  SpringCloud-基础介绍
</a></li><li class="dropdown-subitem"><a href="/spring/springcloud/03-prindetail.html" class="nav-link">
  SpringCloud-原理详解
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">框架</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">框架</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          框架基础总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/framework/basic/01-intro.html" class="nav-link">
  框架基础知识介绍
</a></li><li class="dropdown-subitem"><a href="/framework/basic/02-commconceptdiff.html" class="nav-link">
  框架架构组件区别
</a></li><li class="dropdown-subitem"><a href="/framework/basic/03-commconceptrela.html" class="nav-link">
  框架架构组件关系
</a></li><li class="dropdown-subitem"><a href="/framework/basic/06-microserv15.html" class="nav-link">
  常见15种微服务框架
</a></li><li class="dropdown-subitem"><a href="/framework/basic/07-springframethink.html" class="nav-link">
  Spring框架思想总结
</a></li></ul></li><li class="dropdown-item"><h4>
          常用框架总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/framework/log/01-intro.html" class="nav-link">
  日志框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/orm/01-intro.html" class="nav-link">
  ORM框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/nio/01-intro.html" class="nav-link">
  NIO框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/netty/01-intro.html" class="nav-link">
  Netty框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/nettycase/01-intro.html" class="nav-link">
  Netty案例-介绍和总结
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">架构</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">架构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          架构基础知识
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/architecture/basic/01-intro.html" class="nav-link">
  架构基础知识介绍
</a></li><li class="dropdown-subitem"><a href="/architecture/basic/02-essence.html" class="nav-link">
  架构基本概念和本质
</a></li><li class="dropdown-subitem"><a href="/architecture/microservanddistribute/01-intro.html" class="nav-link">
  微服务架构知识介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">开发</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          开发工具
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dev/tool/01-intro.html" class="nav-link">
  Java开发工具介绍
</a></li><li class="dropdown-subitem"><a href="/dev/tool/05-idea20recommendedplug.html" class="nav-link">
  Idea开发插件推荐
</a></li></ul></li><li class="dropdown-item"><h4>
          开发规范
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dev/standard/01-intro.html" class="nav-link">
  Java开发规范
</a></li><li class="dropdown-subitem"><a href="/dev/designpattern/01-intro.html" class="nav-link">
  Java设计模式
</a></li></ul></li><li class="dropdown-item"><h4>
          开发效率
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dev/deveffciency/02-commpromethods.html" class="nav-link">
  效率提升常用方法
</a></li><li class="dropdown-subitem"><a href="/dev/deveffciency/09-summary.html" class="nav-link">
  效率提升精华总结
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">综合</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">综合</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          中间件
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/middleware/mq/01-intro.html" class="nav-link">
  MQ消息队列介绍
</a></li><li class="dropdown-subitem"><a href="/es/basic/01-intro.html" class="nav-link">
  ES搜索服务器介绍
</a></li><li class="dropdown-subitem"><a href="/middleware/zookeeper/01-intro.html" class="nav-link">
  Zookeeper介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          综合技能
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/mysqlop/basic/01-intro.html" class="nav-link">
  MySQL运维总结
</a></li><li class="dropdown-subitem"><a href="/operation/linux/01-intro.html" class="nav-link">
  Linux常用命令
</a></li><li class="dropdown-subitem"><a href="/operation/ng/05-ngsum.html" class="nav-link">
  Nginx使用总结
</a></li><li class="dropdown-subitem"><a href="/post/javabasic/01-javabasic.html" class="nav-link">
  求职面试整理
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">项目|产品</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">项目|产品</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          研发效能介绍
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/projprod/rdefficiencyintro/01-intro.html" class="nav-link">
  研发效能入门介绍
</a></li><li class="dropdown-subitem"><a href="/projprod/rdefficiencyintro/06-efficiencysystem.html" class="nav-link">
  研发效能体系构建
</a></li></ul></li><li class="dropdown-item"><h4>
          研发效能提升
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/projprod/rdeffciencypromote/09-summary.html" class="nav-link">
  研发效能提升精华总结
</a></li><li class="dropdown-subitem"><a href="/projprod/rdeffciencytool/01-intro.html" class="nav-link">
  研发效能系统管理工具
</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/about/aboutme.html" class="nav-link">
  关于
</a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-17815e06></div> <aside class="sidebar" data-v-17815e06><nav class="nav-links"><div class="nav-item"><a href="/readguide.html" class="nav-link">
  导读
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java基础" class="dropdown-title"><span class="title">Java</span> <span class="arrow down"></span></button> <button type="button" aria-label="Java基础" class="mobile-dropdown-title"><span class="title">Java</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          Java语言基础
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/intro/01-java-intro.html" class="nav-link">
  Java入门介绍
</a></li><li class="dropdown-subitem"><a href="/java/intro/03-java-grammer.html" class="nav-link">
  Java基础语法
</a></li></ul></li><li class="dropdown-item"><h4>
          Java面向对象基础
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/basic/01-lan-feature.html" class="nav-link">
  语言基础特性
</a></li><li class="dropdown-subitem"><a href="/java/basic/02-oop-feature.html" class="nav-link">
  面向对象特征
</a></li></ul></li><li class="dropdown-item"><h4>
          Java集合类编程
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/collection/01-intro.html" class="nav-link">
  集合类基础介绍
</a></li><li class="dropdown-subitem"><a href="/java/collection/02-collectionmap.html" class="nav-link">
  集合框架Collction、Map
</a></li></ul></li><li class="dropdown-item"><h4>
          Java文件和网络编程
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/file/01-intro.html" class="nav-link">
  Java文件IO流入门
</a></li><li class="dropdown-subitem"><a href="/java/net/01-intro.html" class="nav-link">
  Java网络编程入门
</a></li></ul></li><li class="dropdown-item"><h4>
          Java并发编程和JUC
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/thread/01-intro.html" class="nav-link">
  Java并发 基础入门
</a></li><li class="dropdown-subitem"><a href="/java/juc/01-intro.html" class="nav-link">
  Java并发 JUC入门
</a></li></ul></li><li class="dropdown-item"><h4>
          Java虚拟机和语言特性
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/java/jvm/01-intro.html" class="nav-link">
  Java  虚拟机
</a></li><li class="dropdown-subitem"><a href="/java/characteristic/01-java8.html" class="nav-link">
  Java8 语言特性
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">数据库</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">数据库</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          数据库基础和SQL
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/db/intro/01-intro.html" class="nav-link">
  数据库绪论
</a></li><li class="dropdown-subitem"><a href="/db/intro/02-relationdb.html" class="nav-link">
  关系数据库
</a></li><li class="dropdown-subitem"><a href="/db/comsql/01-basicselect.html" class="nav-link">
  基本查询SQL
</a></li><li class="dropdown-subitem"><a href="/db/comsql/02-joinselect.html" class="nav-link">
  连表查询SQL
</a></li></ul></li><li class="dropdown-item"><h4>
          MySQL基础和优化
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/db/mysqlbasic/01-intro.html" class="nav-link">
  入门介绍
</a></li><li class="dropdown-subitem"><a href="/db/mysqlopt1/01-solutionsum.html" class="nav-link">
  性能优化方案
</a></li><li class="dropdown-subitem"><a href="/db/mysqlopt2/01-districtandtable.html" class="nav-link">
  分区和分表
</a></li><li class="dropdown-subitem"><a href="/db/mysqlopt2/05-readwritesepration.html" class="nav-link">
  读写分离介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          NoSQL数据库
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/db/redis/01-intro.html" class="nav-link">
  Redis介绍和总结
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">算法</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          基础概念总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/algorithm/basic/01-basicconcept.html" class="nav-link">
  数据结构基础概念
</a></li><li class="dropdown-subitem"><a href="/algorithm/basic/02-intro.html" class="nav-link">
  算法和数据结构介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/visual/01-commondy.html" class="nav-link">
  常用算法动态展示
</a></li><li class="dropdown-subitem"><a href="/algorithm/visual/04-visualgo.html" class="nav-link">
  visualgo-中文算法展示
</a></li></ul></li><li class="dropdown-item"><h4>
          算法思想总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/algorithm/thought/01-thoughts8intro.html" class="nav-link">
  八种常用算法思想
</a></li><li class="dropdown-subitem"><a href="/algorithm/thought/02-thoughts5intro.html" class="nav-link">
  五种基本算法思想
</a></li></ul></li><li class="dropdown-item"><h4>
          常用算法总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/algorithm/search/01-intro.html" class="nav-link">
  常用查找算法-介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/sort/01-intro.html" class="nav-link">
  常用排序算法-介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/strmatch/01-intro.html" class="nav-link">
  常用字符串匹配-介绍
</a></li><li class="dropdown-subitem"><a href="/algorithm/encryption/01-intro.html" class="nav-link">
  常用加密解密算法-介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">大数据</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          基础知识总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/bigdata/intro/01-intro.html" class="nav-link">
  入门知识介绍
</a></li><li class="dropdown-subitem"><a href="/bigdata/techintro/01-intro.html" class="nav-link">
  技术体系介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          数据采集总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dc/intro/01-intro.html" class="nav-link">
  入门知识介绍
</a></li><li class="dropdown-subitem"><a href="/dc/intro/02-diff.html" class="nav-link">
  常用工具比较
</a></li></ul></li><li class="dropdown-item"><h4>
          数据存储总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ds/intro/01-basicintro.html" class="nav-link">
  Hadoop入门介绍
</a></li><li class="dropdown-subitem"><a href="/ds/intro/02-detailintro.html" class="nav-link">
  Hadoop生态介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          数据仓库总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dw/intro/01-intro.html" class="nav-link">
  数据仓库入门介绍
</a></li><li class="dropdown-subitem"><a href="/dw/intro/03-summary.html" class="nav-link">
  数据仓库精华总结
</a></li></ul></li><li class="dropdown-item"><h4>
          数据处理总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dp/mr/01-intro.html" class="nav-link">
  MapReduce-入门介绍
</a></li><li class="dropdown-subitem"><a href="/dp/mr/02-basicprin.html" class="nav-link">
  MapReduce-工作原理
</a></li></ul></li><li class="dropdown-item"><h4>
          数据应用总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/da/intro/01-intro.html" class="nav-link">
  大数据应用场景基础介绍
</a></li><li class="dropdown-subitem"><a href="/dm/intro/01-intro.html" class="nav-link">
  大数据数据挖掘基础介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">人工智能</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">人工智能</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          基础知识总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ai/intro/01-intro.html" class="nav-link">
  人工智能基础介绍
</a></li><li class="dropdown-subitem"><a href="/ai/mlintro/01-intro.html" class="nav-link">
  机器学习基础介绍
</a></li><li class="dropdown-subitem"><a href="/ai/dlintro/01-intro.html" class="nav-link">
  深度学习基础介绍
</a></li><li class="dropdown-subitem"><a href="/ai/nnprin/01-intro.html" class="nav-link">
  神经网络原理介绍
</a></li><li class="dropdown-subitem"><a href="/ai/mlalgorithm/01-intro.html" class="nav-link">
  机器学习算法介绍
</a></li><li class="dropdown-subitem"><a href="/ai/mlmath/01-intro.html" class="nav-link">
  机器学习数学介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          开发框架总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ad/intro/01-intro.html" class="nav-link">
  主流-AI开源开发框架介绍
</a></li><li class="dropdown-subitem"><a href="/ad/dl4jintro/01-intro.html" class="nav-link">
  JAVA-AI开发框架Dl4j介绍
</a></li><li class="dropdown-subitem"><a href="/ad/pytorch/01-intro.html" class="nav-link">
  AI开发框架-Pytorch介绍
</a></li><li class="dropdown-subitem"><a href="/ad/tensorflow/01-intro.html" class="nav-link">
  AI开发框架-TensorFlow介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          开发应用案例
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/ac/intro/01-intro.html" class="nav-link">
  AI常见案例和趋势介绍
</a></li><li class="dropdown-subitem"><a href="/ac/rsintro/01-intro.html" class="nav-link">
  AI应用案例-推荐系统介绍
</a></li><li class="dropdown-subitem"><a href="/ac/aicity/01-intro.html" class="nav-link">
  AI应用案例-智慧城市介绍
</a></li><li class="dropdown-subitem"><a href="/ac/aibigscreen/01-intro.html" class="nav-link">
  AI应用案例-智慧大屏介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">Spring</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">Spring</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          Spring基础知识
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/basic/01-intro.html" class="nav-link">
  Spring-入门介绍
</a></li><li class="dropdown-subitem"><a href="/spring/basic/02-iocaopintro.html" class="nav-link">
  IOC和AOP-原理介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          SpringMVC总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/springmvc/01-intro.html" class="nav-link">
  SpringMVC-入门介绍
</a></li><li class="dropdown-subitem"><a href="/spring/springmvc/02-prinintro.html" class="nav-link">
  SpringMVC-工作原理介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          SpringBoot总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/springboot/03-workprin.html" class="nav-link">
  SpringBoot-工作原理
</a></li><li class="dropdown-subitem"><a href="/spring/springboot/06-startprincodeanalysis.html" class="nav-link">
  启动原理分析和源码解读
</a></li></ul></li><li class="dropdown-item"><h4>
          Spring注解总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/annotation/03-springannprin.html" class="nav-link">
  Spring注解实现原理
</a></li><li class="dropdown-subitem"><a href="/spring/annotation/04-anntotal1.html" class="nav-link">
  Spring注解大全(一)
</a></li></ul></li><li class="dropdown-item"><h4>
          SpringCloud知识介绍
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/spring/springcloud/01-intro.html" class="nav-link">
  SpringCloud-基础介绍
</a></li><li class="dropdown-subitem"><a href="/spring/springcloud/03-prindetail.html" class="nav-link">
  SpringCloud-原理详解
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">框架</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">框架</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          框架基础总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/framework/basic/01-intro.html" class="nav-link">
  框架基础知识介绍
</a></li><li class="dropdown-subitem"><a href="/framework/basic/02-commconceptdiff.html" class="nav-link">
  框架架构组件区别
</a></li><li class="dropdown-subitem"><a href="/framework/basic/03-commconceptrela.html" class="nav-link">
  框架架构组件关系
</a></li><li class="dropdown-subitem"><a href="/framework/basic/06-microserv15.html" class="nav-link">
  常见15种微服务框架
</a></li><li class="dropdown-subitem"><a href="/framework/basic/07-springframethink.html" class="nav-link">
  Spring框架思想总结
</a></li></ul></li><li class="dropdown-item"><h4>
          常用框架总结
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/framework/log/01-intro.html" class="nav-link">
  日志框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/orm/01-intro.html" class="nav-link">
  ORM框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/nio/01-intro.html" class="nav-link">
  NIO框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/netty/01-intro.html" class="nav-link">
  Netty框架-介绍和总结
</a></li><li class="dropdown-subitem"><a href="/framework/nettycase/01-intro.html" class="nav-link">
  Netty案例-介绍和总结
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">架构</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">架构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          架构基础知识
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/architecture/basic/01-intro.html" class="nav-link">
  架构基础知识介绍
</a></li><li class="dropdown-subitem"><a href="/architecture/basic/02-essence.html" class="nav-link">
  架构基本概念和本质
</a></li><li class="dropdown-subitem"><a href="/architecture/microservanddistribute/01-intro.html" class="nav-link">
  微服务架构知识介绍
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">开发</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          开发工具
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dev/tool/01-intro.html" class="nav-link">
  Java开发工具介绍
</a></li><li class="dropdown-subitem"><a href="/dev/tool/05-idea20recommendedplug.html" class="nav-link">
  Idea开发插件推荐
</a></li></ul></li><li class="dropdown-item"><h4>
          开发规范
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dev/standard/01-intro.html" class="nav-link">
  Java开发规范
</a></li><li class="dropdown-subitem"><a href="/dev/designpattern/01-intro.html" class="nav-link">
  Java设计模式
</a></li></ul></li><li class="dropdown-item"><h4>
          开发效率
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/dev/deveffciency/02-commpromethods.html" class="nav-link">
  效率提升常用方法
</a></li><li class="dropdown-subitem"><a href="/dev/deveffciency/09-summary.html" class="nav-link">
  效率提升精华总结
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">综合</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">综合</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          中间件
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/middleware/mq/01-intro.html" class="nav-link">
  MQ消息队列介绍
</a></li><li class="dropdown-subitem"><a href="/es/basic/01-intro.html" class="nav-link">
  ES搜索服务器介绍
</a></li><li class="dropdown-subitem"><a href="/middleware/zookeeper/01-intro.html" class="nav-link">
  Zookeeper介绍
</a></li></ul></li><li class="dropdown-item"><h4>
          综合技能
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/mysqlop/basic/01-intro.html" class="nav-link">
  MySQL运维总结
</a></li><li class="dropdown-subitem"><a href="/operation/linux/01-intro.html" class="nav-link">
  Linux常用命令
</a></li><li class="dropdown-subitem"><a href="/operation/ng/05-ngsum.html" class="nav-link">
  Nginx使用总结
</a></li><li class="dropdown-subitem"><a href="/post/javabasic/01-javabasic.html" class="nav-link">
  求职面试整理
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Language Menu" class="dropdown-title"><span class="title">项目|产品</span> <span class="arrow down"></span></button> <button type="button" aria-label="Language Menu" class="mobile-dropdown-title"><span class="title">项目|产品</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          研发效能介绍
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/projprod/rdefficiencyintro/01-intro.html" class="nav-link">
  研发效能入门介绍
</a></li><li class="dropdown-subitem"><a href="/projprod/rdefficiencyintro/06-efficiencysystem.html" class="nav-link">
  研发效能体系构建
</a></li></ul></li><li class="dropdown-item"><h4>
          研发效能提升
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/projprod/rdeffciencypromote/09-summary.html" class="nav-link">
  研发效能提升精华总结
</a></li><li class="dropdown-subitem"><a href="/projprod/rdeffciencytool/01-intro.html" class="nav-link">
  研发效能系统管理工具
</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/about/aboutme.html" class="nav-link">
  关于
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>AI开发框架-基础介绍</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/intro/01-intro.html" class="sidebar-link">主流AI机器学习框架介绍</a></li><li><a href="/ad/intro/02-javamllibintro.html" class="sidebar-link">Java-机器学习框架介绍</a></li><li><a href="/ad/intro/03-6javamllibintro.html" class="sidebar-link">Java-6大机器学习库介绍</a></li><li><a href="/ad/intro/04-pythonmllibintro.html" class="sidebar-link">Python-机器学习库Top10</a></li><li><a href="/ad/intro/04.1-corepythonmldiff.html" class="sidebar-link">Python-主流机器学习库比较</a></li><li><a href="/ad/intro/05-top10diff.html" class="sidebar-link">AI深度学习框架Top10比较</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>AI开发框架-DL4J介绍</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/dl4jintro/01-intro.html" class="sidebar-link">DL4J-入门知识介绍</a></li><li><a href="/ad/dl4jintro/02-featuressummary.html" class="sidebar-link">DL4J-特性优点总结</a></li><li><a href="/ad/dl4jintro/03-learnsourcerecommend.html" class="sidebar-link">DL4J-学习资源推荐</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>AI开发框架-DL4J案例</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/dl4jcase/01-intro.html" class="sidebar-link">DL4J-开发入门知识介绍</a></li><li><a href="/ad/dl4jcase/02-devcasseintro.html" class="sidebar-link">DL4J-开发案例入门介绍</a></li><li><a href="/ad/dl4jcase/03-trainingmodelandsave.html" class="sidebar-link">DL4J-训练和保存模型</a></li><li><a href="/ad/dl4jcase/04-bpnetclassifier.html" class="sidebar-link">DL4J-BP网络分类器</a></li><li><a href="/ad/dl4jcase/05-facerecognitioncase.html" class="sidebar-link">DL4J-简单人脸识别案例</a></li><li><a href="/ad/dl4jcase/06-casesummary.html" class="sidebar-link">DL4J-案例实战博客连载</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Python机器学习-基础介绍</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/pymlbasic/01-intro.html" class="sidebar-link">Pyhon机器学习-常用工具库</a></li><li><a href="/ad/pymlbasic/02-mathsymbols.html" class="sidebar-link">Pyhon机器学习-数学符号字母</a></li><li><a href="/ad/pymlbasic/03-jupyternotebook.html" class="sidebar-link">机器学习-Jupyter-Notebook用法</a></li><li><a href="/ad/pymlbasic/04-numpyintro.html" class="sidebar-link">Pyhon机器学习-NumPy介绍</a></li><li><a href="/ad/pymlbasic/05-pandasintro.html" class="sidebar-link">Pyhon机器学习-Pandas介绍</a></li><li><a href="/ad/pymlbasic/06-matplotlibintro.html" class="sidebar-link">Pyhon机器学习-Matplotlib介绍</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Python机器学习-入门案例</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/pymlcase/01-intro.html" class="sidebar-link">Python机器学习-入门实践</a></li><li><a href="/ad/pymlcase/02-linearregressioncase.html" class="sidebar-link">Python机器学习-线性回归预测</a></li><li><a href="/ad/pymlcase/03-logisticregressionclassification.html" class="sidebar-link">Python机器学习-逻辑回归分类</a></li><li><a href="/ad/pymlcase/04-svmcase.html" class="sidebar-link">Python机器学习-向量机SVM</a></li><li><a href="/ad/pymlcase/05-decisiontreeandrandomforest.html" class="sidebar-link">Python机器学习-决策树随机森林</a></li><li><a href="/ad/pymlcase/06-kmenascase.html" class="sidebar-link">Python机器学习-K-Means聚类</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>AI开发框架-SKLearn介绍</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/sklearn/01-intro.html" class="sidebar-link">Sklearn-基础入门介绍</a></li><li><a href="/ad/sklearn/02-simplecase.html" class="sidebar-link">Sklearn-简单实战案例</a></li><li><a href="/ad/sklearn/03-summary.html" class="sidebar-link">Sklearn-基础精华总结</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>AI开发框架-Pytorch介绍</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/pytorch/01-intro.html" class="sidebar-link">Pytorch-基础入门介绍</a></li><li><a href="/ad/pytorch/02-install.html" class="sidebar-link">Pytorch-安装过程详解</a></li><li><a href="/ad/pytorch/03-basicsprocedureandcase.html" class="sidebar-link">Pytorch-基本流程案例</a></li><li><a href="/ad/pytorch/04-imagerecognitioncase1.html" class="sidebar-link">Pytorch-图像识别案例(一)</a></li><li><a href="/ad/pytorch/05-imagerecognitioncase2.html" class="sidebar-link">Pytorch-图像识别案例(二)</a></li><li><a href="/ad/pytorch/06-blogrecommend.html" class="sidebar-link">Pytorch-博客连载推荐</a></li><li><a href="/ad/pytorch/07-basicsummay.html" aria-current="page" class="active sidebar-link">Pytorch-基础精华总结</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>AI开发框架-Tensorflow介绍</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/ad/tensorflow/01-intro.html" class="sidebar-link">TensorFlow-基础入门介绍</a></li><li><a href="/ad/tensorflow/02-intsall.html" class="sidebar-link">TensorFlow-安装步骤详解</a></li><li><a href="/ad/tensorflow/03-datastructureandconcept.html" class="sidebar-link">TensorFlow-数据结构及概念</a></li><li><a href="/ad/tensorflow/04-core3function.html" class="sidebar-link">TensorFlow-三大核心功能</a></li><li><a href="/ad/tensorflow/05-simplecase.html" class="sidebar-link">TensorFlow-简单应用案例</a></li><li><a href="/ad/tensorflow/06-blogrecommend.html" class="sidebar-link">TensorFlow-实战博客推荐</a></li><li><a href="/ad/tensorflow/07-summary.html" class="sidebar-link">TensorFlow-精华基础总结</a></li></ul></section></li></ul> </aside> <main class="page page-content-spec" data-v-17815e06><div class="page_article_title_info" data-v-17815e06><div class="page_content_title" data-v-17815e06>Pytorch-基础精华总结</div> <div class="page_content_visit" data-v-17815e06><span data-v-17815e06>更新时间</span> <span style="display:none;" data-v-17815e06>2021-10-07 13:14:39</span>
            
          <span data-v-17815e06>浏览</span> <span style="display:none;" data-v-17815e06>0</span>
            

        </div></div>  <div class="theme-default-content content__default"><div class="custom-block tip"><p class="custom-block-title">TIP</p> <p>本文主要是介绍 Pytorch-基础精华总结 。</p></div> <p></p><div class="table-of-contents"><ul><li><a href="#pytorch学习-1">PyTorch学习（1）</a></li><li><a href="#一、预先善其事-必先利其器-pytorch与cuda对应关系">一、预先善其事，必先利其器-pytorch与cuda对应关系</a></li><li><a href="#二、pytorch相关">二、pytorch相关</a><ul><li><a href="#_1-创建张量">1.创建张量</a></li><li><a href="#_2-维度变换">2.维度变换</a></li><li><a href="#_3-索引切片及数学运算">3.索引切片及数学运算</a></li><li><a href="#_4-autograd-自动求导">4.autograd：自动求导</a></li></ul></li><li><a href="#【-】">【----------------------------】</a></li><li><a href="#pytorch学习-2">PyTorch学习（2）</a></li><li><a href="#_1-numpy与torch的区别与联系">1 Numpy与Torch的区别与联系</a><ul><li><a href="#_1-1-numpy的array与torch的tensor转换">1.1 numpy的array与Torch的tensor转换</a></li><li><a href="#_1-2-torch中的variable">1.2 Torch中的variable</a></li></ul></li><li><a href="#_2-激励函数-activation-function">2 激励函数（Activation Function）</a></li><li><a href="#_3-regression回归-关系拟合回归">3 Regression回归（关系拟合回归）</a></li><li><a href="#_4-classification-分类">4 Classification（分类）</a></li><li><a href="#_5-torch网络">5 Torch网络</a><ul><li><a href="#_5-1-快速搭建torch网络">5.1 快速搭建torch网络</a></li><li><a href="#_5-2-保存和提取网络与参数">5.2 保存和提取网络与参数</a></li><li><a href="#_5-3-批处理">5.3 批处理</a></li><li><a href="#_5-3-优化器optimizer加速神经网络">5.3 优化器optimizer加速神经网络</a></li></ul></li><li><a href="#_6-神经网络分类">6 神经网络分类</a></li><li><a href="#【-】">【----------------------------】</a></li><li><a href="#pytorch学习-总结篇-3-最实用部分">PyTorch学习-总结篇（3）——最实用部分</a></li><li><a href="#一、每个项目代码应该有五个部分-大同小异">一、每个项目代码应该有五个部分（大同小异）</a></li><li><a href="#二、以一个项目示例来进行讲解-mnist手写数据集">二、以一个项目示例来进行讲解（MNIST手写数据集）</a><ul><li><a href="#_1-导包及定义超参数-这步往往是最后才能完成的-因为只有写完了下面-才能知道你要定义什么及用什么包">1.导包及定义超参数（这步往往是最后才能完成的，因为只有写完了下面，才能知道你要定义什么及用什么包）</a></li><li><a href="#_2-数据集读入">2.数据集读入</a></li><li><a href="#_3-模型的搭建">3.模型的搭建</a></li><li><a href="#_4-损失函数、优化器、可视化及继续训练">4.损失函数、优化器、可视化及继续训练</a></li><li><a href="#_5-模型的训练">5.模型的训练</a></li></ul></li><li><a href="#参考文章">参考文章</a></li></ul></div><p></p> <h2 id="pytorch学习-1"><a href="#pytorch学习-1" class="header-anchor">#</a> PyTorch学习（1）</h2> <p>PyTorch学习（1）一、预先善其事，必先利其器-pytorch与cuda对应关系二、pytorch相关1.创建张量2.维度变换3.索引切片及数学运算4.autograd：自动求导</p> <h2 id="一、预先善其事-必先利其器-pytorch与cuda对应关系"><a href="#一、预先善其事-必先利其器-pytorch与cuda对应关系" class="header-anchor">#</a> 一、预先善其事，必先利其器-pytorch与cuda对应关系</h2> <table><thead><tr><th style="text-align:center;">pytorch</th> <th style="text-align:center;">torchvision</th> <th style="text-align:center;">python</th> <th style="text-align:center;">cuda</th></tr></thead> <tbody><tr><td style="text-align:center;">&lt;1.0.1</td> <td style="text-align:center;">0.2.2</td> <td style="text-align:center;">==2.7，&gt;=3.5，&lt;=3.7</td> <td style="text-align:center;">9.0，10.0</td></tr> <tr><td style="text-align:center;">1.1.0</td> <td style="text-align:center;">0.3.0</td> <td style="text-align:center;">==2.7，&gt;=3.5，&lt;=3.7</td> <td style="text-align:center;">9.0，10.0</td></tr> <tr><td style="text-align:center;">1.2.0</td> <td style="text-align:center;">0.4.0</td> <td style="text-align:center;">==2.7，&gt;=3.5，&lt;=3.7</td> <td style="text-align:center;">9.2，10.0</td></tr> <tr><td style="text-align:center;">1.3.0</td> <td style="text-align:center;">0.4.1</td> <td style="text-align:center;">==2.7，&gt;=3.5，&lt;=3.7</td> <td style="text-align:center;">9.2，10.0</td></tr> <tr><td style="text-align:center;">1.3.1</td> <td style="text-align:center;">0.4.2</td> <td style="text-align:center;">==2.7，&gt;=3.5，&lt;=3.7</td> <td style="text-align:center;">9.2，10.0</td></tr> <tr><td style="text-align:center;">1.4.0</td> <td style="text-align:center;">0.5.0</td> <td style="text-align:center;">==2.7，&gt;=3.5，&lt;=3.8</td> <td style="text-align:center;">9.2，10.0</td></tr> <tr><td style="text-align:center;">1.5.0</td> <td style="text-align:center;">0.6.0</td> <td style="text-align:center;">&gt;=3.6</td> <td style="text-align:center;">9.2，10.1，10.2</td></tr> <tr><td style="text-align:center;">1.5.1</td> <td style="text-align:center;">0.6.1</td> <td style="text-align:center;">&gt;=3.6</td> <td style="text-align:center;">9.2，10.1，10.2</td></tr></tbody></table> <p>各个版本最好相对应，不然代码的运行容易出现问题。</p> <h2 id="二、pytorch相关"><a href="#二、pytorch相关" class="header-anchor">#</a> 二、pytorch相关</h2> <h3 id="_1-创建张量"><a href="#_1-创建张量" class="header-anchor">#</a> 1.创建张量</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch


a1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
a2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
b3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
a4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a1的值:'</span><span class="token punctuation">,</span> a1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a1的大小:'</span><span class="token punctuation">,</span> a1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------------'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a2的值:'</span><span class="token punctuation">,</span> a2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a2的大小:'</span><span class="token punctuation">,</span> a2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------------'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a3的值:'</span><span class="token punctuation">,</span> a3<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a3的大小:'</span><span class="token punctuation">,</span> a3<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------------'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b3的值:'</span><span class="token punctuation">,</span> b3<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b3的大小:'</span><span class="token punctuation">,</span> b3<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------------'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a4的值:'</span><span class="token punctuation">,</span> a4<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a4的大小:'</span><span class="token punctuation">,</span> a4<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n 以上为分步定义tensor的值 \n *******************'</span><span class="token punctuation">)</span>

<span class="token comment"># 结果显示</span>
a1的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
a1的大小<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
a2的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a2的大小<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
a3的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.8593</span><span class="token punctuation">,</span>  <span class="token number">0.8400</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7855</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6212</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2771</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9999</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a3的大小<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
b3的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0023</span><span class="token punctuation">,</span> <span class="token number">0.1359</span><span class="token punctuation">,</span> <span class="token number">0.0431</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.9841</span><span class="token punctuation">,</span> <span class="token number">0.4317</span><span class="token punctuation">,</span> <span class="token number">0.2710</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b3的大小<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
a4的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3898</span><span class="token punctuation">,</span> <span class="token number">0.1011</span><span class="token punctuation">,</span> <span class="token number">0.8075</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">0.4289</span><span class="token punctuation">,</span> <span class="token number">0.2972</span><span class="token punctuation">,</span> <span class="token number">0.8072</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a4的大小<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

以上为分步定义tensor的值
<span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">*</span>

   
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'定义的确定数据的float张量:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 与rand的操作类似，构建多维张量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n 以上为直接定义tensor的值 \n *******************'</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.0000</span><span class="token punctuation">,</span>  <span class="token number">2.2000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
定义的确定数据的<span class="token builtin">float</span>张量<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1.0000</span><span class="token punctuation">,</span>  <span class="token number">2.2000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.0000</span><span class="token punctuation">,</span>  <span class="token number">2.2000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span> <span class="token number">3.0000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

以上为直接定义tensor的值
<span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">*</span>


<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 定义未初始化的2行4列的张量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'定义的1行3列的随机float张量:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n 以上为随机(未初始化)定义tensor的值 \n *******************'</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.9758e-43</span><span class="token punctuation">,</span> <span class="token number">0.0000e+00</span><span class="token punctuation">,</span> <span class="token number">0.0000e+00</span><span class="token punctuation">,</span> <span class="token number">0.0000e+00</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.0000e+00</span><span class="token punctuation">,</span> <span class="token number">0.0000e+00</span><span class="token punctuation">,</span> <span class="token number">0.0000e+00</span><span class="token punctuation">,</span> <span class="token number">0.0000e+00</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
定义的<span class="token number">1</span>行<span class="token number">3</span>列的随机<span class="token builtin">float</span>张量<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0000e+00</span><span class="token punctuation">,</span> <span class="token number">0.0000e+00</span><span class="token punctuation">,</span> <span class="token number">5.3564e-18</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

以上为随机<span class="token punctuation">(</span>未初始化<span class="token punctuation">)</span>定义tensor的值
<span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">*</span>

   
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a1原来的类型:'</span><span class="token punctuation">,</span> a1<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>DoubleTensor<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a1转变后的类型:'</span><span class="token punctuation">,</span> a1<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n 以上为转换默认张量类型 \n *******************'</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
a1原来的类型<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>LongTensor
a1转变后的类型<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>LongTensor

以上为转换默认张量类型
<span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">*</span>

   
a5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
b5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 生成随机的整数张量</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a5的值:'</span><span class="token punctuation">,</span> a5<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b5的值:'</span><span class="token punctuation">,</span> b5<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'将b5作为a5的索引的值:'</span><span class="token punctuation">,</span> a5<span class="token punctuation">[</span>b5<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n 以上为生成随机的整数张量 \n *******************'</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
a5的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5683</span><span class="token punctuation">,</span> <span class="token number">0.6638</span><span class="token punctuation">,</span> <span class="token number">0.6250</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b5的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
将b5作为a5的索引的值<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6638</span><span class="token punctuation">,</span> <span class="token number">0.5683</span><span class="token punctuation">,</span> <span class="token number">0.6250</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

以上为生成随机的整数张量
<span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">*</span>
</code></pre></div><p>扩展：所创建张量的其他相关语句</p> <ul><li><strong>torch.ones(size)/zero(size)/eye(size):</strong> 返回全为1/0/对角单位的张量</li> <li><strong>torch.full(size,fill_value):</strong> 返回以fill_value取值填充的size大小的张量</li> <li><strong>torch.rand(size):</strong> 返回[0，1)之间的均匀分布张量</li> <li><strong>torch.randn(size):</strong> 返回方差为1，均值为0的正态分布张量</li> <li><strong>torch.*_like(input):</strong> 返回和输入大小(几维、几行几列)一样的张量，其中*可以是rand、randn等等</li> <li><strong>torch.linspace(start,end,step=100):</strong> 返回以步长为100的由start到end的一维张量</li> <li><strong>torch.logspace(start,end,steps=100,base=10.0):</strong> 返回以100为步长的由base为底的start次方到end次方的一维张量</li></ul> <h3 id="_2-维度变换"><a href="#_2-维度变换" class="header-anchor">#</a> 2.维度变换</h3> <p>先列一个总纲，具体用法可见代码，顺序与总纲一致</p> <ul><li><strong>tensor.squeeze</strong>（）/<strong>tensor.unsqueeze</strong>（0） 降维/升维</li> <li><strong>tensor.expand</strong>（）/<strong>tensor.repeat</strong>（） 扩展张量</li> <li><strong>tensor.transpose</strong>（）/<strong>tensor.premute</strong>（） 调换张量维度的顺序</li> <li><strong>tensor.cat</strong>（）/<strong>tensor.stack</strong>（） 张量拼接</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y1 <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 在对应索引位置插入一个维度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y1的大小：'</span><span class="token punctuation">,</span> y1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
y2 <span class="token operator">=</span> x<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 删除维度为1的维度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y2的大小：'</span><span class="token punctuation">,</span> y2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
y3 <span class="token operator">=</span> x<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 删除括号数值里对应的索引维度的维度为1的维度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y3的大小：'</span><span class="token punctuation">,</span> y3<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
y1的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y2的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y3的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>



a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的大小：'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
b1 <span class="token operator">=</span> a<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 注意的是expand中的扩展是对某个单一维度（值为1的维度）进行扩展，比如是1行3列，就对行（因为行才是1）进行扩展，列（如果多维，就除要变的不一样，其他必须一样）需要与原数据一致。</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b1的大小：'</span><span class="token punctuation">,</span> b1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
b2 <span class="token operator">=</span> a<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment"># -1表示与原张量维度一致</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b2的大小：'</span><span class="token punctuation">,</span> b2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span>
d1 <span class="token operator">=</span> c<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># repeat是将原张量看成一个整体，对其进行复制操作，例中对第三个维度复制两次，即变成两个，行复制四次，列复制两次，可以不用管维度对应，只管扩张。</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>d1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'d1的大小：'</span><span class="token punctuation">,</span> d1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
d2 <span class="token operator">=</span> c<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 此处是增加一个维度，即整体变成两个，然后里面的一个小块是四个，四个块中的一个又是经过原张量行复制两次，列不复制生成。</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>d2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'d2的大小：'</span><span class="token punctuation">,</span> d2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b1的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b2的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

      <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
d1的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>


      <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
d2的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>




e <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># print(e)</span>
f1 <span class="token operator">=</span> e<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 将指定的维度进行调换，换的只能是两个</span>
<span class="token comment"># print(f1)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'f1的大小：'</span><span class="token punctuation">,</span> f1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
f2 <span class="token operator">=</span> e<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 将所有维度进行括号内的索引顺序转换，转换的个数必须和原张量一样</span>
<span class="token comment"># print(f2)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'f2的大小：'</span><span class="token punctuation">,</span> f2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
f1的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
f2的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>




g1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
g2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>g1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>g2<span class="token punctuation">)</span>
h1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 按行进行同一维度的拼接，如上例，按行拼接拼接后为（6，4）</span>
h2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 沿着一个新的维度对输入张量进行拼接，此处的dim一般为0，不取其他值</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'h1的大小：'</span><span class="token punctuation">,</span> h1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'h2的大小：'</span><span class="token punctuation">,</span> h2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5554</span><span class="token punctuation">,</span>  <span class="token number">0.0449</span><span class="token punctuation">,</span>  <span class="token number">0.1231</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5494</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1639</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.2909</span><span class="token punctuation">,</span>  <span class="token number">2.2580</span><span class="token punctuation">,</span>  <span class="token number">1.5841</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span> <span class="token number">0.1315</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4964</span><span class="token punctuation">,</span>  <span class="token number">0.0706</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9549</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.9899</span><span class="token punctuation">,</span> <span class="token number">0.5225</span><span class="token punctuation">,</span> <span class="token number">0.7383</span><span class="token punctuation">,</span> <span class="token number">0.9421</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.5493</span><span class="token punctuation">,</span> <span class="token number">0.0317</span><span class="token punctuation">,</span> <span class="token number">0.3085</span><span class="token punctuation">,</span> <span class="token number">0.9770</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.5221</span><span class="token punctuation">,</span> <span class="token number">0.0223</span><span class="token punctuation">,</span> <span class="token number">0.2915</span><span class="token punctuation">,</span> <span class="token number">0.7914</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
h1的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
h2的大小： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="_3-索引切片及数学运算"><a href="#_3-索引切片及数学运算" class="header-anchor">#</a> 3.索引切片及数学运算</h3> <div class="language-python extra-class"><pre class="language-python"><code>索引切片：
<span class="token keyword">import</span> torch

a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># 索引</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的前两个维度的索引：'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的具体值索引：'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 切片</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的第一个维度进行切片：'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的每个维度进行切片：'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># ...的用法</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment"># 掩码取值</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
mask <span class="token operator">=</span> x<span class="token punctuation">.</span>ge<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># 与0.5比较，大的为Ture，小的为False</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 挑选出里面为True的值并打印</span>

<span class="token comment"># 通过torch.take取值</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>take<span class="token punctuation">(</span>y<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y的取值：'</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y1的取值：'</span><span class="token punctuation">,</span> y1<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 索引结果</span>
a的前两个维度的索引： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a的具体值索引： tensor<span class="token punctuation">(</span><span class="token number">0.8660</span><span class="token punctuation">)</span>
<span class="token comment"># 切片结果</span>
a的第一个维度进行切片： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a的每个维度进行切片： torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># ...的用法结果</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 掩码取值结果</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5534</span><span class="token punctuation">,</span> <span class="token number">0.1831</span><span class="token punctuation">,</span> <span class="token number">0.9449</span><span class="token punctuation">,</span> <span class="token number">0.6261</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.4419</span><span class="token punctuation">,</span> <span class="token number">0.2026</span><span class="token punctuation">,</span> <span class="token number">0.4816</span><span class="token punctuation">,</span> <span class="token number">0.0258</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.7853</span><span class="token punctuation">,</span> <span class="token number">0.9431</span><span class="token punctuation">,</span> <span class="token number">0.7531</span><span class="token punctuation">,</span> <span class="token number">0.2443</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5534</span><span class="token punctuation">,</span> <span class="token number">0.9449</span><span class="token punctuation">,</span> <span class="token number">0.6261</span><span class="token punctuation">,</span> <span class="token number">0.7853</span><span class="token punctuation">,</span> <span class="token number">0.9431</span><span class="token punctuation">,</span> <span class="token number">0.7531</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 通过torch.take取值结果</span>
y的取值： tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y1的取值： tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>加、减、乘：</p> <ul><li><strong>torch.add</strong>（） 加法</li> <li><strong>torch.sub</strong>（） 减法</li> <li><strong>torch.mul</strong>/<strong>mm</strong>/<strong>bmm</strong>/<strong>matmul</strong>（） 乘法</li></ul> <div class="language-python extra-class"><pre class="language-python"><code>数学运算：
<span class="token keyword">import</span> torch

<span class="token comment">#加、减、乘</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>

c1 <span class="token operator">=</span> a <span class="token operator">+</span> b
c2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'直接用加号结果：'</span><span class="token punctuation">,</span> c1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'使用add结果：'</span><span class="token punctuation">,</span> c2<span class="token punctuation">)</span>

d1 <span class="token operator">=</span> a <span class="token operator">-</span> b
d2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'直接用减号结果：'</span><span class="token punctuation">,</span> d1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'使用sub结果：'</span><span class="token punctuation">,</span> d2<span class="token punctuation">)</span>

c <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
d <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
e <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
f <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
e1 <span class="token operator">=</span> a <span class="token operator">*</span> b
e2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>  <span class="token comment"># 点乘，当a,b维度不一样可以自己复制填充不够的然后相乘，对位相乘</span>
e3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>e<span class="token punctuation">,</span> f<span class="token punctuation">)</span>   <span class="token comment"># 针对二维矩阵，要满足矩阵乘法规则</span>
e4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>c<span class="token punctuation">,</span> d<span class="token punctuation">)</span>  <span class="token comment"># 输入，即括号内的张量必须是三维的，且满足第一个（x,y,z），第二个必须(x,z,随意)</span>
e5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>c<span class="token punctuation">,</span> d<span class="token punctuation">)</span>  <span class="token comment"># 具有广播效果，矩阵维度不一样时，自动填充，然后相乘，但需要相乘矩阵最后两个维度满足矩阵乘法法则</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>e1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>e2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>e3<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>e4<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>e5<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
直接用加号结果： tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.9060</span><span class="token punctuation">,</span> <span class="token number">1.1983</span><span class="token punctuation">,</span> <span class="token number">1.1655</span><span class="token punctuation">,</span> <span class="token number">1.2972</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">1.6351</span><span class="token punctuation">,</span> <span class="token number">0.3494</span><span class="token punctuation">,</span> <span class="token number">0.8485</span><span class="token punctuation">,</span> <span class="token number">1.0029</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">1.8000</span><span class="token punctuation">,</span> <span class="token number">0.4619</span><span class="token punctuation">,</span> <span class="token number">0.9559</span><span class="token punctuation">,</span> <span class="token number">0.7184</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
使用add结果： tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.9060</span><span class="token punctuation">,</span> <span class="token number">1.1983</span><span class="token punctuation">,</span> <span class="token number">1.1655</span><span class="token punctuation">,</span> <span class="token number">1.2972</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">1.6351</span><span class="token punctuation">,</span> <span class="token number">0.3494</span><span class="token punctuation">,</span> <span class="token number">0.8485</span><span class="token punctuation">,</span> <span class="token number">1.0029</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">1.8000</span><span class="token punctuation">,</span> <span class="token number">0.4619</span><span class="token punctuation">,</span> <span class="token number">0.9559</span><span class="token punctuation">,</span> <span class="token number">0.7184</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
直接用减号结果： tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8189</span><span class="token punctuation">,</span>  <span class="token number">0.7739</span><span class="token punctuation">,</span>  <span class="token number">0.7891</span><span class="token punctuation">,</span>  <span class="token number">0.2740</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0898</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0749</span><span class="token punctuation">,</span>  <span class="token number">0.4722</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0202</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span> <span class="token number">0.0752</span><span class="token punctuation">,</span>  <span class="token number">0.0375</span><span class="token punctuation">,</span>  <span class="token number">0.5796</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3047</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
使用sub结果： tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8189</span><span class="token punctuation">,</span>  <span class="token number">0.7739</span><span class="token punctuation">,</span>  <span class="token number">0.7891</span><span class="token punctuation">,</span>  <span class="token number">0.2740</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0898</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0749</span><span class="token punctuation">,</span>  <span class="token number">0.4722</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0202</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span> <span class="token number">0.0752</span><span class="token punctuation">,</span>  <span class="token number">0.0375</span><span class="token punctuation">,</span>  <span class="token number">0.5796</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3047</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0376</span><span class="token punctuation">,</span> <span class="token number">0.2092</span><span class="token punctuation">,</span> <span class="token number">0.1839</span><span class="token punctuation">,</span> <span class="token number">0.4019</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.6663</span><span class="token punctuation">,</span> <span class="token number">0.0291</span><span class="token punctuation">,</span> <span class="token number">0.1243</span><span class="token punctuation">,</span> <span class="token number">0.2514</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.8086</span><span class="token punctuation">,</span> <span class="token number">0.0530</span><span class="token punctuation">,</span> <span class="token number">0.1445</span><span class="token punctuation">,</span> <span class="token number">0.1058</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0376</span><span class="token punctuation">,</span> <span class="token number">0.2092</span><span class="token punctuation">,</span> <span class="token number">0.1839</span><span class="token punctuation">,</span> <span class="token number">0.4019</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.6663</span><span class="token punctuation">,</span> <span class="token number">0.0291</span><span class="token punctuation">,</span> <span class="token number">0.1243</span><span class="token punctuation">,</span> <span class="token number">0.2514</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">0.8086</span><span class="token punctuation">,</span> <span class="token number">0.0530</span><span class="token punctuation">,</span> <span class="token number">0.1445</span><span class="token punctuation">,</span> <span class="token number">0.1058</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1087</span><span class="token punctuation">,</span> <span class="token number">0.0323</span><span class="token punctuation">,</span> <span class="token number">0.2181</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.9481</span><span class="token punctuation">,</span>  <span class="token number">3.7797</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.5594</span><span class="token punctuation">,</span>  <span class="token number">0.2444</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">0.3162</span><span class="token punctuation">,</span>  <span class="token number">0.1580</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0066</span><span class="token punctuation">,</span>  <span class="token number">0.0721</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.9481</span><span class="token punctuation">,</span>  <span class="token number">3.7797</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.5594</span><span class="token punctuation">,</span>  <span class="token number">0.2444</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span> <span class="token number">0.3162</span><span class="token punctuation">,</span>  <span class="token number">0.1580</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0066</span><span class="token punctuation">,</span>  <span class="token number">0.0721</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>扩展：</p> <ul><li><strong>torch.exp</strong>（） e的指数幂</li> <li><strong>torch.log</strong>（） 取对数</li> <li><strong>torch.mean</strong> （） 求均值</li> <li><strong>torch.sum</strong> （） 求和</li> <li><strong>torch.max\torch.min</strong> （） 求最大/最小值</li> <li><strong>torch.prod</strong> （） 返回input中所有元素的乘积</li> <li><strong>torch.argmin</strong>（input）/<strong>torch.argmax</strong>（input） 最大值/最小值的索引</li> <li><strong>torch.where</strong>（condition, x, y)） 如果符合条件返回x，不符合返回y</li> <li><strong>torch.gather</strong>（input, dim, index） 沿dim指定的轴收集数据</li> <li><strong>tensor.floor()</strong> 向下取整</li> <li><strong>tensor.pow</strong>() 平方</li> <li><strong>tensor.sqrt</strong>() 开根号</li> <li><strong>tensor.ceil()</strong> 向上取整</li> <li><strong>tensor.round()</strong> 四舍五入</li> <li><strong>tensor.trunc()</strong> 取整数值</li> <li><strong>tensor.frac()</strong> 取小数值</li> <li><strong>tensor.clamp(min,max)</strong> 比最小值小的变成最小值，把比最大值大的变成最大值</li></ul> <h3 id="_4-autograd-自动求导"><a href="#_4-autograd-自动求导" class="header-anchor">#</a> 4.autograd：自动求导</h3> <p>首先，在pytorch中创建张量的形式为：<strong>torch.tensor</strong>(data= , dtype=None（默认） , device=None（默认） , requires_grad=False（默认） )。简单来说，自动求导就是在进行张量定义时，自行的可以进行求导或者说求梯度计算，只要将张量默认输入参数中的requires_gard设置成True，就看进行自动求导了。下面举个例子，简单看一下具体流程：</p> <img src="/assets/img/ad/pytorch/sumx-1.png" alt="wxmp" class="zoom-custom-imgs"> <ul><li>第一种情况，当我们的输出时一个标量时</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span>， <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 为了方便手动计算，我们使用单位矩阵</span>
a <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">2</span>
z <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> a<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x的值'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的值'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'z的值'</span><span class="token punctuation">,</span> z<span class="token punctuation">)</span>

out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>z<span class="token punctuation">)</span>  <span class="token comment"># 此处的out是一个标量，由x的大小可以看出，求均值的分母为x的个数</span>
out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
x的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
a的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
z的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MulBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>上面代码中out被我们定义为：</p> <img src="/assets/img/ad/pytorch/sumx-2.png" alt="wxmp" class="zoom-custom-imgs"> <p>所以求导很容易看出：</p> <img src="/assets/img/ad/pytorch/sumx-3.png" alt="wxmp" class="zoom-custom-imgs"> <ul><li>第二种情况，当我们的输出是一个向量时</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> copy

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 为了方便手动计算，我们使用单位矩阵</span>
a <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">2</span>
z <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> a<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x的值'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的值'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'z的值'</span><span class="token punctuation">,</span> z<span class="token punctuation">)</span>

gradients1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>  <span class="token comment"># 要注意的是这里的参数要与out的维度保持一致</span>
z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradients1<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 此处是为了保证最后输出的行数，以此类推，几个gradients就是几行</span>
A_temp <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>

gradients2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradients2<span class="token punctuation">)</span>
B_temp <span class="token operator">=</span> x<span class="token punctuation">.</span>grad
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>A_temp<span class="token punctuation">,</span> B_temp<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
x的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
a的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
z的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MulBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.8000</span><span class="token punctuation">,</span> <span class="token number">18.0000</span><span class="token punctuation">,</span>  <span class="token number">0.1800</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">18.0000</span><span class="token punctuation">,</span> <span class="token number">18.0000</span><span class="token punctuation">,</span> <span class="token number">18.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><p>这里我们传入的参数看成行向量，与对应的雅可比矩阵1进行线性操作。</p> <ul><li>第三种情况，当我们输出为一个矩阵时</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 为了方便手动计算，我们使用单位矩阵</span>
a <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">2</span>
z <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> a<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x的值'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a的值'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'z的值'</span><span class="token punctuation">,</span> z<span class="token punctuation">)</span>

gradients <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradients<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
x的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
a的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
z的值 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MulBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="【-】"><a href="#【-】" class="header-anchor">#</a> 【----------------------------】</h2> <h2 id="pytorch学习-2"><a href="#pytorch学习-2" class="header-anchor">#</a> PyTorch学习（2）</h2> <p><strong>这里是根据莫凡pytorch学习的，与pytorch学习（1）可能有所重叠，但是大部分不太一样，可以结合着一起看</strong></p> <h2 id="_1-numpy与torch的区别与联系"><a href="#_1-numpy与torch的区别与联系" class="header-anchor">#</a> 1 Numpy与Torch的区别与联系</h2> <h3 id="_1-1-numpy的array与torch的tensor转换"><a href="#_1-1-numpy的array与torch的tensor转换" class="header-anchor">#</a> 1.1 numpy的array与Torch的tensor转换</h3> <p>1）数据类型转换</p> <p>注：torch只处理二维数据</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

np_data <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
torch_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np_data<span class="token punctuation">)</span>
tensor2array <span class="token operator">=</span> torch_data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nnp_data'</span><span class="token punctuation">,</span> np_data<span class="token punctuation">,</span>
     <span class="token string">'\ntorch_data'</span><span class="token punctuation">,</span> torch_data<span class="token punctuation">,</span>
     <span class="token string">'\ntensor2array'</span><span class="token punctuation">,</span> tensor2array<span class="token punctuation">,</span> <span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
np_data <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
torch_data tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
tensor2array <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre></div><p>2）矩阵乘法</p> <div class="language-python extra-class"><pre class="language-python"><code>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\nnumpy'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>data<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">,</span>
     <span class="token string">'\ntorch'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> tensor<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
numpy <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">5</span>  <span class="token number">8</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span> <span class="token number">8</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
torch tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
注意的是torch中默认的tensor是<span class="token builtin">float</span>形式的
</code></pre></div><h3 id="_1-2-torch中的variable"><a href="#_1-2-torch中的variable" class="header-anchor">#</a> 1.2 Torch中的variable</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable

tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
variable <span class="token operator">=</span> Variable<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

t_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>tensor<span class="token operator">*</span>tensor<span class="token punctuation">)</span>
v_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>variable<span class="token operator">*</span>variable<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'tensor'</span><span class="token punctuation">,</span> tensor<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'variable'</span><span class="token punctuation">,</span> variable<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'t_out'</span><span class="token punctuation">,</span> t_out<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'v_out'</span><span class="token punctuation">,</span> v_out<span class="token punctuation">)</span>

v_out<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 反向传播</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'grad'</span><span class="token punctuation">,</span> variable<span class="token punctuation">.</span>grad<span class="token punctuation">)</span>  <span class="token comment"># variable的梯度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>variable<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
tensor tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
variable tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
t_out tensor<span class="token punctuation">(</span><span class="token number">7.5000</span><span class="token punctuation">)</span>
v_out tensor<span class="token punctuation">(</span><span class="token number">7.5000</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MeanBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
grad tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.5000</span><span class="token punctuation">,</span> <span class="token number">1.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token number">1.5000</span><span class="token punctuation">,</span> <span class="token number">2.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre></div><h2 id="_2-激励函数-activation-function"><a href="#_2-激励函数-activation-function" class="header-anchor">#</a> 2 激励函数（Activation Function）</h2> <p>对于多层神经网络，激励函数的选择有一定窍门</p> <p>推荐网络与激活函数的对应：</p> <ul><li>CNN-relu</li> <li>RNN-relu/tanh</li></ul> <p>有三种常用激活函数：(这里说的是线图)</p> <p>relu、sigmoid、tanh</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span>  <span class="token comment"># 从-5~5分成200段</span>
x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x_np <span class="token operator">=</span> x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

y_relu <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
y_sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
y_tanh <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">311</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_np<span class="token punctuation">,</span> y_relu<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">312</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_np<span class="token punctuation">,</span> y_sigmoid<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'g'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">313</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_np<span class="token punctuation">,</span> y_tanh<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1.2</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
</code></pre></div><img src="/assets/img/ad/pytorch/sum/1740792-20201109074425019-1118262356.jpg" alt="wxmp" class="zoom-custom-imgs"> <h2 id="_3-regression回归-关系拟合回归"><a href="#_3-regression回归-关系拟合回归" class="header-anchor">#</a> 3 Regression回归（关系拟合回归）</h2> <p>一般分为两种：</p> <ul><li>回归问题：一堆数据出一条线</li> <li>分类问题：一堆数据进行分类</li></ul> <p>我们讲的是回归问题：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 一维变二维</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.2</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x<span class="token punctuation">,</span> y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>y<span class="token punctuation">)</span>

<span class="token comment"># plt.scatter(x.data.numpy(), y.data.numpy())</span>
<span class="token comment"># plt.show()</span>

<span class="token comment"># 搭建网络</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_features<span class="token punctuation">,</span> n_hidden <span class="token punctuation">,</span> n_output<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
       <span class="token comment"># 以上为固定的初始化</span>
       self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_features<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_output<span class="token punctuation">)</span>

   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
       x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
       x <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       <span class="token keyword">return</span> x

net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 1个输入点，10个隐藏层的节点，1个输出</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>ion<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 可视化</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
loss_function <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 回归问题用均方误差，分类问题用其他的误差损失函数</span>

<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   out <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
   loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>out<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># 预测值在前真实值在后</span>
   optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
   loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
   optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
   <span class="token keyword">if</span> t <span class="token operator">%</span> <span class="token number">5</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
       plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
       plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
       plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
       plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'Loss=%.4f'</span> <span class="token operator">%</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'size'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">'color'</span><span class="token punctuation">:</span> <span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
       plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>ioff<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
Net<span class="token punctuation">(</span>
<span class="token punctuation">(</span>hidden<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>predict<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre></div><p>最终输出的结果图：</p> <img src="/assets/img/ad/pytorch/sum/1740792-20201109074424717-1807317857.jpg" alt="wxmp" class="zoom-custom-imgs"> <h2 id="_4-classification-分类"><a href="#_4-classification-分类" class="header-anchor">#</a> 4 Classification（分类）</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

n_data <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
x0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>n_data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>n_data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>x0<span class="token punctuation">,</span> x1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>y0<span class="token punctuation">,</span> y1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">)</span>

x<span class="token punctuation">,</span> y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>y<span class="token punctuation">)</span>

<span class="token comment"># plt.scatter(x.data.numpy(), y.data.numpy())</span>
<span class="token comment"># plt.show()</span>

<span class="token comment"># 搭建网络</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_features<span class="token punctuation">,</span> n_hidden <span class="token punctuation">,</span> n_output<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
       <span class="token comment"># 以上为固定的初始化</span>
       self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_features<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_output<span class="token punctuation">)</span>

   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
       x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
       x <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       <span class="token keyword">return</span> x

net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 2个输入点，10个隐藏层的节点，2个输出</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>ion<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 可视化</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
loss_function <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 训练的步数</span>
   out <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
   loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>out<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># 预测值在前真实值在后</span>
   optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
   loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
   optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
   <span class="token keyword">if</span> t <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
       plt<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span>
       out <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>out<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
       prediction <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>out<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># 如果索引为1则为最大值所在位置，如果为0，则为最大值本身</span>
       pred_y <span class="token operator">=</span> prediction<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
       target_y <span class="token operator">=</span> y<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
       plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>pred_y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
       accuracy <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>pred_y <span class="token operator">==</span> target_y<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">200</span>
       plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'Accuracy=%.4f'</span> <span class="token operator">%</span> accuracy<span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'size'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">'color'</span><span class="token punctuation">:</span> <span class="token string">'red'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
       plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>ioff<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
</code></pre></div><img src="/assets/img/ad/pytorch/sum/1740792-20201109074424400-813208365.jpg" alt="wxmp" class="zoom-custom-imgs"> <h2 id="_5-torch网络"><a href="#_5-torch网络" class="header-anchor">#</a> 5 Torch网络</h2> <h3 id="_5-1-快速搭建torch网络"><a href="#_5-1-快速搭建torch网络" class="header-anchor">#</a> 5.1 快速搭建torch网络</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 搭建网络</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_features<span class="token punctuation">,</span> n_hidden <span class="token punctuation">,</span> n_output<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
       <span class="token comment"># 以上为固定的初始化</span>
       self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_features<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_output<span class="token punctuation">)</span>

   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
       x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
       x <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       <span class="token keyword">return</span> x

net1 <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 2个输入点，10个隐藏层的节点，2个输出</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net1<span class="token punctuation">)</span>

net2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
   torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
   torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
   torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net2<span class="token punctuation">)</span>
</code></pre></div><p>这里的net1与net2其实是一样的，其中多数用第二种方式进行模型搭建，net2与tensorflow中的搭建方式一样。</p> <h3 id="_5-2-保存和提取网络与参数"><a href="#_5-2-保存和提取网络与参数" class="header-anchor">#</a> 5.2 保存和提取网络与参数</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 一维变二维</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.2</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x<span class="token punctuation">,</span> y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>x<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>y<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># 当requires_grade为False时，不用求梯度</span>

<span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   net1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
       torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
       torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
       torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">)</span>
   optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span>
   loss_function <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

   <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 训练的步数</span>
       prediction <span class="token operator">=</span> net1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># 预测值在前真实值在后</span>
       optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
       loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
       optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

   torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net1<span class="token punctuation">,</span> <span class="token string">'net.pkl'</span><span class="token punctuation">)</span>  <span class="token comment"># 保存模型</span>
   torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net1<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'net_params.pkl'</span><span class="token punctuation">)</span>  <span class="token comment"># 保存所有节点</span>

   plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">131</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Net1'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> prediction<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">restore_net</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   net2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'net.pkl'</span><span class="token punctuation">)</span>
   prediction <span class="token operator">=</span> net2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">132</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Net2'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> prediction<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">restore_params</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   net3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
       torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
       torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
       torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token punctuation">)</span>
   net3<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'net_params.pkl'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   prediction <span class="token operator">=</span> net3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">133</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Net3'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> prediction<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

save<span class="token punctuation">(</span><span class="token punctuation">)</span>
restore_net<span class="token punctuation">(</span><span class="token punctuation">)</span>
restore_params<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
</code></pre></div><img src="/assets/img/ad/pytorch/sum/1740792-20201109074423973-39184794.jpg" alt="wxmp" class="zoom-custom-imgs"> <h3 id="_5-3-批处理"><a href="#_5-3-批处理" class="header-anchor">#</a> 5.3 批处理</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data

BATCH_SIZE <span class="token operator">=</span> <span class="token number">5</span>  <span class="token comment"># 一小批5个训练</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

torch_dataset <span class="token operator">=</span> Data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
   dataset<span class="token operator">=</span>torch_dataset<span class="token punctuation">,</span>
   batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span>
   shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
   num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>  <span class="token comment"># shuffle就是定义是否打乱数据顺序， num_workers就是用几个线程进行提取</span>

<span class="token keyword">def</span> <span class="token function">show_batch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 总体训练三次</span>
       <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: '</span><span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> <span class="token string">'| Step: '</span><span class="token punctuation">,</span> step<span class="token punctuation">,</span> <span class="token string">'| batch x: '</span><span class="token punctuation">,</span> batch_x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'| batch y: '</span><span class="token punctuation">,</span> batch_y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
   show_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>
   
<span class="token comment">#结果显示</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> Step<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> batch x<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span>  <span class="token number">1</span><span class="token punctuation">.</span>  <span class="token number">2</span><span class="token punctuation">.</span>  <span class="token number">9</span><span class="token punctuation">.</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">|</span> batch y<span class="token punctuation">:</span> <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">10</span><span class="token punctuation">.</span>  <span class="token number">9</span><span class="token punctuation">.</span>  <span class="token number">2</span><span class="token punctuation">.</span>  <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> Step<span class="token punctuation">:</span>  <span class="token number">1</span> <span class="token operator">|</span> batch x<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span> <span class="token number">7</span><span class="token punctuation">.</span> <span class="token number">6</span><span class="token punctuation">.</span> <span class="token number">3</span><span class="token punctuation">.</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">|</span> batch y<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span> <span class="token number">4</span><span class="token punctuation">.</span> <span class="token number">5</span><span class="token punctuation">.</span> <span class="token number">8</span><span class="token punctuation">.</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">1</span> <span class="token operator">|</span> Step<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> batch x<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">2</span><span class="token punctuation">.</span> <span class="token number">7</span><span class="token punctuation">.</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">|</span> batch y<span class="token punctuation">:</span> <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">.</span> <span class="token number">10</span><span class="token punctuation">.</span>  <span class="token number">9</span><span class="token punctuation">.</span>  <span class="token number">4</span><span class="token punctuation">.</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">1</span> <span class="token operator">|</span> Step<span class="token punctuation">:</span>  <span class="token number">1</span> <span class="token operator">|</span> batch x<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span>  <span class="token number">4</span><span class="token punctuation">.</span>  <span class="token number">9</span><span class="token punctuation">.</span>  <span class="token number">8</span><span class="token punctuation">.</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">|</span> batch y<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">7</span><span class="token punctuation">.</span> <span class="token number">2</span><span class="token punctuation">.</span> <span class="token number">3</span><span class="token punctuation">.</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">2</span> <span class="token operator">|</span> Step<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> batch x<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span>  <span class="token number">7</span><span class="token punctuation">.</span>  <span class="token number">1</span><span class="token punctuation">.</span>  <span class="token number">5</span><span class="token punctuation">.</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">|</span> batch y<span class="token punctuation">:</span> <span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span>  <span class="token number">4</span><span class="token punctuation">.</span> <span class="token number">10</span><span class="token punctuation">.</span>  <span class="token number">6</span><span class="token punctuation">.</span>  <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">2</span> <span class="token operator">|</span> Step<span class="token punctuation">:</span>  <span class="token number">1</span> <span class="token operator">|</span> batch x<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">.</span> <span class="token number">3</span><span class="token punctuation">.</span> <span class="token number">8</span><span class="token punctuation">.</span> <span class="token number">6</span><span class="token punctuation">.</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token operator">|</span> batch y<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span> <span class="token number">8</span><span class="token punctuation">.</span> <span class="token number">3</span><span class="token punctuation">.</span> <span class="token number">5</span><span class="token punctuation">.</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
</code></pre></div><h3 id="_5-3-优化器optimizer加速神经网络"><a href="#_5-3-优化器optimizer加速神经网络" class="header-anchor">#</a> 5.3 优化器optimizer加速神经网络</h3> <ul><li><p>所有的优化器都是更新我们神经网络的参数，例传统更新方法：</p></li> <li><p>Adam方法</p></li></ul> <p>m为下坡属性，v为阻力属性</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
<span class="token comment"># from torch.autograd import Variable</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

LR <span class="token operator">=</span> <span class="token number">0.02</span>
BATH_SIZE <span class="token operator">=</span> <span class="token number">32</span>
EPOCH <span class="token operator">=</span> <span class="token number">12</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0.1</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token operator">*</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># plt.scatter(x.numpy(), y.numpy())</span>
<span class="token comment"># plt.show()</span>

torch_dataset <span class="token operator">=</span> Data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>torch_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># class Net(torch.nn.Module):</span>
<span class="token comment">#     def __init__(self, n_features=1, n_hidden=20 , n_output=1):</span>
<span class="token comment">#         super(Net, self).__init__()</span>
<span class="token comment">#         # 以上为固定的初始化</span>
<span class="token comment">#         self.hidden = torch.nn.Linear(n_features, n_hidden)</span>
<span class="token comment">#         self.predict = torch.nn.Linear(n_hidden, n_output)</span>
<span class="token comment">#</span>
<span class="token comment">#     def forward(self, x):</span>
<span class="token comment">#         x = torch.relu(self.hidden(x))</span>
<span class="token comment">#         x = self.predict(x)</span>
<span class="token comment">#         return x</span>
net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
   torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
   torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
   torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

net_SGD <span class="token operator">=</span> net
<span class="token comment"># net_Momentum = net</span>
<span class="token comment"># net_RMSprop = net</span>
net_Adam <span class="token operator">=</span> net
nets <span class="token operator">=</span> <span class="token punctuation">[</span>net_SGD<span class="token punctuation">,</span> net_Adam<span class="token punctuation">]</span>

opt_SGD <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net_SGD<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LR<span class="token punctuation">)</span>
<span class="token comment"># opt_Momentum = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.7)</span>
<span class="token comment"># opt_RMSprop = torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=0.9)</span>
opt_Adam <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net_Adam<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LR<span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.99</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
optimizers <span class="token operator">=</span> <span class="token punctuation">[</span>opt_SGD<span class="token punctuation">,</span> opt_Adam<span class="token punctuation">]</span>

loss_func <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
losses_his <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">show_batch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
       <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token comment"># b_x = Variable(batch_x)</span>
           <span class="token comment"># b_y = Variable(batch_y)</span>
           <span class="token keyword">for</span> net<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> l_his <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>nets<span class="token punctuation">,</span> optimizers<span class="token punctuation">,</span> losses_his<span class="token punctuation">)</span><span class="token punctuation">:</span>
               output <span class="token operator">=</span> net<span class="token punctuation">(</span>batch_x<span class="token punctuation">)</span>
               loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span>
               opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
               loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
               opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
               l_his<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
               <span class="token comment"># print('1111', l_his)</span>

   labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> <span class="token string">'Adam'</span><span class="token punctuation">]</span>
   <span class="token keyword">for</span> i<span class="token punctuation">,</span> l_his <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>losses_his<span class="token punctuation">)</span><span class="token punctuation">:</span>
       plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>l_his<span class="token punctuation">,</span> label<span class="token operator">=</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Steps'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
   show_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#结果显示</span>
</code></pre></div><img src="/assets/img/ad/pytorch/sum/1740792-20201109074423617-1668708936.png" alt="wxmp" class="zoom-custom-imgs"> <h2 id="_6-神经网络分类"><a href="#_6-神经网络分类" class="header-anchor">#</a> 6 神经网络分类</h2> <ul><li>CNN 卷积神经网络</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

EPOCH <span class="token operator">=</span> <span class="token number">1</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">50</span>
LR <span class="token operator">=</span> <span class="token number">0.001</span>
DOWNLOAD_MNIST <span class="token operator">=</span> <span class="token boolean">True</span>

train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>
   root<span class="token operator">=</span><span class="token string">'./mnist'</span><span class="token punctuation">,</span>
   train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
   transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 将三维数据压缩成二维的（0， 1）</span>
   download<span class="token operator">=</span>DOWNLOAD_MNIST
<span class="token punctuation">)</span>
<span class="token comment"># print(train_data.data.size())</span>
<span class="token comment"># print(train_data.targets.size())</span>
<span class="token comment"># plt.imshow(train_data.data[0].numpy(), cmap='gray')</span>
<span class="token comment"># plt.title('%i' % train_data.targets[0])</span>
<span class="token comment"># plt.show()</span>

train_loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./mnist/'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>test_data<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>
test_y <span class="token operator">=</span> test_data<span class="token punctuation">.</span>targets<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">CNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span>CNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
           nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>
               in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
               out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>
               kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
               stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
               padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>  <span class="token comment"># padding=(kernel_size-1)/2</span>
          <span class="token punctuation">)</span><span class="token punctuation">,</span>
           nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
           nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
           nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
           nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
           nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
       x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 这里的size就是conv2的输出，-1就是展平</span>
       output <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       <span class="token keyword">return</span> output

cnn <span class="token operator">=</span> CNN<span class="token punctuation">(</span><span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>cnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LR<span class="token punctuation">)</span>
loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">show_batch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
       <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
           <span class="token comment"># b_x = Variable(batch_x)</span>
           <span class="token comment"># b_y = Variable(batch_y)</span>
           output <span class="token operator">=</span> cnn<span class="token punctuation">(</span>batch_x<span class="token punctuation">)</span>
           loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span>
           optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
           loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
           optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

           <span class="token keyword">if</span> step <span class="token operator">%</span> <span class="token number">50</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
               test_output <span class="token operator">=</span> cnn<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
               pred_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>test_output<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
               accuracy <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>pred_y <span class="token operator">==</span> test_y<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
               <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: '</span><span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> <span class="token string">'| train loss: %.4f'</span> <span class="token operator">%</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'| test accuracy: %2f'</span> <span class="token operator">%</span> accuracy<span class="token punctuation">)</span>
   test_output <span class="token operator">=</span> cnn<span class="token punctuation">(</span>test_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
   pred_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>test_output<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
   <span class="token keyword">print</span><span class="token punctuation">(</span>pred_y<span class="token punctuation">,</span> <span class="token string">'prediction number'</span><span class="token punctuation">)</span>
   <span class="token keyword">print</span><span class="token punctuation">(</span>test_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'real number'</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
   show_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
<span class="token number">0</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> train loss<span class="token punctuation">:</span> <span class="token number">2.2959</span> <span class="token operator">|</span> test accuracy<span class="token punctuation">:</span> <span class="token number">0.107000</span>
……
Epoch<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> train loss<span class="token punctuation">:</span> <span class="token number">0.0895</span> <span class="token operator">|</span> test accuracy<span class="token punctuation">:</span> <span class="token number">0.981500</span>
<span class="token punctuation">[</span><span class="token number">7</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">1</span> <span class="token number">4</span> <span class="token number">9</span> <span class="token number">5</span> <span class="token number">9</span><span class="token punctuation">]</span> prediction number
<span class="token punctuation">[</span><span class="token number">7</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">1</span> <span class="token number">4</span> <span class="token number">9</span> <span class="token number">5</span> <span class="token number">9</span><span class="token punctuation">]</span> real number

Process finished <span class="token keyword">with</span> exit code <span class="token number">0</span>

</code></pre></div><ul><li>RNN 循环神经网络（一般用在时间顺序上）</li> <li>LSTM 长短时记忆网络（RNN的一种，就是加了输入输出与中断三个门控单元）</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 分类</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> dsets
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data

EPOCH <span class="token operator">=</span> <span class="token number">1</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">64</span>
TIME_STEP <span class="token operator">=</span> <span class="token number">28</span>
INPUT_SIZE <span class="token operator">=</span> <span class="token number">28</span>
LR <span class="token operator">=</span> <span class="token number">0.01</span>
DOWNLOAD_MNIST <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># 如果下载了mnist数据集则为false，没有则设置为true</span>

train_data <span class="token operator">=</span> dsets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./mnist'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span>DOWNLOAD_MNIST<span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

test_data <span class="token operator">=</span> dsets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./mnist/'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
test_x <span class="token operator">=</span> test_data<span class="token punctuation">.</span>data<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>
test_y <span class="token operator">=</span> test_data<span class="token punctuation">.</span>targets<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">RNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span>RNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

       self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>
           input_size<span class="token operator">=</span>INPUT_SIZE<span class="token punctuation">,</span>
           hidden_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
           num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># hidden层数</span>
           batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># (batch, time_step, input)默认形式</span>
      <span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
       r_out<span class="token punctuation">,</span> <span class="token punctuation">(</span>h_n<span class="token punctuation">,</span> h_c<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>  <span class="token comment"># h_n与h_c表示分线程与主线程的隐藏层，None表示第一个隐藏层是否有</span>
       out <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>r_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
       <span class="token keyword">return</span> out

rnn <span class="token operator">=</span> RNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>rnn<span class="token punctuation">)</span>

<span class="token comment"># 训练</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LR<span class="token punctuation">)</span>
loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">show_batch</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
           output <span class="token operator">=</span> rnn<span class="token punctuation">(</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
           loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
           optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 清零</span>
           loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
           optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 优化器优化</span>

           <span class="token keyword">if</span> step <span class="token operator">%</span> <span class="token number">50</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
               test_output <span class="token operator">=</span> rnn<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
               pred_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>test_output<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
               accuracy <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>pred_y <span class="token operator">==</span> test_y<span class="token punctuation">)</span> <span class="token operator">/</span> test_y<span class="token punctuation">.</span>size
               <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: '</span><span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> <span class="token string">'| train loss: %.4f'</span> <span class="token operator">%</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'| test accuracy: %2f'</span> <span class="token operator">%</span> accuracy<span class="token punctuation">)</span>

   test_output <span class="token operator">=</span> rnn<span class="token punctuation">(</span>test_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   pred_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>test_output<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
   <span class="token keyword">print</span><span class="token punctuation">(</span>pred_y<span class="token punctuation">,</span> <span class="token string">'prediction number'</span><span class="token punctuation">)</span>
   <span class="token keyword">print</span><span class="token punctuation">(</span>test_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'real number'</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
   show_batch<span class="token punctuation">(</span><span class="token punctuation">)</span>
   
<span class="token comment">#结果显示</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> train loss<span class="token punctuation">:</span> <span class="token number">2.2838</span> <span class="token operator">|</span> test accuracy<span class="token punctuation">:</span> <span class="token number">0.089500</span>
Epoch<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> train loss<span class="token punctuation">:</span> <span class="token number">0.9505</span> <span class="token operator">|</span> test accuracy<span class="token punctuation">:</span> <span class="token number">0.600500</span>
……
Epoch<span class="token punctuation">:</span>  <span class="token number">0</span> <span class="token operator">|</span> train loss<span class="token punctuation">:</span> <span class="token number">0.1406</span> <span class="token operator">|</span> test accuracy<span class="token punctuation">:</span> <span class="token number">0.946000</span>
<span class="token punctuation">[</span><span class="token number">7</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">1</span> <span class="token number">4</span> <span class="token number">9</span> <span class="token number">5</span> <span class="token number">9</span><span class="token punctuation">]</span> prediction number
<span class="token punctuation">[</span><span class="token number">7</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">1</span> <span class="token number">4</span> <span class="token number">9</span> <span class="token number">5</span> <span class="token number">9</span><span class="token punctuation">]</span> real number
<span class="token comment"># 回归</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data

torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 设置一个种子，让每个训练的网络初始化相同</span>

TIME_STEP <span class="token operator">=</span> <span class="token number">10</span>
INPUT_SIZE <span class="token operator">=</span> <span class="token number">1</span>
LR <span class="token operator">=</span> <span class="token number">0.02</span>

<span class="token comment"># steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)</span>
<span class="token comment"># x_np = np.sin(steps)</span>
<span class="token comment"># y_np = np.cos(steps)</span>
<span class="token comment"># plt.plot(steps, y_np, 'r-', label='target (cos)')</span>
<span class="token comment"># plt.plot(steps, x_np, 'b-', label='input (sin)')</span>
<span class="token comment"># plt.legend(loc='best')</span>
<span class="token comment"># plt.show()</span>

<span class="token keyword">class</span> <span class="token class-name">RNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span>RNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

       self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>
           input_size<span class="token operator">=</span>INPUT_SIZE<span class="token punctuation">,</span>
           hidden_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>
           num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># hidden层数</span>
           batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># (batch, time_step, input)默认形式</span>
      <span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> h_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
       r_out<span class="token punctuation">,</span> h_state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h_state<span class="token punctuation">)</span>  <span class="token comment"># x包含很多步的，h_state只包含一步</span>
       outs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
       <span class="token keyword">for</span> time_step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>r_out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
           outs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>r_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> time_step<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
       <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>outs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> h_state  <span class="token comment">#</span>

rnn <span class="token operator">=</span> RNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>rnn<span class="token punctuation">)</span>

<span class="token comment"># 训练</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LR<span class="token punctuation">)</span>
loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ion<span class="token punctuation">(</span><span class="token punctuation">)</span>

h_state <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   start<span class="token punctuation">,</span> end <span class="token operator">=</span> step <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token punctuation">(</span>step <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi
   steps <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> TIME_STEP<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
   x_np <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>
   y_np <span class="token operator">=</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>
   x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_np<span class="token punctuation">[</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span>
   y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_np<span class="token punctuation">[</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span>

   prediction<span class="token punctuation">,</span> h_state <span class="token operator">=</span> rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h_state<span class="token punctuation">)</span>
   h_state <span class="token operator">=</span> h_state<span class="token punctuation">.</span>data  <span class="token comment">#</span>
   loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
   optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
   loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
   optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

   plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>steps<span class="token punctuation">,</span> y_np<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>steps<span class="token punctuation">,</span> prediction<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>draw<span class="token punctuation">(</span><span class="token punctuation">)</span>
   plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>ioff<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#结果显示</span>
</code></pre></div><img src="/assets/img/ad/pytorch/sum/1740792-20201109074423000-349510738.png" alt="wxmp" class="zoom-custom-imgs"> <img src="/assets/img/ad/pytorch/sum/1740792-20201109074422472-2101522312.png" alt="wxmp" class="zoom-custom-imgs"> <h2 id="【-】-2"><a href="#【-】-2" class="header-anchor">#</a> 【----------------------------】</h2> <h2 id="pytorch学习-总结篇-3-最实用部分"><a href="#pytorch学习-总结篇-3-最实用部分" class="header-anchor">#</a> PyTorch学习-总结篇（3）——最实用部分</h2> <p>一、每个项目代码应该有五个部分（大同小异）</p> <p>二、以一个项目示例来进行讲解（MNIST手写数据集）</p> <p>1.导包及定义超参数（这步往往是最后才能完成的，因为只有写完了下面，才能知道你要定义什么及用什么包）</p> <p>2.数据集读入</p> <p>3.模型的搭建</p> <p>4.损失函数、优化器、可视化及继续训练</p> <p>5.模型的训练</p> <p><strong>经过（1）和（2）的学习，相信对基础知识有一定的了解，其实如果想快速进行代码书写与项目调试及运行，仅看（3）应该可以让你快速掌握项目的编写规则</strong></p> <h2 id="一、每个项目代码应该有五个部分-大同小异"><a href="#一、每个项目代码应该有五个部分-大同小异" class="header-anchor">#</a> 一、每个项目代码应该有五个部分（大同小异）</h2> <ul><li>首先，一个项目的代码应该是导包及定义我们的超参数</li> <li>然后，将本次项目所需数据集读入，一般包括训练集和测试集两个部分</li> <li>其次，开始搭建我们的网络模型主体框架</li> <li>再然后，是进行模型的损失函数、优化器及可视化操作</li> <li>最后，是进行我们模型的训练及测试</li></ul> <h2 id="二、以一个项目示例来进行讲解-mnist手写数据集"><a href="#二、以一个项目示例来进行讲解-mnist手写数据集" class="header-anchor">#</a> 二、以一个项目示例来进行讲解（MNIST手写数据集）</h2> <h3 id="_1-导包及定义超参数-这步往往是最后才能完成的-因为只有写完了下面-才能知道你要定义什么及用什么包"><a href="#_1-导包及定义超参数-这步往往是最后才能完成的-因为只有写完了下面-才能知道你要定义什么及用什么包" class="header-anchor">#</a> 1.导包及定义超参数（这步往往是最后才能完成的，因为只有写完了下面，才能知道你要定义什么及用什么包）</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment"># -代码界的小菜鸟-</span>

<span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>untils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> tensorboardX <span class="token keyword">import</span> SummaryWriter
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span>transforms

batch_size <span class="token operator">=</span> <span class="token number">64</span>
epochs <span class="token operator">=</span> <span class="token number">10</span>
checkpoints_dir <span class="token operator">=</span> <span class="token string">'./checkpoints'</span>
event_dir <span class="token operator">=</span> <span class="token string">'./event_file'</span>
model_name <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 如果需要加载模型继续训练，则’/10.pth‘</span>
lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span>

<span class="token comment">#检测GPU是否可以使用</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'GPU是否可用：'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 可用为True</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="_2-数据集读入"><a href="#_2-数据集读入" class="header-anchor">#</a> 2.数据集读入</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 实例化数据集Dataset</span>
train_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./dataset/'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./dataset/'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 数据加载器</span>
train_loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># shuffle是否随机打乱顺序</span>
test_loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 保存检查点的地址</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>checkpoints_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>checkpoints_dir<span class="token punctuation">)</span>
</code></pre></div><h3 id="_3-模型的搭建"><a href="#_3-模型的搭建" class="header-anchor">#</a> 3.模型的搭建</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 模型搭建(pytorch框架定义的的神经网络模型都需要继承nn.Module类)</span>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

   <span class="token comment"># 初始化函数，定义了该神经网络的基本结构</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数</span>
       self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 输入为图像（1），即灰度图，输出为20张特征图，卷积和为5*5的正方形</span>
       self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
       self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span>  <span class="token comment"># 定义全连接线性函数：y=Wx+b，并将4*4*20个节点连接到300个节点上</span>
       self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

   <span class="token comment"># 定义神经网络的前向传播函数</span>
   <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
       x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 输入x经过卷积conv1后，再经过一个激活函数更新x</span>
       x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 经过激活函数后，使用2*2的窗口进行最大池化，更新x</span>
       x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
       x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
       x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">*</span> <span class="token number">20</span><span class="token punctuation">)</span>  <span class="token comment"># 利用view函数将张量x变成一维向量的形式，总特征个数不变</span>
       x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 更新后的x经过全连接函数，再经过激活函数，更新x</span>
       x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       <span class="token keyword">return</span> x
   
<span class="token comment"># 模型实例化</span>
model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
</code></pre></div><h3 id="_4-损失函数、优化器、可视化及继续训练"><a href="#_4-损失函数、优化器、可视化及继续训练" class="header-anchor">#</a> 4.损失函数、优化器、可视化及继续训练</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 定义损失函数</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 交叉熵损失函数</span>

<span class="token comment"># 定义优化器</span>
optimzer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>

<span class="token comment"># 可视化处理</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span>event_dir<span class="token punctuation">)</span>

<span class="token comment"># 继续训练</span>
start_epoch <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">if</span> model_name<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'加载模型：'</span><span class="token punctuation">,</span>checkpoints_dir <span class="token operator">+</span> model_name<span class="token punctuation">)</span>
    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>checkpoints_dir <span class="token operator">+</span> model_name<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    optimzer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
</code></pre></div><h3 id="_5-模型的训练"><a href="#_5-模型的训练" class="header-anchor">#</a> 5.模型的训练</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 开始训练</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 模型训练的标志</span>
    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 训练数据，放到GPU上</span>
        target <span class="token operator">=</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 训练标签，放到GPU上</span>

        <span class="token comment"># 前向传播</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>  <span class="token comment"># 计算损失函数</span>

        <span class="token comment"># 反向传播</span>
        optimzer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 首先进行梯度清零</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 反向传播</span>
        optimzer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 更新参数</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Epoch: {} \tLoss:{{:,6f}}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 可视化</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span>tag<span class="token operator">=</span><span class="token string">'train_loss'</span><span class="token punctuation">,</span> scalar_value<span class="token operator">=</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> global_step<span class="token operator">=</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>


    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 模型测试的标志</span>
    test_loss <span class="token operator">=</span> <span class="token number">0</span>
    correct <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> data<span class="token punctuation">,</span> target <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
            data<span class="token punctuation">,</span> target <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
            pred <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 获取最大的对数概率的索引</span>
            correct <span class="token operator">+=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>target<span class="token punctuation">.</span>view_as<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            test_loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'测试集：损失：{:.4f}，精度：{:.2f}%'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_loss<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">.</span> <span class="token operator">*</span> correct <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 可视化</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span>tag<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> scalar_value<span class="token operator">=</span>test_loss<span class="token punctuation">,</span> global_step<span class="token operator">=</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>


    <span class="token comment"># 保存模型</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
        checkpoint <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'model_state_dict'</span><span class="token punctuation">:</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'optimizer_state_dict'</span><span class="token punctuation">:</span> optimzer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> <span class="token string">'%s/%d.pth'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>checkpoints_dir<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
<span class="token comment">#结果显示</span>
GPU是否可用： <span class="token boolean">True</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">1</span>  Loss<span class="token punctuation">:</span><span class="token number">2.264611</span>
测试集：损失：<span class="token number">0.0358</span>，精度：<span class="token number">20.98</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">2</span>  Loss<span class="token punctuation">:</span><span class="token number">2.253827</span>
测试集：损失：<span class="token number">0.0354</span>，精度：<span class="token number">28.34</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">3</span>  Loss<span class="token punctuation">:</span><span class="token number">2.217229</span>
测试集：损失：<span class="token number">0.0349</span>，精度：<span class="token number">39.88</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">4</span>  Loss<span class="token punctuation">:</span><span class="token number">2.233548</span>
测试集：损失：<span class="token number">0.0343</span>，精度：<span class="token number">50.97</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">5</span>  Loss<span class="token punctuation">:</span><span class="token number">2.144451</span>
测试集：损失：<span class="token number">0.0335</span>，精度：<span class="token number">58.34</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">6</span>  Loss<span class="token punctuation">:</span><span class="token number">2.111312</span>
测试集：损失：<span class="token number">0.0325</span>，精度：<span class="token number">64.29</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">7</span>  Loss<span class="token punctuation">:</span><span class="token number">1.988998</span>
测试集：损失：<span class="token number">0.0310</span>，精度：<span class="token number">68.26</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">8</span>  Loss<span class="token punctuation">:</span><span class="token number">1.837759</span>
测试集：损失：<span class="token number">0.0290</span>，精度：<span class="token number">71.13</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">9</span>  Loss<span class="token punctuation">:</span><span class="token number">1.635040</span>
测试集：损失：<span class="token number">0.0264</span>，精度：<span class="token number">72.52</span><span class="token operator">%</span>
Train Epoch<span class="token punctuation">:</span> <span class="token number">10</span>     Loss<span class="token punctuation">:</span><span class="token number">1.344689</span>
测试集：损失：<span class="token number">0.0232</span>，精度：<span class="token number">75.39</span><span class="token operator">%</span>
</code></pre></div><p>可视化步骤：</p> <p>1.打开event_file文件夹，在当前文件夹打开cmd，然后输入tensorboard --logdir &quot;./&quot;，就可以看到：</p> <img src="/assets/img/ad/pytorch/sum/1740792-20201113152300277-852624041.jpg" alt="wxmp" class="zoom-custom-imgs"> <p>2.打开浏览器在 浏览器中输入https://localhost:6006/ 即可显示 ：</p> <img src="/assets/img/ad/pytorch/sum/1740792-20201113152259720-1948360881.jpg" alt="wxmp" class="zoom-custom-imgs"> <div class="language-python extra-class"><pre class="language-python"><code>torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data
</code></pre></div><h2 id="参考文章"><a href="#参考文章" class="header-anchor">#</a> 参考文章</h2> <ul><li>https://www.cnblogs.com/minyuan/p/13958475.html#autoid-1-0-0</li> <li>https://www.cnblogs.com/minyuan/p/13960119.html</li> <li>https://www.cnblogs.com/minyuan/p/13969547.html</li></ul></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新时间:</span> <span class="time">2021-10-07 13:14:39</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/ad/pytorch/06-blogrecommend.html" class="prev">
        Pytorch-博客连载推荐
      </a></span> <span class="next"><a href="/ad/tensorflow/01-intro.html">
        TensorFlow-基础入门介绍
      </a>
      →
    </span></p></div> <div class="page_article_visit_tail" data-v-17815e06><img src="/assets/img/view/visit.png" alt="" data-v-17815e06>
         
        <span style="display:none;" data-v-17815e06>0</span></div> <div class="page_article_comment" data-v-17815e06></div></main> <div class="page-right-index-sidebar" data-v-17815e06><div class="content_index_title" data-v-17815e06>
      Pytorch-基础精华总结
    </div> <div class="page-right-index-toc" data-v-17815e06><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#pytorch学习-1" aria-current="page" class="unactive_index_li" data-v-17815e06>PyTorch学习（1）
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#一、预先善其事-必先利其器-pytorch与cuda对应关系" aria-current="page" class="unactive_index_li" data-v-17815e06>一、预先善其事，必先利其器-pytorch与cuda对应关系
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#二、pytorch相关" aria-current="page" class="unactive_index_li" data-v-17815e06>二、pytorch相关
          </a> <ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_1-创建张量" aria-current="page" class="unactive_index_li" data-v-17815e06>1.创建张量</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_2-维度变换" aria-current="page" class="unactive_index_li" data-v-17815e06>2.维度变换</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_3-索引切片及数学运算" aria-current="page" class="unactive_index_li" data-v-17815e06>3.索引切片及数学运算</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_4-autograd-自动求导" aria-current="page" class="unactive_index_li" data-v-17815e06>4.autograd：自动求导</a></li></ul></li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#【-】" aria-current="page" class="unactive_index_li" data-v-17815e06>【----------------------------】
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#pytorch学习-2" aria-current="page" class="unactive_index_li" data-v-17815e06>PyTorch学习（2）
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_1-numpy与torch的区别与联系" aria-current="page" class="unactive_index_li" data-v-17815e06>1 Numpy与Torch的区别与联系
          </a> <ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_1-1-numpy的array与torch的tensor转换" aria-current="page" class="unactive_index_li" data-v-17815e06>1.1 numpy的array与Torch的tensor转换</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_1-2-torch中的variable" aria-current="page" class="unactive_index_li" data-v-17815e06>1.2 Torch中的variable</a></li></ul></li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_2-激励函数-activation-function" aria-current="page" class="unactive_index_li" data-v-17815e06>2 激励函数（Activation Function）
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_3-regression回归-关系拟合回归" aria-current="page" class="unactive_index_li" data-v-17815e06>3 Regression回归（关系拟合回归）
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_4-classification-分类" aria-current="page" class="unactive_index_li" data-v-17815e06>4 Classification（分类）
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_5-torch网络" aria-current="page" class="unactive_index_li" data-v-17815e06>5 Torch网络
          </a> <ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_5-1-快速搭建torch网络" aria-current="page" class="unactive_index_li" data-v-17815e06>5.1 快速搭建torch网络</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_5-2-保存和提取网络与参数" aria-current="page" class="unactive_index_li" data-v-17815e06>5.2 保存和提取网络与参数</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_5-3-批处理" aria-current="page" class="unactive_index_li" data-v-17815e06>5.3 批处理</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_5-3-优化器optimizer加速神经网络" aria-current="page" class="unactive_index_li" data-v-17815e06>5.3 优化器optimizer加速神经网络</a></li></ul></li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_6-神经网络分类" aria-current="page" class="unactive_index_li" data-v-17815e06>6 神经网络分类
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#【-】-2" aria-current="page" class="unactive_index_li" data-v-17815e06>【----------------------------】
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#pytorch学习-总结篇-3-最实用部分" aria-current="page" class="unactive_index_li" data-v-17815e06>PyTorch学习-总结篇（3）——最实用部分
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#一、每个项目代码应该有五个部分-大同小异" aria-current="page" class="unactive_index_li" data-v-17815e06>一、每个项目代码应该有五个部分（大同小异）
          </a> </li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#二、以一个项目示例来进行讲解-mnist手写数据集" aria-current="page" class="unactive_index_li" data-v-17815e06>二、以一个项目示例来进行讲解（MNIST手写数据集）
          </a> <ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_1-导包及定义超参数-这步往往是最后才能完成的-因为只有写完了下面-才能知道你要定义什么及用什么包" aria-current="page" class="unactive_index_li" data-v-17815e06>1.导包及定义超参数（这步往往是最后才能完成的，因为只有写完了下面，才能知道你要定义什么及用什么包）</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_2-数据集读入" aria-current="page" class="unactive_index_li" data-v-17815e06>2.数据集读入</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_3-模型的搭建" aria-current="page" class="unactive_index_li" data-v-17815e06>3.模型的搭建</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_4-损失函数、优化器、可视化及继续训练" aria-current="page" class="unactive_index_li" data-v-17815e06>4.损失函数、优化器、可视化及继续训练</a></li></ul><ul data-v-17815e06><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#_5-模型的训练" aria-current="page" class="unactive_index_li" data-v-17815e06>5.模型的训练</a></li></ul></li><li data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html#参考文章" aria-current="page" class="unactive_index_li" data-v-17815e06>参考文章
          </a> </li></ul> <div style="height:10px" data-v-17815e06></div></div></div> <div class="page-right-tool-sidebar" data-v-17815e06><div class="tool_bar_div" data-v-17815e06><img src="/assets/img/toolbar/phone.png" class="tool_bar_img_icon" data-v-17815e06> <div data-v-17815e06>手机看</div></div> <div class="tool_bar_div" data-v-17815e06><img src="/assets/img/toolbar/wechat.png" class="tool_bar_img_icon" data-v-17815e06> <div data-v-17815e06>公众号</div></div> <div class="tool_bar_div" data-v-17815e06><img src="/assets/img/toolbar/communication.png" class="tool_bar_img_icon" data-v-17815e06> <div data-v-17815e06>讨论</div></div> <div class="tool_bar_div" data-v-17815e06><img src="/assets/img/toolbar/leftclose.png" class="tool_bar_img_icon" data-v-17815e06> <div data-v-17815e06>左栏</div></div> <div class="tool_bar_div" data-v-17815e06><img src="/assets/img/toolbar/fullscreen.png" class="tool_bar_img_icon" data-v-17815e06> <div data-v-17815e06>全屏</div></div> <div style="display:none;" data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html" aria-current="page" class="router-link-exact-active router-link-active" data-v-17815e06><div class="tool_bar_div" data-v-17815e06><img src="/assets/img/toolbar/prev.png" class="tool_bar_img_icon" data-v-17815e06> <div data-v-17815e06>上一篇</div></div></a></div> <div style="display:none;" data-v-17815e06><a href="/ad/pytorch/07-basicsummay.html" aria-current="page" class="router-link-exact-active router-link-active" data-v-17815e06><div class="tool_bar_div" data-v-17815e06><img src="/assets/img/toolbar/next.png" class="tool_bar_img_icon" data-v-17815e06> <div data-v-17815e06>下一篇</div></div></a></div></div> <div id="qrCodeDiv" class="toolbar_qrcode_unactive" data-v-17815e06><div class=" toolbar_head_tile" data-v-17815e06>扫一扫 手机阅读</div> <img src="" class="img-qrcode" data-v-17815e06> <h5 data-v-17815e06>可分享给好友和朋友圈</h5></div> <div id="wxmpDiv" class="toolbar_wxmp_active" style="display:none;" data-v-17815e06><div class="toolbar_head_tile" data-v-17815e06>扫描关注公众号，回复&quot;资料&quot;，下载相关图书和资料</div> <img src="/assets/img/wx/wxmp.jpg" class="img-wx-mp" data-v-17815e06> <h5 data-v-17815e06>公众号:智能后端和架构</h5></div> <div id="coummpDiv" class="toolbar_communication_active" style="display:none;" data-v-17815e06><div class="toolbar_head_tile" data-v-17815e06>QQ群:569556849 <br data-v-17815e06>问题咨询和技术交流</div> <img src="/assets/img/qq/qqgroup.png" class="img-wx-mp" data-v-17815e06> <h5 data-v-17815e06>PS 备注:智能后端和架构</h5></div> <div class="topDivImg" style="display:none;" data-v-17815e06><img src="/assets/img/toolbar/top.png" class="tool_top_img_icon" data-v-17815e06></div> <div style="display:none" data-v-17815e06><script type="text/javascript" src="https://s9.cnzz.com/z_stat.php?id=1279777129&web_id=1279777129" data-v-17815e06></script></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.db30138a.js" defer></script><script src="/assets/js/5.df8bf371.js" defer></script><script src="/assets/js/1.60d99fe1.js" defer></script><script src="/assets/js/78.f56b2037.js" defer></script>
  </body>
</html>
