(window.webpackJsonp=window.webpackJsonp||[]).push([[323],{838:function(a,t,s){"use strict";s.r(t);var r=s(53),e=Object(r.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("div",{staticClass:"custom-block tip"},[s("p",{staticClass:"custom-block-title"},[a._v("TIP")]),a._v(" "),s("p",[a._v("本文主要是介绍 DataX-工作原理 。")])]),a._v(" "),s("p"),s("div",{staticClass:"table-of-contents"},[s("ul",[s("li",[s("a",{attrs:{href:"#图解-datax-核心设计原理"}},[a._v("图解 DataX 核心设计原理")])]),s("li",[s("a",{attrs:{href:"#设计理念"}},[a._v("设计理念")])]),s("li",[s("a",{attrs:{href:"#架构设计"}},[a._v("架构设计")])]),s("li",[s("a",{attrs:{href:"#核心概念"}},[a._v("核心概念")]),s("ul",[s("li",[s("a",{attrs:{href:"#_1、job"}},[a._v("1、Job")])]),s("li",[s("a",{attrs:{href:"#_2、task-group"}},[a._v("2、Task Group")])]),s("li",[s("a",{attrs:{href:"#_3、task"}},[a._v("3、Task")])]),s("li",[s("a",{attrs:{href:"#_4、channel"}},[a._v("4、Channel")])]),s("li",[s("a",{attrs:{href:"#_5、transformer"}},[a._v("5、Transformer")])])])]),s("li",[s("a",{attrs:{href:"#调度流程"}},[a._v("调度流程")]),s("ul",[s("li",[s("a",{attrs:{href:"#_1、切分策略"}},[a._v("1、切分策略")])]),s("li",[s("a",{attrs:{href:"#_2、公平分配策略"}},[a._v("2、公平分配策略")])])])]),s("li",[s("a",{attrs:{href:"#参考文章"}},[a._v("参考文章")])])])]),s("p"),a._v(" "),s("h2",{attrs:{id:"图解-datax-核心设计原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#图解-datax-核心设计原理"}},[a._v("#")]),a._v(" 图解 DataX 核心设计原理")]),a._v(" "),s("p",[a._v("DataX 是阿里巴巴开源的一个异构数据源离线同步工具，致力于实现包括关系型数据库（MySQL、Oracle 等）、HDFS、Hive、ODPS、HBase、FTP 等各种异构数据源之间稳定高效的数据同步功能。")]),a._v(" "),s("p",[a._v("前段时间我在 K8s 相关文章中有提到过数据同步的项目，该项目就是基于 DataX 内核构建的，由于公司数据同步的需求，还需要在 DataX 原有的基础上支持增量同步功能，同时支持分布式调度，在「"),s("a",{attrs:{href:"https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzU3MjQ1ODcwNQ%3D%3D%26mid%3D2247485432%26idx%3D1%26sn%3De038dd6d188687c1f113eb6adf8c637f%26scene%3D21%23wechat_redirect",target:"_blank",rel:"noopener noreferrer"}},[a._v("使用 K8s 进行作业调度实战分享"),s("OutboundLink")],1),a._v("」这篇文章中已经详细描述其中的实现。")]),a._v(" "),s("p",[a._v("基于我在项目中对 DataX 的实践过程，给大家分享我所理解的 DataX 核心设计原理。")]),a._v(" "),s("h2",{attrs:{id:"设计理念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#设计理念"}},[a._v("#")]),a._v(" 设计理念")]),a._v(" "),s("p",[a._v("异构数据源离线同步是将源端数据同步到目的端，但是端与端的数据源类型种类繁多，在没有 DataX 之前，端与端的链路将组成一个复杂的网状结构，非常零散无法将同步核心逻辑抽象出来，DataX 的理念就是作为一个同步核心载体连接连接各类数据源，当我们需要数据同步时，只需要以插件的形式接入到 DataX 即可，将复杂的网状结构链路变成了一个星型结构，如下图所示：")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-1.png"),alt:"wxmp"}}),a._v(" "),s("h2",{attrs:{id:"架构设计"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#架构设计"}},[a._v("#")]),a._v(" 架构设计")]),a._v(" "),s("p",[a._v("用过 IDEA 的小伙都知道，IDEA 有很多非常棒的插件，用户可根据自身编程需求，下载相关的插件，DataX 也是使用这种可插拔的设计，采用了 Framework + Plugin 的架构设计，如下图所示：")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-2.png"),alt:"wxmp"}}),a._v(" "),s("p",[a._v("有了插件，DataX 可支持任意数据源到数据源，只要实现了 Reader/Writer Plugin，官方已经实现了主流的数据源插件，比如 MySQL、Oracle、SQLServer 等，当然我们也可以开发一个 DataX 插件。")]),a._v(" "),s("h2",{attrs:{id:"核心概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#核心概念"}},[a._v("#")]),a._v(" 核心概念")]),a._v(" "),s("p",[a._v("DataX 核心主要由 Job、Task Group、Task、Channel 等概念组成：")]),a._v(" "),s("h3",{attrs:{id:"_1、job"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1、job"}},[a._v("#")]),a._v(" 1、Job")]),a._v(" "),s("p",[a._v("在 DataX 中用来描述一个源端到一个目的端的同步作业，是 DataX 数据同步面向用户的最小业务单元。一个Job 对应 一个 JobContainer， JobContainer 负责 Job 的全局切分、调度、前置语句和后置语句等工作。")]),a._v(" "),s("h3",{attrs:{id:"_2、task-group"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2、task-group"}},[a._v("#")]),a._v(" 2、Task Group")]),a._v(" "),s("p",[a._v("一组 Task 的集合，根据 DataX 的公平分配策略，公平地分配 Task 到对应的 TaskGroup 中。一个 TaskGroup 对应一个 TaskGroupContainer，负责执行一组 Task。")]),a._v(" "),s("h3",{attrs:{id:"_3、task"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3、task"}},[a._v("#")]),a._v(" 3、Task")]),a._v(" "),s("p",[a._v("Job 的最小执行单元，一个 Job 可根据 Reader 端切分策略，且分成若干个 Task，以便于并发执行。")]),a._v(" "),s("p",[a._v("Job、Task Group、Task 三者之间的关系可以用如下图表示：")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-3.png"),alt:"wxmp"}}),a._v(" "),s("p",[a._v("根据切分策略将一个 Job 切分成多个 Task，根据分配策略将多个 Task 组成一个 TaskGroup。")]),a._v(" "),s("h3",{attrs:{id:"_4、channel"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4、channel"}},[a._v("#")]),a._v(" 4、Channel")]),a._v(" "),s("p",[a._v("DataX 会单独启动一条线程运行运行一个 Task，而 Task 会持有一个 Channel，用作 Reader 与 Writer 的数据传输媒介，DataX 的数据流向都是按照 "),s("code",[a._v("Reader—>Channel—>Writer")]),a._v(" 的方向流转，用如下图表示：")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-4.png"),alt:"wxmp"}}),a._v(" "),s("p",[a._v("Channel 作为传输通道，即能充当缓冲层，同时还能对数据传输进行限流操作。")]),a._v(" "),s("h3",{attrs:{id:"_5、transformer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5、transformer"}},[a._v("#")]),a._v(" 5、Transformer")]),a._v(" "),s("p",[a._v("DataX 的 transformer 模式同时还提供了强大的数据转换功能，DataX 默认提供了丰富的数据转换实现类，用户还可以根据项目自身需求，扩展数据转换。")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-5.png"),alt:"wxmp"}}),a._v(" "),s("h2",{attrs:{id:"调度流程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#调度流程"}},[a._v("#")]),a._v(" 调度流程")]),a._v(" "),s("p",[a._v("DataX 将用户的 job.json 同步作业配置解析成一个 Job，DataX 通过 JobContainer 完成全局切分、调度、前置语句和后置语句等工作，整体调度流程用如下图表示：")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-6.png"),alt:"wxmp"}}),a._v(" "),s("h3",{attrs:{id:"_1、切分策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1、切分策略"}},[a._v("#")]),a._v(" 1、切分策略")]),a._v(" "),s("p",[a._v("1）计算并发量（即 needChannelNumber 大小）")]),a._v(" "),s("p",[a._v("DataX有流控模式，其中，可以设置 bps 限速，tps 限速：")]),a._v(" "),s("ul",[s("li",[a._v("bps 限速：needChannelNumber = 总 byteLimit / 单个 Channel byteLimit")]),a._v(" "),s("li",[a._v("tps 限速：needChannelNumber = 总 recordLimit / 单个 Channel recordLimit")])]),a._v(" "),s("p",[a._v("如果以上都没有设置，则会根据用户在 "),s("code",[a._v("job.setting.speed.channel")]),a._v(" 配置的并发数量设置 needChannelNumber。")]),a._v(" "),s("p",[a._v("2）根据 needChannelNumber 将 Job 切分成多个 Task")]),a._v(" "),s("p",[a._v("这个步骤的具体切分逻辑交由相关插件去完成，例如 Rdb 对数据的拆分主要分成两类：")]),a._v(" "),s("ul",[s("li",[a._v("如果用户配置了具体的 Table 数量，那么就按照 Table 为最小单元进行拆分（即一个 Table 对应一个 Task），并生成对应的 querySql；")]),a._v(" "),s("li",[a._v("如果用户还配置了 splitPk，则会根据 splitPk 进行切分，具体逻辑是根据 splitPk 区间对 Table 进行拆分，并生成对应的 querySql。")])]),a._v(" "),s("h3",{attrs:{id:"_2、公平分配策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2、公平分配策略"}},[a._v("#")]),a._v(" 2、公平分配策略")]),a._v(" "),s("p",[a._v("DataX 在执行调度之前，会调用 "),s("code",[a._v("JobAssignUtil#assignFairly")]),a._v("方法对切分好的 Task 公平分配给每个 TaskGroup。")]),a._v(" "),s("p",[a._v("在分配之前，会计算 TaskGroup 的数量，具体公式：")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("int taskGroupNumber "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("int"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" Math.ceil"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0")]),a._v(" * channelNumber / channelsPerTaskGroup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n")])])]),s("p",[a._v("channelNumber 即为在切分策略中根据用户配置计算得到的 needChannelNumber 并发数量大小，channelsPerTaskGroup 为每个 TaskGroup 需要的并发数量，默认为 5。")]),a._v(" "),s("p",[a._v("求出 TaskGroup 的数量之后，就会执行公平分配策略，将 Task 平均分配个每个 TaskGroup，最后执行调度，完成整个同步作业。举个公平分配策略的例子：")]),a._v(" "),s("p",[a._v("假设 A 库有表 0、1、2，B 库上有表 3、4，C 库上有表 5、6、7，如果此时有 4 个 TaskGroup，则 assign 后的结果为：")]),a._v(" "),s("div",{staticClass:"language-shell extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[a._v("taskGroup-0: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(",  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(",\ntaskGroup-1: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(",  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(",\ntaskGroup-2: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(",  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(",\ntaskGroup-3: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(",  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v("\n")])])]),s("p",[a._v("举个例子来描述 Job、Task、Task Group 之间的关系：")]),a._v(" "),s("p",[a._v("用户构建了一个数据同步作业，该作业的目的是将 MySql 的 100 张表同步到 Oracle 库中，假设此时用户设置了 20 个并发（即 channelNumber=20）：")]),a._v(" "),s("ol",[s("li",[a._v("DataX 根据表的数量切分成 100 个 Task；")]),a._v(" "),s("li",[a._v("DataX 默认给每个 TaskGroup 分配 5 个 Channel，因此 taskGroupNumber = channelNumber / channelsPerTaskGroup = 20 / 5 = 4；")]),a._v(" "),s("li",[a._v("根据 DataX 的公平分配策略，会将 100 个 Task 平均分配给每个 TaskGroup，因此每个 TaskGroup 处理 taskNumber / taskGroupNumber = 100 / 4 = 25 个 Task。")])]),a._v(" "),s("p",[a._v("以上的例子用如下图表示：")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-7.png"),alt:"wxmp"}}),a._v(" "),s("p",[a._v("由于一个 Channel 对应一个线程执行，因此 DataX 的线程模型可以用如下图表示：")]),a._v(" "),s("img",{staticClass:"zoom-custom-imgs",attrs:{src:a.$withBase("/assets/img/dc/datax/prin-8.png"),alt:"wxmp"}}),a._v(" "),s("h2",{attrs:{id:"参考文章"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[a._v("#")]),a._v(" 参考文章")]),a._v(" "),s("ul",[s("li",[a._v("https://my.oschina.net/objcoding/blog/4549885")])])])}),[],!1,null,null,null);t.default=e.exports}}]);