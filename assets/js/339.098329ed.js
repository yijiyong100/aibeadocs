(window.webpackJsonp=window.webpackJsonp||[]).push([[339],{854:function(t,s,a){"use strict";a.r(s);var n=a(53),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("本文主要是介绍 Sqoop-精华总结 。")])]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#sqoop知识总结"}},[t._v("sqoop知识总结")])]),a("li",[a("a",{attrs:{href:"#sqoop"}},[t._v("sqoop")])]),a("li",[a("a",{attrs:{href:"#_1-是什么"}},[t._v("1.是什么")])]),a("li",[a("a",{attrs:{href:"#_2-作业本质"}},[t._v("2.作业本质")]),a("ul",[a("li",[a("a",{attrs:{href:"#数据导入"}},[t._v("数据导入")])]),a("li",[a("a",{attrs:{href:"#数据导出"}},[t._v("数据导出")])])])]),a("li",[a("a",{attrs:{href:"#_3-安装"}},[t._v("3.安装")]),a("ul",[a("li",[a("a",{attrs:{href:"#安装节点"}},[t._v("安装节点")])]),a("li",[a("a",{attrs:{href:"#安装步骤"}},[t._v("安装步骤")])])])]),a("li",[a("a",{attrs:{href:"#_4-命令"}},[t._v("4.命令")]),a("ul",[a("li",[a("a",{attrs:{href:"#将mysql导入hdfs"}},[t._v("将mysql导入hdfs")])]),a("li",[a("a",{attrs:{href:"#将mysql导入hive"}},[t._v("将mysql导入hive")])]),a("li",[a("a",{attrs:{href:"#增量数据导入"}},[t._v("增量数据导入")])]),a("li",[a("a",{attrs:{href:"#将hdfs导出到mysql"}},[t._v("将hdfs导出到mysql")])]),a("li",[a("a",{attrs:{href:"#将hive导出到mysql"}},[t._v("将hive导出到mysql")])]),a("li",[a("a",{attrs:{href:"#将mysql导入hbase"}},[t._v("将mysql导入hbase")])])])]),a("li",[a("a",{attrs:{href:"#参考文章"}},[t._v("参考文章")])])])]),a("p"),t._v(" "),a("h2",{attrs:{id:"sqoop知识总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sqoop知识总结"}},[t._v("#")]),t._v(" sqoop知识总结")]),t._v(" "),a("h2",{attrs:{id:"sqoop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sqoop"}},[t._v("#")]),t._v(" sqoop")]),t._v(" "),a("h2",{attrs:{id:"_1-是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-是什么"}},[t._v("#")]),t._v(" 1.是什么")]),t._v(" "),a("p",[t._v("Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。")]),t._v(" "),a("p",[t._v("Sqoop项目开始于2009年，最早是作为Hadoop的一个第三方模块存在，后来为了让使用者能够快速部署，也为了让开发人员能够更快速的迭代开发，Sqoop独立成为一个Apache项目。")]),t._v(" "),a("p",[t._v("原来大部分数据存储关系型数据库的 mysql或者Oracle，随着数据量的激增，传统的关系型数据存储方案不适合，需要将传统关系型数据库的数据转移到大数据平台存储，即mysql|oracle ----\x3e hadoop。")]),t._v(" "),a("p",[t._v("另外，大数据平台（hadoop）中分析的一些业务指标数据，为了便于web页面的可视化的展示，需要导出到mysql中，即hadoop---\x3emysql|oracle。")]),t._v(" "),a("p",[t._v("总结："),a("strong",[t._v("sqoop就是一个数据迁移工具")])]),t._v(" "),a("h2",{attrs:{id:"_2-作业本质"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-作业本质"}},[t._v("#")]),t._v(" 2.作业本质")]),t._v(" "),a("p",[t._v("sqoop进行数据迁移的本质就是将sqoop命令转换为mapreduce任务进行数据迁移的，即sqoop就是hadoop的另一种形式的客户端。")]),t._v(" "),a("h3",{attrs:{id:"数据导入"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据导入"}},[t._v("#")]),t._v(" 数据导入")]),t._v(" "),a("p",[t._v("mysql|oracle ---\x3e hdfs")]),t._v(" "),a("p",[t._v("map端：DBInputFormat 数据库输入类")]),t._v(" "),a("p",[t._v("context.write();")]),t._v(" "),a("p",[t._v("FileOutputFormat() 指定输出路径 hdfs")]),t._v(" "),a("p",[t._v("只有maptask即可，相当于定制了输入类")]),t._v(" "),a("h3",{attrs:{id:"数据导出"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据导出"}},[t._v("#")]),t._v(" 数据导出")]),t._v(" "),a("p",[t._v("hdfs ---\x3e mysql")]),t._v(" "),a("p",[t._v("map端：FileInputFormat hdfs文件路径")]),t._v(" "),a("p",[t._v("context.write()")]),t._v(" "),a("p",[t._v("DBOutputFormat 将数据写出到mysql中")]),t._v(" "),a("h2",{attrs:{id:"_3-安装"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-安装"}},[t._v("#")]),t._v(" 3.安装")]),t._v(" "),a("h3",{attrs:{id:"安装节点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安装节点"}},[t._v("#")]),t._v(" 安装节点")]),t._v(" "),a("p",[t._v("1个节点，这个节点必须可以访问到大数据平台（hdfs、hive）客户端")]),t._v(" "),a("h3",{attrs:{id:"安装步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#安装步骤"}},[t._v("#")]),t._v(" 安装步骤")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("上传\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("解压\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("tar")]),t._v(" -xvzf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz \n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ln")]),t._v(" -s sqoop-1.4.6.bin__hadoop-2.0.4-alpha sqoop\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("配置环境变量\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("SQOOP_HOME")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/home/hadoop/app/sqoop\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("PATH")])]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("$PATH")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$SQOOP_HOME")]),t._v("/bin\n\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("source")]),t._v(" /etc/profile\n\n验证：\nsqoop version \n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("修改sqoop的配置文件\n/home/hadoop/app/sqoop/conf\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v(" sqoop-env-template.sh sqoop-env.sh\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#hadoop的common安装位置")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_COMMON_HOME")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/home/hadoop/app/hadoop-2.7.6\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#hadoop的核心依赖的安装位置 mapreduce")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_MAPRED_HOME")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/home/hadoop/app/hadoop-2.7.6\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#配置hbase的安装目录")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#export HBASE_HOME=")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#配置hive的安装目录")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HIVE_HOME")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/home/hadoop/app/hive\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#zookeeper的配置文件所在路径的")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("ZOOCFGDIR")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/home/hadoop/app/zookeeper/conf\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("将mysql的驱动包放在sqoop的lib下\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("测试\nlist-databases   查看mysql数据库中的所有数据库\n\nbin/sqoop list-databases "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://cdh01:3306/ "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root\n")])])]),a("h2",{attrs:{id:"_4-命令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-命令"}},[t._v("#")]),t._v(" 4.命令")]),t._v(" "),a("p",[t._v("sqoop help 查看sqoop的帮助文档")]),t._v(" "),a("h3",{attrs:{id:"将mysql导入hdfs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#将mysql导入hdfs"}},[t._v("#")]),t._v(" 将mysql导入hdfs")]),t._v(" "),a("h4",{attrs:{id:"不指定导入hdfs路径"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#不指定导入hdfs路径"}},[t._v("#")]),t._v(" 不指定导入hdfs路径")]),t._v(" "),a("p",[t._v("默认导入的hdfs的路径 /user/hadoop/表名")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\tmysql 用户名\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\tmysql用户密码\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t\t需要导入到hdfs的mysql表名\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t列分割符\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\t\t\t\t\t\t\tmap tasks的并行度\n")])])]),a("h4",{attrs:{id:"指定导入hdfs路径"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#指定导入hdfs路径"}},[t._v("#")]),t._v(" 指定导入hdfs路径")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/sqoop/job"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t指定路径\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("h4",{attrs:{id:"指定导入列"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#指定导入列"}},[t._v("#")]),t._v(" 指定导入列")]),t._v(" "),a("p",[t._v("--columns 指定需要导入的mysql数据库中的列，多列之间用逗号隔开")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--columns "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t指定导入列\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/sqoop/job"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("h4",{attrs:{id:"指定过滤条件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#指定过滤条件"}},[t._v("#")]),t._v(" 指定过滤条件")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--columns "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\n--where "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"age>20"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t指定筛选条件\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/sqoop/job"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("h4",{attrs:{id:"指定sql查询语句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#指定sql查询语句"}},[t._v("#")]),t._v(" 指定sql查询语句")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--query "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'select * from stu where age>20 and "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$CONDITIONS")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t指定sql查询\n--target-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/sqoop/job"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("p",[a("strong",[t._v("注意：--query 和 --table --columns --where不能一起使用的")])]),t._v(" "),a("h4",{attrs:{id:"指定maptask的个数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#指定maptask的个数"}},[t._v("#")]),t._v(" 指定maptask的个数")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--query "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'select * from stu where age>20 and "),a("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$CONDITIONS")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\n--target-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/sqoop/job"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\n--split-by  sid "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v(" \t\t指定每一个maptask切分数据的依据字段\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v("\n每一个maptask数据怎么分配的？\n平均分配  是\nhash分配   否\n")])])]),a("h3",{attrs:{id:"将mysql导入hive"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#将mysql导入hive"}},[t._v("#")]),t._v(" 将mysql导入hive")]),t._v(" "),a("h4",{attrs:{id:"默认导入"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#默认导入"}},[t._v("#")]),t._v(" 默认导入")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\tmysql中的表名\n--target-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/sqoop/job"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-import\t\t\t与导入到hdfs唯一的差别\n")])])]),a("h5",{attrs:{id:"mysql数据导入到hive中的步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mysql数据导入到hive中的步骤"}},[t._v("#")]),t._v(" mysql数据导入到hive中的步骤")]),t._v(" "),a("div",{staticClass:"language-markdown extra-class"},[a("pre",{pre:!0,attrs:{class:"language-markdown"}},[a("code",[t._v("1.首先将mysql中的数据导入到hdfs的默认路径下hdfs://cdh01/user/hadoop/表名\n2.在hive中创建对应的表\n3.将hdfs上的表加载到hive对应的表中  即load data 操作\n")])])]),a("h5",{attrs:{id:"默认导入的hive的库和表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#默认导入的hive的库和表"}},[t._v("#")]),t._v(" 默认导入的hive的库和表")]),t._v(" "),a("div",{staticClass:"language-markdown extra-class"},[a("pre",{pre:!0,attrs:{class:"language-markdown"}},[a("code",[t._v("默认库  default\n默认的表名和mysql中的表名一致\n导入hive表的数据的存储文件列之间的分割符 \\001\n")])])]),a("h4",{attrs:{id:"导入到hive中指定的库和表名"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#导入到hive中指定的库和表名"}},[t._v("#")]),t._v(" 导入到hive中指定的库和表名")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("--fields-terminated-by  指定hive表文件存储的列分割符 最好指定\n--lines-terminated-by   指定hive表文件存储的行之间的分割符\n--hive-overwrite    \t覆盖导入\n--hive-database   \t\t指定导入hive的数据库\n--hive-table   \t\t\t指定导入到hive中的表名\n--create-hive-table \t创建hive中表,如果表不存在则创建\n--delete-target-dir \t删除目标文件\nsqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--lines-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\n"}},[t._v("\\n")]),t._v('"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-import "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-overwrite "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--create-hive-table  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-database test_sqoop "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-table new_stu\n")])])]),a("p",[a("strong",[t._v("注意：mysql导入hive时候，如果指定了--hive-database，需要先手动创建好库。")])]),t._v(" "),a("h3",{attrs:{id:"增量数据导入"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#增量数据导入"}},[t._v("#")]),t._v(" 增量数据导入")]),t._v(" "),a("p",[t._v("每次只导入新增的数据")]),t._v(" "),a("p",[t._v("需要添加三个参数")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("--check-column\t\t指定的增量导入数据的校验建，通常选主键   自增的\n--incremental \t \t指定增量数据导入的类型：append 追加， lastmodified 最后一次修改\n--last-value\t\t知道上一次导入的最后一个校验建的值\n")])])]),a("p",[t._v("案例")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/sqoop/job"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--incremental append "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--check-column  sid "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--last-value "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("h3",{attrs:{id:"将hdfs导出到mysql"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#将hdfs导出到mysql"}},[t._v("#")]),t._v(" 将hdfs导出到mysql")]),t._v(" "),a("p",[t._v("参数解释")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("导出的mysql数据库连接mysql url指定  也可以在表名之前指定\n--table   指定需要导出的mysql中的表\n--export-dir   指定hdfs需要导出的路径\n--fields-terminated-by   指定hdfs文件的列分隔符的\nbin/sqoop "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\n\t\t\t\t\t\t\t\t\t\t\ttest表示mysql中的库名\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table stu2 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t\t\t\t\t导出到mysql中的哪个表，这个表需要先创建好\n--export-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/user/hadoop/stu'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t需要导出的hdfs文件目录\n--fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v("'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--update-key uid "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t\t\t\t根据uid来更新\n--update-mode allowinsert\t\t\t\t\t更新模式：允许插入，如果不存在的话\n")])])]),a("h3",{attrs:{id:"将hive导出到mysql"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#将hive导出到mysql"}},[t._v("#")]),t._v(" 将hive导出到mysql")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t\t\t\t\t\t\t\t导出到mysql的哪个表\n--export-dir "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/user/hive/warehouse/stu'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t需要导出的hive表在hdfs的存储路径\n--input-fields-terminated-by "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),a("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t\t\t指定的是hive表存储文件的列之间的分割符\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n")])])]),a("h3",{attrs:{id:"将mysql导入hbase"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#将mysql导入hbase"}},[t._v("#")]),t._v(" 将mysql导入hbase")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[t._v("bin/sqoop "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'jdbc:mysql://cdh01/test?useUnicode=true&characterEncoding=utf-8'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-m "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-create-table "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t\t自动在hbase中创建\n--hbase-table stu "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--column-family cf "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\t\t\t\t\t指定列簇名字\n--hbase-row-key uid\t\t\t\t\t\t指定rowkey对应的mysql主键\n")])])]),a("p",[a("strong",[t._v("注意：列族只能指定1个")])]),t._v(" "),a("h2",{attrs:{id:"参考文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[t._v("#")]),t._v(" 参考文章")]),t._v(" "),a("ul",[a("li",[t._v("https://www.cnblogs.com/kyle-blog/p/14285848.html")])])])}),[],!1,null,null,null);s.default=e.exports}}]);