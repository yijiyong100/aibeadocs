(window.webpackJsonp=window.webpackJsonp||[]).push([[376],{891:function(t,a,e){"use strict";e.r(a);var s=e(53),r=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("div",{staticClass:"custom-block tip"},[e("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),e("p",[t._v("本文主要是介绍 Mahout-基础知识 。")])]),t._v(" "),e("p"),e("div",{staticClass:"table-of-contents"},[e("ul",[e("li",[e("a",{attrs:{href:"#mahout简介"}},[t._v("Mahout简介")])]),e("li",[e("a",{attrs:{href:"#一、mahout是什么"}},[t._v("一、mahout是什么")]),e("ul",[e("li",[e("a",{attrs:{href:"#mahout主要包含以下5部分"}},[t._v("mahout主要包含以下5部分")])])])]),e("li",[e("a",{attrs:{href:"#二、mahout历史"}},[t._v("二、mahout历史")]),e("ul",[e("li",[e("a",{attrs:{href:"#mahout-的目标还包括"}},[t._v("Mahout 的目标还包括：")])])])]),e("li",[e("a",{attrs:{href:"#三、mahout的特性"}},[t._v("三、mahout的特性")]),e("ul",[e("li",[e("a",{attrs:{href:"#mahout-的主要特性包括"}},[t._v("Mahout 的主要特性包括：")])])])]),e("li",[e("a",{attrs:{href:"#四、mahout当前已实现的三个具体的机器学习任务"}},[t._v("四、mahout当前已实现的三个具体的机器学习任务")]),e("ul",[e("li",[e("a",{attrs:{href:"#_1-、协作筛选"}},[t._v("（1）、协作筛选")])]),e("li",[e("a",{attrs:{href:"#_2-、集群"}},[t._v("（2）、集群")])]),e("li",[e("a",{attrs:{href:"#_3-、分类"}},[t._v("（3）、分类")])])])]),e("li",[e("a",{attrs:{href:"#五、mahout下载"}},[t._v("五、mahout下载")])]),e("li",[e("a",{attrs:{href:"#【-】"}},[t._v("【----------------------------】")])]),e("li",[e("a",{attrs:{href:"#mahout介绍和安装"}},[t._v("Mahout介绍和安装")])]),e("li",[e("a",{attrs:{href:"#简介"}},[t._v("简介")]),e("ul",[e("li",[e("a",{attrs:{href:"#mahout历史演变"}},[t._v("Mahout历史演变")])]),e("li",[e("a",{attrs:{href:"#hadoop家族中mahout的结构图"}},[t._v("Hadoop家族中Mahout的结构图")])]),e("li",[e("a",{attrs:{href:"#mahout在hadoop-平台上的安装"}},[t._v("Mahout在Hadoop 平台上的安装")])])])]),e("li",[e("a",{attrs:{href:"#参考文章"}},[t._v("参考文章")])])])]),e("p"),t._v(" "),e("h2",{attrs:{id:"mahout简介"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mahout简介"}},[t._v("#")]),t._v(" Mahout简介")]),t._v(" "),e("h2",{attrs:{id:"一、mahout是什么"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一、mahout是什么"}},[t._v("#")]),t._v(" 一、mahout是什么")]),t._v(" "),e("p",[t._v("Apache Mahout是ApacheSoftware Foundation （ASF）旗下的一个开源项目，提供了一些经典的机器学习的算法，皆在帮助开发人员更加方便快捷地创建智能应用程序。目前已经有了三个公共发型版本，通过ApacheMahout库，Mahout可以有效地扩展到云中。Mahout包括许多实现，包括聚类、分类、推荐引擎、频繁子项挖掘。")]),t._v(" "),e("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dm/mahoutintro/intro-1.png"),alt:"wxmp"}}),t._v(" "),e("p",[t._v("Apache Mahout的主要目标是建立可伸缩的机器学习算法。这种可伸缩性是针对大规模的数据集而言的。Apache Mahout的算法运行在ApacheHadoop平台下，他通过Mapreduce模式实现。但是，Apache Mahout并非严格要求算法的实现基于Hadoop平台，单个节点或非Hadoop平台也可以。Apache Mahout核心库的非分布式算法也具有良好的性能。")]),t._v(" "),e("h3",{attrs:{id:"mahout主要包含以下5部分"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mahout主要包含以下5部分"}},[t._v("#")]),t._v(" mahout主要包含以下5部分")]),t._v(" "),e("p",[t._v("频繁挖掘模式：挖掘数据中频繁出现的项集。")]),t._v(" "),e("p",[t._v("聚类：将诸如文本、文档之类的数据分成局部相关的组。")]),t._v(" "),e("p",[t._v("分类：利用已经存在的分类文档训练分类器，对未分类的文档进行分类。")]),t._v(" "),e("p",[t._v("推荐引擎（协同过滤）：获得用户的行为并从中发现用户可能喜欢的事物。")]),t._v(" "),e("p",[t._v("频繁子项挖掘：利用一个项集（查询记录或购物记录）去识别经常一起出现的项目。")]),t._v(" "),e("h2",{attrs:{id:"二、mahout历史"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#二、mahout历史"}},[t._v("#")]),t._v(" 二、mahout历史")]),t._v(" "),e("p",[t._v("Apache Mahout起源于2008年，经过两年的发展，2010年4月ApacheMahout最终成为了Apache的顶级项目。Mahout 项目是由 ApacheLucene（开源搜索）社区中对机器学习感兴趣的一些成员发起的，他们希望建立一个可靠、文档翔实、可伸缩的项目，在其中实现一些常见的用于集群和分类的机器学习算法。该社区最初基于 Ng et al. 的文章 “Map-Reduce for MachineLearning on Multicore”， 但此后在发展中又并入了更多广泛的机器学习方法。")]),t._v(" "),e("h3",{attrs:{id:"mahout-的目标还包括"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mahout-的目标还包括"}},[t._v("#")]),t._v(" Mahout 的目标还包括：")]),t._v(" "),e("p",[t._v("（1）、建立一个用户和贡献者社区，使代码不必依赖于特定贡献者的参与或任何特定公司和大学的资金。")]),t._v(" "),e("p",[t._v("（2）、专注于实际用例，这与高新技术研究及未经验证的技巧相反。")]),t._v(" "),e("p",[t._v("（3）、提供高质量文章和示例。")]),t._v(" "),e("h2",{attrs:{id:"三、mahout的特性"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#三、mahout的特性"}},[t._v("#")]),t._v(" 三、mahout的特性")]),t._v(" "),e("p",[t._v("虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和CF 方面。（集群与CF概念模糊可看文章第四节）")]),t._v(" "),e("h3",{attrs:{id:"mahout-的主要特性包括"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mahout-的主要特性包括"}},[t._v("#")]),t._v(" Mahout 的主要特性包括：")]),t._v(" "),e("p",[t._v("Taste CF。Taste 是 Sean Owen 在 SourceForge 上发起的一个针对 CF 的开源项目，并在 2008 年被赠予 Mahout。\n　　一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift。\n　　Distributed Naive Bayes 和Complementary Naive Bayes 分类实现。\n　　针对进化编程的分布式适用性功能。\n　　Matrix 和矢量库。")]),t._v(" "),e("p",[t._v("上述算法的示例。")]),t._v(" "),e("h2",{attrs:{id:"四、mahout当前已实现的三个具体的机器学习任务"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#四、mahout当前已实现的三个具体的机器学习任务"}},[t._v("#")]),t._v(" 四、mahout当前已实现的三个具体的机器学习任务")]),t._v(" "),e("p",[t._v("它们正好也是实际应用程序中相当常见的三个领域：")]),t._v(" "),e("p",[t._v("协作筛选")]),t._v(" "),e("p",[t._v("集群")]),t._v(" "),e("p",[t._v("分类")]),t._v(" "),e("p",[t._v("先从概念的层面上更加深入地讨论这些任务。")]),t._v(" "),e("h3",{attrs:{id:"_1-、协作筛选"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-、协作筛选"}},[t._v("#")]),t._v(" （1）、协作筛选")]),t._v(" "),e("p",[t._v("协作筛选(CF) 是 Amazon 等公司极为推崇的一项技巧，它使用评分、单击和购买等用户信息为其他站点用户提供推荐产品。CF 通常用于推荐各种消费品，比如说书籍、音乐和电影。但是，它还在其他应用程序中得到了应用，主要用于帮助多个操作人员通过协作来缩小数据范围。您可能已经在 Amazon 体验了 CF 的应用。")]),t._v(" "),e("p",[t._v("CF 应用程序根据用户和项目历史向系统的当前用户提供推荐。生成推荐的 4 种典型方法如下：")]),t._v(" "),e("p",[t._v("基于用户：通过查找相似的用户来推荐项目。由于用户的动态特性，这通常难以定量。")]),t._v(" "),e("p",[t._v("基于项目：计算项目之间的相似度并做出推荐。项目通常不会过多更改，因此这通常可以离线完成。")]),t._v(" "),e("p",[t._v("Slope-One：非常快速简单的基于项目的推荐方法，需要使用用户的评分信息（而不仅仅是布尔型的首选项）。")]),t._v(" "),e("p",[t._v("基于模型：通过开发一个用户及评分模型来提供推荐。")]),t._v(" "),e("p",[t._v("所有 CF 方法最终都需要计算用户及其评分项目之间的相似度。可以通过许多方法来计算相似度，并且大多数 CF 系统都允许您插入不同的指标，以便确定最佳结果。")]),t._v(" "),e("h3",{attrs:{id:"_2-、集群"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-、集群"}},[t._v("#")]),t._v(" （2）、集群")]),t._v(" "),e("p",[t._v("对于大型数据集来说，无论它们是文本还是数值，一般都可以将类似的项目自动组织，或集群， 到一起。举例来说，对于全美国某天内的所有的报纸新闻，您可能希望将所有主题相同的文章自动归类到一起；然后，可以选择专注于特定的集群和主题，而不需要阅读大量无关内容。另一个例子是：某台机器上的传感器会持续输出内容，您可能希望对输出进行分类，以便于分辨正常和有问题的操作，因为普通操作和异常操作 会归类到不同的集群中。")]),t._v(" "),e("p",[t._v("与 CF 类似，集群计算集合中各项目之间的相似度，但它的任务只是对相似的项目进行分组。在许多集群实现中，集合中的项目都是作为矢量表示在 n维度空间中的。通过矢量，开发人员可以使用各种指标（比如说曼哈顿距离、欧氏距离或余弦相似性）来计算两个项目之间的距离。然后，通过将距离相近的项目归类到一起，可以计算出实际集群。")]),t._v(" "),e("p",[t._v("可以通过许多方法来计算集群，每种方法都有自己的利弊。一些方法从较小的集群逐渐构建成较大的集群，还有一些方法将单个大集群分解为越来越小的集群。在发展成平凡集群表示之前（所有项目都在一个集群中，或者所有项目都在各自的集群中），这两种方法都会通过特定的标准退出处理。流行的方法包括 k-Means 和分层集群。如下所示，Mahout 也随带了一些不同的集群方法。")]),t._v(" "),e("h3",{attrs:{id:"_3-、分类"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-、分类"}},[t._v("#")]),t._v(" （3）、分类")]),t._v(" "),e("p",[t._v("分类（通常也称为 归类）的目标是标记不可见的文档，从而将它们归类不同的分组中。机器学习中的许多分类方法都需要计算各种统计数据（通过指定标签与文档的特性相关），从而创建一个模型以便以后用于分类不可见的文档。举例来说，一种简单的分类方法可以跟踪与标签相关的词，以及这些词在某个标签中的出现次数。然后，在对新文档进行分类时，系统将在模型中查找文档中的词并计算概率，然后输出最佳结果并通过一个分类来证明结果的正确性。")]),t._v(" "),e("p",[t._v("分类功能的特性可以包括词汇、词汇权重（比如说根据频率）和语音部件等。当然，这些特性确实有助于将文档关联到某个标签并将它整合到算法中。")]),t._v(" "),e("p",[t._v("机器学习这个领域相当广泛和活跃。理论再多终究需要实践。")]),t._v(" "),e("h2",{attrs:{id:"五、mahout下载"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#五、mahout下载"}},[t._v("#")]),t._v(" 五、mahout下载")]),t._v(" "),e("p",[t._v("1、官网地址")]),t._v(" "),e("p",[t._v("http://mirrors.cnnic.cn/apache/mahout/0.9/")]),t._v(" "),e("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dm/mahoutintro/intro-2.png"),alt:"wxmp"}}),t._v(" "),e("p",[t._v("下载 mahout-distribution-0.9.tar.gz")]),t._v(" "),e("p",[t._v("2、所有版本下载地址")]),t._v(" "),e("p",[t._v("http://archive.apache.org/dist/mahout/")]),t._v(" "),e("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dm/mahoutintro/intro-3.png"),alt:"wxmp"}}),t._v(" "),e("p",[t._v("在这里可以下载所有mahout版本。")]),t._v(" "),e("p",[t._v("参考文档：")]),t._v(" "),e("p",[t._v("Hadoop实战 第二版 陆嘉恒")]),t._v(" "),e("p",[t._v("http://baike.baidu.com/view/4029457.htm?fr=aladdin")]),t._v(" "),e("p",[t._v("http://www.ibm.com/developerworks/cn/java/j-mahout/#resources")]),t._v(" "),e("h2",{attrs:{id:"【-】"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#【-】"}},[t._v("#")]),t._v(" 【----------------------------】")]),t._v(" "),e("h2",{attrs:{id:"mahout介绍和安装"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mahout介绍和安装"}},[t._v("#")]),t._v(" Mahout介绍和安装")]),t._v(" "),e("h2",{attrs:{id:"简介"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),e("p",[t._v("Mahout:是一个Apache的一个开源的机器学习库，主要实现了三大类算法Recommender")]),t._v(" "),e("p",[t._v("(collaborative filtering)、Clustering、classification。可扩展，用Java实现，用MapReduce实现了部分数据挖掘算法，解决了并行挖掘的问题。")]),t._v(" "),e("p",[t._v("Mahout为数据分析人员，解决了大数据的门槛；为算法工程师提供了基础算法库；为Hadoop开发人员提供了数据建模的标准。")]),t._v(" "),e("p",[t._v("——张丹(Conan) http://blog.fens.me/hadoop-mahout-roadmap/")]),t._v(" "),e("h3",{attrs:{id:"mahout历史演变"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mahout历史演变"}},[t._v("#")]),t._v(" Mahout历史演变")]),t._v(" "),e("p",[t._v("Mahout began life in 2008 as a project of Apache`s lucene project .Lucene provides advanced implementations of search ,text mining and information-retrival techniques.In the universe of computer science ,there concepts are adjacent to machine learning techniques like clustering and to an extent ,classification .As a result,some of the work of the Lucene committers that fell more into these machine learning areas was spun off into its own subproject. Soon after ,Mahout absorbed the Taste open source collaborative filtering project.As of April 2010 ,Mahout became a top-level Apache project in its own right, and get a bran-new elephant rider logo to boot.")]),t._v(" "),e("p",[t._v("——Mahout in Action")]),t._v(" "),e("p",[t._v("25 April 2014 - Goodbye MapReduce")]),t._v(" "),e("p",[t._v("The Mahout community decided to move its codebase onto modern data processing systems that offer a richer programming model and more efficient execution than Hadoop MapReduce. Mahout will therefore reject new MapReduce algorithm implementations from now on. We will however keep our widely used MapReduce algorithms in the codebase and maintain them.")]),t._v(" "),e("p",[t._v("We are building our future implementations on top of a DSL for linear algebraic operations which has been developed over the last months. Programs written in this DSL are automatically optimized and executed in parallel on Apache Spark.")]),t._v(" "),e("p",[t._v("——http://mahout.apache.org/")]),t._v(" "),e("h3",{attrs:{id:"hadoop家族中mahout的结构图"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hadoop家族中mahout的结构图"}},[t._v("#")]),t._v(" Hadoop家族中Mahout的结构图")]),t._v(" "),e("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dm/mahoutintro/intro2-1.png"),alt:"wxmp"}}),t._v(" "),e("p",[e("strong",[t._v("主要算法：")])]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("算法类")]),t._v(" "),e("th",[t._v("算法名")]),t._v(" "),e("th",[t._v("中文名")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("分类算法")]),t._v(" "),e("td",[t._v("Logistic Regression")]),t._v(" "),e("td",[t._v("逻辑回归")])]),t._v(" "),e("tr",[e("td",[t._v("Bayesian")]),t._v(" "),e("td",[t._v("贝叶斯")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("SVM")]),t._v(" "),e("td",[t._v("支持向量机")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Perceptron")]),t._v(" "),e("td",[t._v("感知器算法")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Neural Network")]),t._v(" "),e("td",[t._v("神经网络")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Random Forests")]),t._v(" "),e("td",[t._v("随机森林")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Restricted Boltzmann Machines")]),t._v(" "),e("td",[t._v("有限波尔兹曼机")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("聚类算法")]),t._v(" "),e("td",[t._v("Canopy Clustering")]),t._v(" "),e("td",[t._v("Canopy聚类")])]),t._v(" "),e("tr",[e("td",[t._v("K-means Clustering")]),t._v(" "),e("td",[t._v("K均值算法")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Fuzzy K-means")]),t._v(" "),e("td",[t._v("模糊K均值")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Expectation Maximization")]),t._v(" "),e("td",[t._v("EM聚类（期望最大化聚类）")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Mean Shift Clustering")]),t._v(" "),e("td",[t._v("均值漂移聚类")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Hierarchical Clustering")]),t._v(" "),e("td",[t._v("层次聚类")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Dirichlet Process Clustering")]),t._v(" "),e("td",[t._v("狄里克雷过程聚类")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Latent Dirichlet Allocation")]),t._v(" "),e("td",[t._v("LDA聚类")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Spectral Clustering")]),t._v(" "),e("td",[t._v("谱聚类")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("关联规则挖掘")]),t._v(" "),e("td",[t._v("Parallel FP Growth Algorithm")]),t._v(" "),e("td",[t._v("并行FP Growth算法")])]),t._v(" "),e("tr",[e("td",[t._v("回归")]),t._v(" "),e("td",[t._v("Locally Weighted Linear Regression")]),t._v(" "),e("td",[t._v("局部加权线性回归")])]),t._v(" "),e("tr",[e("td",[t._v("降维/维约简")]),t._v(" "),e("td",[t._v("Singular Value Decomposition")]),t._v(" "),e("td",[t._v("奇异值分解")])]),t._v(" "),e("tr",[e("td",[t._v("Principal Components Analysis")]),t._v(" "),e("td",[t._v("主成分分析")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Independent Component Analysis")]),t._v(" "),e("td",[t._v("独立成分分析")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("Gaussian Discriminative Analysis")]),t._v(" "),e("td",[t._v("高斯判别分析")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("进化算法")]),t._v(" "),e("td",[t._v("并行化了Watchmaker框架")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("推荐/协同过滤")]),t._v(" "),e("td",[t._v("Non-distributed recommenders")]),t._v(" "),e("td",[t._v("Taste(UserCF, ItemCF, SlopeOne）")])]),t._v(" "),e("tr",[e("td",[t._v("Distributed Recommenders")]),t._v(" "),e("td",[t._v("ItemCF")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("向量相似度计算")]),t._v(" "),e("td",[t._v("RowSimilarityJob")]),t._v(" "),e("td",[t._v("计算列间相似度")])]),t._v(" "),e("tr",[e("td",[t._v("VectorDistanceJob")]),t._v(" "),e("td",[t._v("计算向量间距离")]),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td",[t._v("非Map-Reduce算法")]),t._v(" "),e("td",[t._v("Hidden Markov Models")]),t._v(" "),e("td",[t._v("隐马尔科夫模型")])]),t._v(" "),e("tr",[e("td",[t._v("集合方法扩展")]),t._v(" "),e("td",[t._v("Collections")]),t._v(" "),e("td",[t._v("扩展了java的Collections类")])])])]),t._v(" "),e("p",[t._v("——"),e("a",{attrs:{href:"http://blog.csdn.net/",target:"_blank",rel:"noopener noreferrer"}},[t._v("http://blog.csdn.net"),e("OutboundLink")],1)]),t._v(" "),e("h3",{attrs:{id:"mahout在hadoop-平台上的安装"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mahout在hadoop-平台上的安装"}},[t._v("#")]),t._v(" Mahout在Hadoop 平台上的安装")]),t._v(" "),e("div",{staticClass:"language-shell extra-class"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[t._v("\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(".下载mahout:http://archive.apache.org/dist/mahout/\n\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(".下载Maven 一般ubuntu系统直接 "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("apt-get")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" maven\n\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(".将mahout 的文件解压成文件夹mahout 并放入/usr文件夹\n\n "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("tar")]),t._v(" -zxvf mahout-distribution-0.9.tar.gz\n\n "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("mv")]),t._v("  mahout-distribution-0.9 /usr/mahout\n\n"),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(".创建一个脚本，配置mahout的环境。脚本内容\n\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("JAVA_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/usr/lib/jvm/jdk8/  \n\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("MAHOUT_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/usr/mahout9\n\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("MAHOUT_CONF_DIR")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/usr/mahout9/conf\n\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("PATH")])]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$MAHOUT_HOME")]),t._v("/bin:"),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$MAHOUT_HOME")]),t._v("/conf:"),e("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("$PATH")]),t._v("\n\n \n\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_HOME")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/usr/hadoop\n\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("HADOOP_CONF_DIR")]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("/usr/hadoop/conf\n\n"),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token assign-left variable"}},[e("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("PATH")])]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token environment constant"}},[t._v("$PATH")]),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(":")]),e("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$HADOOP_HOME")]),t._v("/bin\n\n")])])]),e("p",[t._v("5.运行脚本文件，运行mahout命令")]),t._v(" "),e("p",[t._v("6.到这里就表示安装成功，下面下载一个测书数据，是一下mahout 的Kmeans聚类方法。")]),t._v(" "),e("p",[t._v("Sudo wget http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data")]),t._v(" "),e("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dm/mahoutintro/intro2-2.png"),alt:"wxmp"}}),t._v(" "),e("p",[t._v("7.将数据上传到HDFS 上")]),t._v(" "),e("p",[t._v("hdfs fs -mkdir testdata")]),t._v(" "),e("p",[t._v("hdfs fs -put /usr/"),e("a",{attrs:{href:"http://archive.ics.uci.edu/ml/databases/synthetic_control/synthetic_control.data",target:"_blank",rel:"noopener noreferrer"}},[t._v("synthetic_control.data"),e("OutboundLink")],1),t._v(" ./testdata")]),t._v(" "),e("p",[t._v("8.运行k-means聚类算法")]),t._v(" "),e("p",[t._v("mahout -core org.apache.clustering.syntheticcontrol.kmeans.Job")]),t._v(" "),e("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dm/mahoutintro/intro2-3.png"),alt:"wxmp"}}),t._v(" "),e("h2",{attrs:{id:"参考文章"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[t._v("#")]),t._v(" 参考文章")]),t._v(" "),e("ul",[e("li",[t._v("https://blog.csdn.net/baolibin528/article/details/39760443")]),t._v(" "),e("li",[t._v("https://www.cnblogs.com/xiangfeng/p/4362301.html")])])])}),[],!1,null,null,null);a.default=r.exports}}]);