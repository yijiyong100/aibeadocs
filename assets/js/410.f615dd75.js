(window.webpackJsonp=window.webpackJsonp||[]).push([[410],{925:function(t,a,r){"use strict";r.r(a);var e=r(53),s=Object(e.a)({},(function(){var t=this,a=t.$createElement,r=t._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("div",{staticClass:"custom-block tip"},[r("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),r("p",[t._v("本文主要是介绍 Spark-RDD模型介绍 。")])]),t._v(" "),r("p"),r("div",{staticClass:"table-of-contents"},[r("ul",[r("li",[r("a",{attrs:{href:"#_1-rdd是什么"}},[t._v("1.RDD是什么")]),r("ul",[r("li",[r("a",{attrs:{href:"#rdd解析"}},[t._v("RDD解析")])]),r("li",[r("a",{attrs:{href:"#rdd的5特属性"}},[t._v("RDD的5特属性")])])])]),r("li",[r("a",{attrs:{href:"#_2-为什么需要rdd"}},[t._v("2.为什么需要RDD")])]),r("li",[r("a",{attrs:{href:"#_3-rdd-vs-dsm"}},[t._v("3.RDD vs DSM")])]),r("li",[r("a",{attrs:{href:"#_4-rdd的特征"}},[t._v("4.RDD的特征")]),r("ul",[r("li",[r("a",{attrs:{href:"#_4-1-in-memory-computation"}},[t._v("4.1 In-memory Computation")])]),r("li",[r("a",{attrs:{href:"#_4-2-lazy-evaluations"}},[t._v("4.2 Lazy Evaluations")])]),r("li",[r("a",{attrs:{href:"#_4-3-fault-tolerance"}},[t._v("4.3 Fault Tolerance")])]),r("li",[r("a",{attrs:{href:"#_4-4-immutability"}},[t._v("4.4 Immutability")])]),r("li",[r("a",{attrs:{href:"#_4-5-partitioning"}},[t._v("4.5 Partitioning")])]),r("li",[r("a",{attrs:{href:"#_4-6-coarse-grained-operations"}},[t._v("4.6 Coarse-grained Operations")])]),r("li",[r("a",{attrs:{href:"#_4-7-location-stickiness"}},[t._v("4.7 Location-Stickiness")])]),r("li",[r("a",{attrs:{href:"#_4-8-persistence"}},[t._v("4.8 Persistence")])])])]),r("li",[r("a",{attrs:{href:"#_5-rdd-operation"}},[t._v("5.RDD Operation")]),r("ul",[r("li",[r("a",{attrs:{href:"#_5-1-transformations"}},[t._v("5.1 Transformations")])])])]),r("li",[r("a",{attrs:{href:"#_6-rdd的局限性"}},[t._v("6.RDD的局限性")]),r("ul",[r("li",[r("a",{attrs:{href:"#_6-1-no-input-optimization-engine"}},[t._v("6.1 No input optimization engine")])]),r("li",[r("a",{attrs:{href:"#_6-2-runtime-type-safety"}},[t._v("6.2 Runtime type safety")])]),r("li",[r("a",{attrs:{href:"#_6-3-degrade-when-not-enough-memory"}},[t._v("6.3 Degrade when not enough memory")])]),r("li",[r("a",{attrs:{href:"#_6-4-performance-limitation-overhead-of-serialization-garbage-collection"}},[t._v("6.4 Performance limitation & Overhead of serialization & garbage collection")])]),r("li",[r("a",{attrs:{href:"#_6-5-handling-structured-data"}},[t._v("6.5 Handling structured data")])])])]),r("li",[r("a",{attrs:{href:"#【-】"}},[t._v("【----------------------------】")])]),r("li",[r("a",{attrs:{href:"#spark-rdd介绍"}},[t._v("Spark—RDD介绍")])]),r("li",[r("a",{attrs:{href:"#_1、概念介绍"}},[t._v("1、概念介绍")])]),r("li",[r("a",{attrs:{href:"#_2、rdd特点"}},[t._v("2、RDD特点")]),r("ul",[r("li",[r("a",{attrs:{href:"#_1-不可变"}},[t._v("1)不可变：")])]),r("li",[r("a",{attrs:{href:"#_2-可分区"}},[t._v("2)可分区：")])]),r("li",[r("a",{attrs:{href:"#_3-弹性"}},[t._v("3)弹性：")])])])]),r("li",[r("a",{attrs:{href:"#_3、在计算数据中rdd都做了什么"}},[t._v("3、在计算数据中RDD都做了什么：")])]),r("li",[r("a",{attrs:{href:"#_4、spark-wordcount-解释rdd"}},[t._v("4、Spark wordcount 解释RDD")])]),r("li",[r("a",{attrs:{href:"#参考文章"}},[t._v("参考文章")])])])]),r("p"),t._v(" "),r("p",[t._v("本篇文章主要是介绍什么RDD、RDD的5个特性和RDD的特征。")]),t._v(" "),r("h2",{attrs:{id:"_1-rdd是什么"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-rdd是什么"}},[t._v("#")]),t._v(" 1.RDD是什么")]),t._v(" "),r("p",[t._v("RDD是Resilient Distributed Dataset。\nRDD是Spark的基础数据结构。表现形式为不可变的分区元素的集合，并且可以在集群中并行操作。")]),t._v(" "),r("h3",{attrs:{id:"rdd解析"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rdd解析"}},[t._v("#")]),t._v(" RDD解析")]),t._v(" "),r("blockquote",[r("ul",[r("li",[t._v("Resilient(弹性):在DAG的帮助下，具有容错性。即在节点故障导致丢失或者损坏分区，可以重新计算数据。")]),t._v(" "),r("li",[t._v("Distributed:数据存储在多个节点上。")]),t._v(" "),r("li",[t._v("Dataset:要处理的数据集。用户可以在外部数据源获取数据，这些数据源可以JSON文件、CSV文件、文本文件获取通过JDBC的形式获取数据库中没有特定数据结构的数据。")])])]),t._v(" "),r("h3",{attrs:{id:"rdd的5特属性"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rdd的5特属性"}},[t._v("#")]),t._v(" RDD的5特属性")]),t._v(" "),r("blockquote",[r("ul",[r("li",[t._v("获取分区列表(getPartitions):有一个数据分片列表，能够将数据进行切分，切分后的数据能够进行并行计算，是数据集的原子组成部分。")]),t._v(" "),r("li",[t._v("可以在每一个分区上进行计算(compute)：计算每个分区，得到一个可便利的结果，用于说明在父RDD上执行何种计算。")]),t._v(" "),r("li",[t._v("获取每个RDD的依赖(getDependencies):计算每个RDD对父RDD的依赖列表，源RDD没有依赖，通过依赖关系描述血统。")]),t._v(" "),r("li",[t._v("RDD的键值分区器( @transient val partitioner: Option[Partitioner] = None):描述分区模式和数据存放的位置，键值对的RDD根据哈希值进行分区。")]),t._v(" "),r("li",[t._v("在那个分区上进行计算最好(getPreferredLocations):每一个分片的优先计算位置。")])])]),t._v(" "),r("p",[t._v("RDD中的数据集是按照逻辑分不到集群中的节点上，这样可以在各个节点上并行计算。RDD具有容错性，在失败的情况下，可以自动恢复。")]),t._v(" "),r("p",[t._v("RDD可以被缓存，并且可以手动分区。")]),t._v(" "),r("p",[t._v("开发人员可以将需要再次使用的RDD进行持久化。Spark是默认将数据持久化到内存中，如果内存不足，会将数据写入到磁盘上。用户可以自定义持久化方式。")]),t._v(" "),r("h2",{attrs:{id:"_2-为什么需要rdd"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-为什么需要rdd"}},[t._v("#")]),t._v(" 2.为什么需要RDD")]),t._v(" "),r("p",[t._v("提出RDD的动机有:")]),t._v(" "),r("blockquote",[r("ul",[r("li",[t._v("迭代计算。")]),t._v(" "),r("li",[t._v("交互式的数据挖掘工具。")]),t._v(" "),r("li",[t._v("DSM(Distributed Shared Memory)是一个通用的抽象，这种通用性使得在集群上高效执行和容错性变得更难。")])])]),t._v(" "),r("p",[t._v("RDD具有容错性，这是因为RDD是基于coarse-grained transformation而不是fine-grained updates来更新状态。")]),t._v(" "),r("p",[t._v("RDD是lazy的，在需要的时候，这样可以节省很多时间并提高效率。")]),t._v(" "),r("h2",{attrs:{id:"_3-rdd-vs-dsm"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-rdd-vs-dsm"}},[t._v("#")]),t._v(" 3.RDD vs DSM")]),t._v(" "),r("table",[r("thead",[r("tr",[r("th"),t._v(" "),r("th",[t._v("RDD")]),t._v(" "),r("th",[t._v("DSM")])])]),t._v(" "),r("tbody",[r("tr",[r("td",[t._v("Read")]),t._v(" "),r("td",[t._v("RDD的读操作可以是粗力度,也可以是细粒度。 粗粒度是对整个数据集进行转换操作,而不是针对数据集中的每一个元素。 细粒度是针对数据集中的每一个元素进行转换操作。")]),t._v(" "),r("td",[t._v("DSM中的转换操作是细粒度的。")])]),t._v(" "),r("tr",[r("td",[t._v("Write")]),t._v(" "),r("td",[t._v("RDD的写入是粗粒度")]),t._v(" "),r("td",[t._v("DSM的写操作是细粒度")])]),t._v(" "),r("tr",[r("td",[t._v("Consistency")]),t._v(" "),r("td",[t._v("RDD的数据是不可变的")]),t._v(" "),r("td",[t._v("如果开发者遵循规则，内存中的数据保持一致，并且内存操作结果是可预测的")])]),t._v(" "),r("tr",[r("td",[t._v("Fault-Recovery Mechanism")]),t._v(" "),r("td",[t._v("丢失的数据可以通过DAG来恢复，RDD的数据都是不可变的，很容易恢复")]),t._v(" "),r("td",[t._v("通过checkpoint实现容错，如果出现问题，回到最新的checkpoint")])]),t._v(" "),r("tr",[r("td",[t._v("Straggler Mitigation")]),t._v(" "),r("td",[t._v("RDD可以用备份任务来解决运行比较慢的任务")]),t._v(" "),r("td",[t._v("解决运行慢的任务非常困难")])]),t._v(" "),r("tr",[r("td",[t._v("Behavior if not enough RAM")]),t._v(" "),r("td",[t._v("RDD的数据比较多，在内存中存储不了，将多余数据写入磁盘")]),t._v(" "),r("td",[t._v("DSM中，如果数据量大于内存的最大值，性能下降厉害")])])])]),t._v(" "),r("h2",{attrs:{id:"_4-rdd的特征"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-rdd的特征"}},[t._v("#")]),t._v(" 4.RDD的特征")]),t._v(" "),r("h3",{attrs:{id:"_4-1-in-memory-computation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-in-memory-computation"}},[t._v("#")]),t._v(" 4.1 In-memory Computation")]),t._v(" "),r("p",[t._v("Spark RDD具有内存计算功能。RDD将中间的结果存储在内存中，如果内存中存不下的时候，将数据放在磁盘上。")]),t._v(" "),r("h3",{attrs:{id:"_4-2-lazy-evaluations"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-lazy-evaluations"}},[t._v("#")]),t._v(" 4.2 Lazy Evaluations")]),t._v(" "),r("p",[t._v("Spark的所有转换操作都是Lazy的，如果遇到action操作时，才会执行之前的操作。")]),t._v(" "),r("h3",{attrs:{id:"_4-3-fault-tolerance"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-fault-tolerance"}},[t._v("#")]),t._v(" 4.3 Fault Tolerance")]),t._v(" "),r("p",[t._v("Spark RDD具有容错能力。如果碰到故障时，RDD可以根据追踪数据的依赖关系，来重新生成丢失的数据。")]),t._v(" "),r("h3",{attrs:{id:"_4-4-immutability"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-immutability"}},[t._v("#")]),t._v(" 4.4 Immutability")]),t._v(" "),r("p",[t._v("RDD中的数据都是不可变的，可以在进程之间共享使用。")]),t._v(" "),r("h3",{attrs:{id:"_4-5-partitioning"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-partitioning"}},[t._v("#")]),t._v(" 4.5 Partitioning")]),t._v(" "),r("p",[t._v("分区是RDD并行计算的基本单元。每个分区都是一个可变数据的逻辑分区。在现有分区的基础上可以通过一些转换操作生成新的分区。")]),t._v(" "),r("h3",{attrs:{id:"_4-6-coarse-grained-operations"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-6-coarse-grained-operations"}},[t._v("#")]),t._v(" 4.6 Coarse-grained Operations")]),t._v(" "),r("p",[t._v("将一个方法作用于数据集中的每一个元素。")]),t._v(" "),r("h3",{attrs:{id:"_4-7-location-stickiness"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-location-stickiness"}},[t._v("#")]),t._v(" 4.7 Location-Stickiness")]),t._v(" "),r("p",[t._v("RDD可以定义计算分区的放置首选项。DAG Scheduler将尽量任务放到数据所在的节点上。")]),t._v(" "),r("h3",{attrs:{id:"_4-8-persistence"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-8-persistence"}},[t._v("#")]),t._v(" 4.8 Persistence")]),t._v(" "),r("p",[t._v("RDD可以根据需要不同，选择相应的存储策略。")]),t._v(" "),r("h2",{attrs:{id:"_5-rdd-operation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-rdd-operation"}},[t._v("#")]),t._v(" 5.RDD Operation")]),t._v(" "),r("h3",{attrs:{id:"_5-1-transformations"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-transformations"}},[t._v("#")]),t._v(" 5.1 Transformations")]),t._v(" "),r("p",[t._v("RDD的转换操作都是lazy的，分为两种narrow transformation, wide transformation。")]),t._v(" "),r("h4",{attrs:{id:"_5-1-1-narrow-transformations-窄依赖"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-1-narrow-transformations-窄依赖"}},[t._v("#")]),t._v(" 5.1.1 Narrow Transformations(窄依赖)")]),t._v(" "),r("p",[t._v("在单个分区中计算记录所需的所有元素都存在父RDD的单个分区中。\nmap、flatMap、MapPartition、filter、Sample、Union操作的结果就是Narrow transformation。")]),t._v(" "),r("p",[t._v("一个父RDD的partition至少会被子RDD的某个partition使用一次。就是一个父类RDD的一个分区不可能对应一个子RDD的多个分区。")]),t._v(" "),r("h4",{attrs:{id:"_5-1-2-wide-transformation-宽依赖"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-2-wide-transformation-宽依赖"}},[t._v("#")]),t._v(" 5.1.2 Wide transformation(宽依赖)")]),t._v(" "),r("p",[t._v("在单个分区中计算记录所需的所有元素都存在父RDD的多个分区中。\nintersection、distinct、reduceByKey、GroupByKey、join、Cartesian、repartition、colaesce操作的结果是Wide transformation。")]),t._v(" "),r("p",[t._v("一个父RDD的partition会被子RDD的partition使用多次。就是一个父RDD的一个分区对应一个子RDD的多个分区。")]),t._v(" "),r("p",[t._v("Join操作：窄依赖，两个数据集使用相同的分区器；宽依赖，使用不同的分区器。")]),t._v(" "),r("p",[t._v("可以使用toDebugString，看到RDD的线性信息，如果出现ShuffleDependency，就是发生shuffle操作。")]),t._v(" "),r("h4",{attrs:{id:"_5-1-3依赖关系说明"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-3依赖关系说明"}},[t._v("#")]),t._v(" 5.1.3依赖关系说明")]),t._v(" "),r("p",[t._v("窄依赖的RDd可以通过相同的键进行联合分区，整个操作都可以在一个集群节点上进行，以流水线的方式计算所有父分区，不会造成网络之间的数据混合。")]),t._v(" "),r("p",[t._v("宽依赖RDD涉及数据混合，宽依赖需要首先计算好所有父分区数据，然后在节点直接进行shuffle。")]),t._v(" "),r("p",[t._v("窄依赖能够更有效的进行失效节点的恢复，重新计算丢失RDD分区的父分区，不同节点之间可以并行计算；\n对一个宽窄依赖的血统图，单个节点失效可能导致这个RDD的所有祖先丢失部分数据，因而需要整体重新计算(Shuffle执行时固化操作，以及采取persist缓存策略，可以在固化点或者缓存点重新计算)。")]),t._v(" "),r("p",[t._v("执行时，调度程序检查依赖性的类型，将窄依赖的RDD划到一组处理当中，即Stage，宽依赖在一个跨越连续的Stage，同时需要显示指定多个子RDD的分区。")]),t._v(" "),r("p",[t._v("可以参考"),r("a",{attrs:{href:"https://github.com/rohgar/scala-spark-4/wiki/Wide-vs-Narrow-Dependencies",target:"_blank",rel:"noopener noreferrer"}},[t._v("Wide vs Narrow Dependencies"),r("OutboundLink")],1)]),t._v(" "),r("h2",{attrs:{id:"_6-rdd的局限性"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-rdd的局限性"}},[t._v("#")]),t._v(" 6.RDD的局限性")]),t._v(" "),r("h3",{attrs:{id:"_6-1-no-input-optimization-engine"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-1-no-input-optimization-engine"}},[t._v("#")]),t._v(" 6.1 No input optimization engine")]),t._v(" "),r("p",[t._v("RDD没有自动优化的规则，无法使用Spark高级优化器，例如catalyst优化器和Tungsten执行引擎。可以实现手动RDD优化。")]),t._v(" "),r("p",[t._v("在Dataset和DataFrame中不存在这个问题，DataSet和DataFrame可以使用catalyst来产生优化后的逻辑和物理执行计划，这样可以节省空间和提高运行速度。")]),t._v(" "),r("h3",{attrs:{id:"_6-2-runtime-type-safety"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-2-runtime-type-safety"}},[t._v("#")]),t._v(" 6.2 Runtime type safety")]),t._v(" "),r("p",[t._v("在RDD中没有静态类型和运行时类型安全，并且不允许在运行时检查错误。\nDataset提供了编译时期类型安全来构建复杂数据工作流。")]),t._v(" "),r("h3",{attrs:{id:"_6-3-degrade-when-not-enough-memory"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-3-degrade-when-not-enough-memory"}},[t._v("#")]),t._v(" 6.3 Degrade when not enough memory")]),t._v(" "),r("p",[t._v("在存储RDD时，如果没有足够的内存或者磁盘，将会使得RDD的性能下降特别厉害。")]),t._v(" "),r("h3",{attrs:{id:"_6-4-performance-limitation-overhead-of-serialization-garbage-collection"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-4-performance-limitation-overhead-of-serialization-garbage-collection"}},[t._v("#")]),t._v(" 6.4 Performance limitation & Overhead of serialization & garbage collection")]),t._v(" "),r("p",[t._v("因为RDD是内存中的JVM对象，这就牵扯到GC和Java序列化，在数据增长时，会需要大量的内存或者磁盘空间。\nGC的成本与Java对象是成正比的，使用数据结构比较少的对象可以减少成本，或者将数据持久化。")]),t._v(" "),r("h3",{attrs:{id:"_6-5-handling-structured-data"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-5-handling-structured-data"}},[t._v("#")]),t._v(" 6.5 Handling structured data")]),t._v(" "),r("p",[t._v("RDD不提供数据的schema信息。\nDataset和DataFrame提供了数据的schema信息，可以每一列数据的含义。")]),t._v(" "),r("h2",{attrs:{id:"【-】"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#【-】"}},[t._v("#")]),t._v(" 【----------------------------】")]),t._v(" "),r("h2",{attrs:{id:"spark-rdd介绍"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#spark-rdd介绍"}},[t._v("#")]),t._v(" Spark—RDD介绍")]),t._v(" "),r("p",[t._v("Spark—RDD")]),t._v(" "),r("h2",{attrs:{id:"_1、概念介绍"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1、概念介绍"}},[t._v("#")]),t._v(" 1、概念介绍")]),t._v(" "),r("p",[t._v("RDD（Resilient Distributed Dataset）:弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。")]),t._v(" "),r("p",[t._v("官方定义还是比较抽象，个人理解为:它本质就是一个类，屏蔽了底层对数据的复杂抽象和处理，为用户提供了一组方便数据转换和求值的方法。")]),t._v(" "),r("h2",{attrs:{id:"_2、rdd特点"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2、rdd特点"}},[t._v("#")]),t._v(" 2、RDD特点")]),t._v(" "),r("h3",{attrs:{id:"_1-不可变"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-不可变"}},[t._v("#")]),t._v(" 1)不可变：")]),t._v(" "),r("p",[t._v("弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合")]),t._v(" "),r("h3",{attrs:{id:"_2-可分区"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-可分区"}},[t._v("#")]),t._v(" 2)可分区：")]),t._v(" "),r("p",[t._v("RDD在抽象上来说是一种元素集合，包含了数据。它是被分区的，分为多个分区，每个分区分布在集群中的不同Worker节点上，从而让RDD中的数据可以被并行操作。（分布式数据集）")]),t._v(" "),r("h3",{attrs:{id:"_3-弹性"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-弹性"}},[t._v("#")]),t._v(" 3)弹性：")]),t._v(" "),r("ul",[r("li",[t._v("1.存储弹性：内存与磁盘的自动切换")]),t._v(" "),r("li",[t._v("2.容错弹性：数据丢失可以自动恢复")]),t._v(" "),r("li",[t._v("3.计算弹性：计算出错重试机制")]),t._v(" "),r("li",[t._v("4.分片弹性：根据需要重新分片")])]),t._v(" "),r("h2",{attrs:{id:"_3、在计算数据中rdd都做了什么"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3、在计算数据中rdd都做了什么"}},[t._v("#")]),t._v(" 3、在计算数据中RDD都做了什么：")]),t._v(" "),r("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/spark/rddintro-1.png"),alt:"wxmp"}}),t._v(" "),r("p",[t._v("主要流程：")]),t._v(" "),r("p",[t._v("RDD创建——>RDD转换——>RDD缓存——>RDD行动——>RDD的输出")]),t._v(" "),r("p",[t._v("spark计算的核心就在RDD转换、缓存、行动上。")]),t._v(" "),r("h2",{attrs:{id:"_4、spark-wordcount-解释rdd"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4、spark-wordcount-解释rdd"}},[t._v("#")]),t._v(" 4、Spark wordcount 解释RDD")]),t._v(" "),r("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/spark/rddintro-2.png"),alt:"wxmp"}}),t._v(" "),r("h2",{attrs:{id:"参考文章"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[t._v("#")]),t._v(" 参考文章")]),t._v(" "),r("ul",[r("li",[t._v("https://www.jianshu.com/p/c43cd6a5538d")]),t._v(" "),r("li",[t._v("https://www.cnblogs.com/jnba/p/10830446.html")])])])}),[],!1,null,null,null);a.default=s.exports}}]);