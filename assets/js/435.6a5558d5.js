(window.webpackJsonp=window.webpackJsonp||[]).push([[435],{950:function(t,s,a){"use strict";a.r(s);var e=a(53),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("本文主要是介绍 Tez-精华知识总结 。")])]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#hive执行引擎tez学习以及实际使用"}},[t._v("HIVE执行引擎TEZ学习以及实际使用")])]),a("li",[a("a",{attrs:{href:"#概述"}},[t._v("概述")])]),a("li",[a("a",{attrs:{href:"#tez产生背景"}},[t._v("Tez产生背景")])]),a("li",[a("a",{attrs:{href:"#tez原理"}},[t._v("Tez原理")]),a("ul",[a("li",[a("a",{attrs:{href:"#dag"}},[t._v("DAG")])]),a("li",[a("a",{attrs:{href:"#runtime-api-input-processor-output"}},[t._v("Runtime API——Input/Processor/Output")])]),a("li",[a("a",{attrs:{href:"#runtime优化"}},[t._v("Runtime优化")])]),a("li",[a("a",{attrs:{href:"#从逻辑执行计划到物理执行计划"}},[t._v("从逻辑执行计划到物理执行计划")])]),a("li",[a("a",{attrs:{href:"#其他优化措施"}},[t._v("其他优化措施")])]),a("li",[a("a",{attrs:{href:"#tez优缺点"}},[t._v("Tez优缺点")])])])]),a("li",[a("a",{attrs:{href:"#tez安装过程"}},[t._v("Tez安装过程")])]),a("li",[a("a",{attrs:{href:"#tez实际使用"}},[t._v("Tez实际使用")])]),a("li",[a("a",{attrs:{href:"#总结"}},[t._v("总结")])]),a("li",[a("a",{attrs:{href:"#参考文章"}},[t._v("参考文章")])])])]),a("p"),t._v(" "),a("h2",{attrs:{id:"hive执行引擎tez学习以及实际使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hive执行引擎tez学习以及实际使用"}},[t._v("#")]),t._v(" HIVE执行引擎TEZ学习以及实际使用")]),t._v(" "),a("h2",{attrs:{id:"概述"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#概述"}},[t._v("#")]),t._v(" 概述")]),t._v(" "),a("p",[t._v("Tez是Apache最新的支持DAG作业的开源计算框架，它可以将多个有依赖的作业转换为一个作业从而大幅提升DAG作业的性能。Tez并不直接面向最终用户——事实上它允许开发者为最终用户构建性能更快、扩展性更好的应用程序。Hadoop传统上是一个大量数据批处理平台。但是，有很多用例需要近乎实时的查询处理性能。还有一些工作则不太适合MapReduce，例如机器学习。Tez的目的就是帮助Hadoop处理这些用例场景。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718191327403-1868942264.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("Tez构建在YARN之上，后者是Hadoop所使用的新资源管理框架。Tez产生的主要原因是绕开MapReduce所施加的限制。除了必须要编写Mapper和Reducer的限制之外，强制让所有类型的计算都满足这一范例还有效率低下的问题——例如使用HDFS存储多个MR作业之间的临时数据，这是一个负载。在Hive中，查询需要对不相关的key进行多次shuffle操作的场景非常普遍，例如join - grp by - window function - order by。")]),t._v(" "),a("h2",{attrs:{id:"tez产生背景"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tez产生背景"}},[t._v("#")]),t._v(" Tez产生背景")]),t._v(" "),a("p",[t._v("MR性能差，资源消耗大，如：Hive作业之间的数据不是直接流动的，而是借助HDFS作为共享数据存储系统，即一个作业将处理好的数据写入HDFS，下一个作业再从HDFS重新读取数据进行处理。很明显更高效的方式是，第一个作业直接将数据传递给下游作业。")]),t._v(" "),a("p",[t._v("MR 默认了map和reduce阶段，map会对中间结果进行分区、排序，reduce会进行合并排序，这一过程并不适用于所有场景。")]),t._v(" "),a("p",[t._v("引擎级别的Runtime优化：MR执行计划在编译时已经确定，无法动态调整(?)。然而在执行ETL和Ad-hoc等任务时，根据实际处理的表大小，动态调整join策略、任务并行度将大大缩短任务执行时间。")]),t._v(" "),a("p",[t._v("下面给您展示一张Tez官方图，您就可以简单明白Tez和MapReduce的关系。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718191745080-1336205523.png"),alt:"wxmp"}}),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718191752404-1120819473.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("总的来说之前mapReduce在map和reduce阶段都会产生I/O落盘，但是Tez就不要这一步骤了。")]),t._v(" "),a("p",[t._v("目前hive使用了Tez（Hive是一个将用户的SQL请求翻译为MR任务，最终查询HDFS的工具Tez采用了DAG（有向无环图）来组织MR任务。")]),t._v(" "),a("p",[t._v("核心思想：将Map任务和Reduce任务进一步拆分，Map任务拆分为Input-Processor-Sort-Merge-Output，Reduce任务拆分为Input-Shuffer-Sort-Merge-Process-output，Tez将若干小任务灵活重组，形成一个大的DAG作业。")]),t._v(" "),a("p",[t._v("Tez与oozie不同：oozie只能以MR任务为整体来管理、组织，本质上仍然是多个MR任务的执行，不能解决上面提到的多个任务之间硬盘IO冗余的问题。")]),t._v(" "),a("p",[t._v("Tez只是一个Client，部署很方便。 目前Hive使用了Tez（Hive是一个将用户的SQL请求翻译为MR任务，最终查询HDFS的工具）。")]),t._v(" "),a("h2",{attrs:{id:"tez原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tez原理"}},[t._v("#")]),t._v(" Tez原理")]),t._v(" "),a("p",[t._v("Tez包含的组件：")]),t._v(" "),a("p",[t._v("有向无环图（DAG）——定义整体任务。一个DAG对象对应一个任务。")]),t._v(" "),a("p",[t._v("节点（Vertex）——定义用户逻辑以及执行用户逻辑所需的资源和环境。一个节点对应任务中的一个步骤。")]),t._v(" "),a("p",[t._v("边（Edge）——定义生产者和消费者节点之间的连接。")]),t._v(" "),a("p",[t._v("边需要分配属性，对Tez而言这些属性是必须的，有了它们才能在运行时将逻辑图展开为能够在集群上并行执行的物理任务集合。下面是一些这样的属性：")]),t._v(" "),a("p",[t._v("数据移动属性，定义了数据如何从一个生产者移动到一个消费者。")]),t._v(" "),a("p",[t._v("调度（Scheduling）属性（顺序或者并行），帮助我们定义生产者和消费者任务之间应该在什么时候进行调度。")]),t._v(" "),a("p",[t._v("数据源属性（持久的，可靠的或者暂时的），定义任务输出内容的生命周期或者持久性，让我们能够决定何时终止。")]),t._v(" "),a("p",[t._v("该模型所有的输入和输出都是可插拔的。为了方便，Tez使用了一个基于事件的模型，目的是为了让任务和系统之间、组件和组件之间能够通信。事件用于将信息（例如任务失败信息）传递给所需的组件，将输出的数据流（例如生成的数据位置信息）传送给输入，以及在运行时对DAG执行计划做出改变等。Tez还提供了各种开箱即用的输入和输出处理器。这些富有表现力的API能够让更高级语言（例如Hive）的编写者很优雅地将自己的查询转换成Tez任务。")]),t._v(" "),a("p",[t._v("TEZ技术：")]),t._v(" "),a("p",[t._v("Application Master Pool 初始化AM池。Tez先将作业提交到AMPoolServer服务上。AMPoolServer服务启动时就申请多个AM，Tez提交作业会优先使用缓冲池资源")]),t._v(" "),a("p",[t._v("Container Pool AM启动时会预先申请多个Container")]),t._v(" "),a("p",[t._v("Container重用")]),t._v(" "),a("p",[t._v("TEZ实现方法：")]),t._v(" "),a("p",[t._v("Tez对外提供了6种可编程组件，分别是：")]),t._v(" "),a("p",[t._v("Input：对输入数据源的抽象，它解析输入数据格式，并吐出一个个Key/value")]),t._v(" "),a("p",[t._v("Output：对输出数据源的抽象，它将用户程序产生的Key/value写入文件系统")]),t._v(" "),a("p",[t._v("Paritioner：对数据进行分片，类似于MR中的Partitioner")]),t._v(" "),a("p",[t._v("Processor：对计算的抽象，它从一个Input中获取数据，经处理后，通过Output输出")]),t._v(" "),a("p",[t._v("Task：对任务的抽象，每个Task由一个Input、Ouput和Processor组成")]),t._v(" "),a("p",[t._v("Maser ：管理各个Task的依赖关系，并按顺依赖关系执行他们")]),t._v(" "),a("p",[t._v("除了以上6种组件，Tez还提供了两种算子，分别是Sort（排序）和Shuffle（混洗），为了用户使用方便，它还提供了多种Input、Output、Task和Sort的实现")]),t._v(" "),a("h3",{attrs:{id:"dag"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dag"}},[t._v("#")]),t._v(" DAG")]),t._v(" "),a("p",[t._v("Edge：定义了上下游Vertex之间的连接方式。")]),t._v(" "),a("p",[t._v("Edge相关属性：")]),t._v(" "),a("ul",[a("li",[t._v("Data movement：定义了producer与consumer之间数据流动的方式。")]),t._v(" "),a("li",[t._v("One-To-One: 第i个producer产生的数据，发送给第i个consumer。这种上下游关系属于Spark的窄依赖。")]),t._v(" "),a("li",[t._v("Broadcast: producer产生的数据路由都下游所有consumer。这种上下游关系也属于Spark的窄依赖。")]),t._v(" "),a("li",[t._v("Scatter-Gather: producer将产生的数据分块，将第i块数据发送到第i个consumer。这种上下游关系属于Spark的宽依赖。")])]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192156170-1831208496.png"),alt:"wxmp"}}),t._v(" "),a("ul",[a("li",[a("p",[t._v("Scheduling：定义了何时启动consumer Task")])]),t._v(" "),a("li",[a("p",[t._v("Sequential: Consumer task 需要producer task结束后启动，如：MR。")])]),t._v(" "),a("li",[a("p",[t._v("Concurrent: Consumer task 与producer task一起启动，如：流计算。")])]),t._v(" "),a("li",[a("p",[t._v("Data source：定义了任务outp的生命周期与可靠性。")])]),t._v(" "),a("li",[a("p",[t._v("Persisted: 当任务退出后，该任务output依然存在，但经过一段时间后，可能会被删除，如：Mapper输出的中间结果。")])]),t._v(" "),a("li",[a("p",[t._v("Persisted-Reliable: 任务output总是存在，比如，MR中reducer的输出结果，存在HDFS上。")])]),t._v(" "),a("li",[a("p",[t._v("Ephemeral: 任务输出只有当该task在运行的时候，才存在，如：流计算的中间结果。")])])]),t._v(" "),a("p",[t._v("举例——MapReduce在Tez的编程模型")]),t._v(" "),a("p",[t._v("一个DAG图中只有两个Vertex，Map Vertex与Reduce Vertex。")]),t._v(" "),a("p",[t._v("连接Map Vertex与Reduce Vertex的Edge有以下属性：")]),t._v(" "),a("ul",[a("li",[t._v("Data movement：")]),t._v(" "),a("li",[t._v("Scatter-Gather Scheduling：")]),t._v(" "),a("li",[t._v("Sequential Data Source：")]),t._v(" "),a("li",[t._v("Map Vertex的Data Source为Persisted-Reliable，")]),t._v(" "),a("li",[t._v("reduce Vertex 的Data Source为Persisted")])]),t._v(" "),a("p",[t._v("Tez Api实现WordCount")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192238090-1799923852.png"),alt:"wxmp"}}),t._v(" "),a("h3",{attrs:{id:"runtime-api-input-processor-output"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#runtime-api-input-processor-output"}},[t._v("#")]),t._v(" Runtime API——Input/Processor/Output")]),t._v(" "),a("p",[t._v("Task是Tez的最小执行单元，Vertex中task的数量与该vertex的并行度一致。以下是Input、Processor、Output均需要实现的接口：")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("initialize")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tez")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Context")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("This")]),t._v(" is where "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("I")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("P")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("O")]),t._v(" receive their corresponding context "),a("span",{pre:!0,attrs:{class:"token class-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("objects"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v(" They")]),t._v(" can"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optionally"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" a list of events"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("handleEvents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" events"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" – "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Any")]),t._v(" events generated "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" the specific "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("I")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("P")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("O")]),t._v(" will be passed in via "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("interface"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v(" Inputs")]),t._v(" receive "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataMovementEvent")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" generated by corresponding "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Outputs")]),t._v(" on "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("interface")]),t._v(" – and will need "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("interpret")]),t._v(" them "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("retrieve")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v(" At")]),t._v(" the moment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),t._v(" can be ignored "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Outputs")]),t._v(" and "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Processors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\nList")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Event")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("close")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" – "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Any")]),t._v(" cleanup or "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" commits will typically be implemented in the close "),a("span",{pre:!0,attrs:{class:"token class-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("method"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v(" This")]),t._v(" is generally a good place "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Outputs")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("generate")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataMovementEvent")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("More")]),t._v(" on these events later"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),a("p",[t._v("Input: 接收上游Output事件，获取上游数据位置；从physical Edge中获取实际数据；解析实际数据，为Processor提供统一的逻辑试图；")]),t._v(" "),a("p",[t._v("Processor: 利用Input获取实际数据，执行用户逻辑，最后输出；")]),t._v(" "),a("p",[t._v("Output: 将Processor提供的数据，进行分区；向下游Input发送事件；")]),t._v(" "),a("p",[t._v("Tez的事件驱动机制: Tez中各个组件通过不同类型的Event进行通信。")]),t._v(" "),a("p",[t._v("数据传输：Output通过ShuffleEvent传递上游数据位置，AM负责将Event路由到相应Input中。")]),t._v(" "),a("p",[t._v("容错：Input当无法获取到上游数据时，会通知框架重新调度上游任务，这也意味着任务成功完成后，仍然会被重新调度。")]),t._v(" "),a("p",[t._v("runtime执行计划优化：根据上游Map Stage产生的数据大小，动态reducer并行度。Output产生的事件路由到可拔插的Vertex/Edge management module，对应moudule就可以对runtime执行计划进行调整。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192448245-2073898418.png"),alt:"wxmp"}}),t._v(" "),a("h3",{attrs:{id:"runtime优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#runtime优化"}},[t._v("#")]),t._v(" Runtime优化")]),t._v(" "),a("p",[t._v("任务运行时，程序知晓更多任务相关的信息，通过这些信息，我们可以动态修改修改执行计划，比如：修改mapper或reducer数量，决定何时启动reducer等。在Tez中，不同组件通过不同事件类型，进行通信。")]),t._v(" "),a("p",[t._v("动态修改reducer并行度：MapTask通过VertexManager类型的事件向ShuffleVertextManager发送信息，比如:所处理的partition大小等。 ShuffleVertexManager通过所获得的信息，可以估算出所有Task的输出数据大小，最后来调整下游reduce Vertex的并行度，如下图：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192555816-1361951048.png"),alt:"wxmp"}}),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192540602-2100980752.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v('reducer"慢"启动(预先启动)： 上游MapTask通过事件不断向ShuffleVertexManager汇报任务完成情况，ShuffleVertexManager通过这些信息，可以判断何时启动下游reduceTask与需要启动的reduceTask数量。')]),t._v(" "),a("h3",{attrs:{id:"从逻辑执行计划到物理执行计划"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#从逻辑执行计划到物理执行计划"}},[t._v("#")]),t._v(" 从逻辑执行计划到物理执行计划")]),t._v(" "),a("p",[t._v("从逻辑DAG到最后物理执行计划示意图：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192719786-30313954.png"),alt:"wxmp"}}),t._v(" "),a("h3",{attrs:{id:"其他优化措施"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#其他优化措施"}},[t._v("#")]),t._v(" 其他优化措施")]),t._v(" "),a("p",[t._v("Tez Session: 与数据库session相似，在同一个Tez Session中，可串行执行多个Tez Dag。Tez Session避免了AM的多次启动与销毁，在有多个DAG图的Tez作业（HQL任务）中大大减小了任务执行时间。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192803408-879683967.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("这也是为什么在Tez-UI中，一个HQL任务，只有一个Application，却有多个DAG(MR中一个HQL任务，有多个Application)。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192830332-601965228.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("Tez相关参数：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192901426-1437623504.png"),alt:"wxmp"}}),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192909369-1602973446.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("Container复用")]),t._v(" "),a("p",[t._v("问题：")]),t._v(" "),a("p",[t._v("container的资源兼容？ 被先后调度到同一个container的多个task所需要的资源，必须与container的资源相互兼容。也就是说，container拥有的资源，如：jar包，Memory，CPU等，需要是task所需资源的“超集”。")]),t._v(" "),a("p",[t._v("怎么调度？ 进行container复用时，Tez对Task进行调度。Tez会依据：任务本地性、任务所需资源、pending任务的优先级等因素，进行任务调度。")]),t._v(" "),a("p",[t._v("优点：")]),t._v(" "),a("p",[t._v("减少作业执行过程中JVM的创建与销毁带来的开销")]),t._v(" "),a("p",[t._v("减小对RM的请求压力")]),t._v(" "),a("p",[t._v("运行在同一container上task之间的数据共享。比如，MapJoin中可以通过共享小表数据的方式，减少资源消耗。")]),t._v(" "),a("p",[t._v("相关参数：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200718192949290-1135851389.png"),alt:"wxmp"}}),t._v(" "),a("h3",{attrs:{id:"tez优缺点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tez优缺点"}},[t._v("#")]),t._v(" Tez优缺点")]),t._v(" "),a("p",[t._v("优点：")]),t._v(" "),a("p",[t._v("避免中间数据写回HDFS，减小任务执行时间")]),t._v(" "),a("p",[t._v("vertex management模块使runtime动态修改执行计划变成可能")]),t._v(" "),a("p",[t._v("input/processor/output编程模型，大大提高了任务模型的灵活性")]),t._v(" "),a("p",[t._v("提供container复用机制与Tez Session，减少资源消耗")]),t._v(" "),a("p",[t._v("缺点：")]),t._v(" "),a("p",[t._v("出现数据重复问题等数据质量问题")]),t._v(" "),a("p",[t._v("Tez与Hive捆绑，在其他领域应用较少")]),t._v(" "),a("p",[t._v("社区不活跃")]),t._v(" "),a("h2",{attrs:{id:"tez安装过程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tez安装过程"}},[t._v("#")]),t._v(" Tez安装过程")]),t._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(".下载tez src解压，修改pom.xml, 将hadoop.version改为2.7.2，最好用非root用户编译\n\nmvn clean package -DskipTests"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("true -Dmaven.javadoc.skip"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("true\nGithub-refer：https://github.com/apache/tez\nDownload-refer：http://tez.apache.org/\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(".编译成功后，在tez-dist/target目录下，能够发现如下文件\narchive-tmp maven-archiver tez-0.8.4 tez-0.8.4-minimal tez-0.8.4-minimal.tar.gz tez-0.8.4.tar.gz tez-dist-0.8.4-tests.jar\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v(".将tez-0.8.4-minimal上传到hdfs上，本例中上传到/tez目录下 Hadoop fs –put tez-0.8.4-minimal.tar.gz /tez/\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),t._v(", 将tez-0.8.4-minimal.tar.gz考到/usr/hive下，并解压到./tez下\n\ntaz –zxvf tez-0.8.4-minimal.tar.gz –C ./tez\n拷贝tez的lib下或者主目录下jar包"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("》到hive主目录下lib中去\n\n"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v(".在客户端安装tez-0.8.4-minimal，并且在conf目录下建立tez-site.xml并正确配置\n\n")])])]),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[t._v(" "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("tez.lib.uris"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("${fs.defaultFS}/user/tez/tez-0.8.5-minimal.tar.gz"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("tez.use.cluster.hadoop-libs"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("true"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("6.在hive的客户端配置环境变量 (可以配置到/etc/profile.d/Hadoop.sh")]),t._v(" "),a("div",{staticClass:"language-ini extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ini"}},[a("code",[t._v("export TEZ_HOME"),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v("/usr/hive/tez")]),t._v("\n\nfor jar in `ls ${TEZ_HOME}|grep jar`;do\n  export HADOOP_CLASSPATH"),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v("${TEZ_HOME}/$jar:${HADOOP_CLASSPATH}")]),t._v("\ndone\nfor jar in `ls ${TEZ_HOME}/lib/|grep jar`;do\n export HADOOP_CLASSPATH"),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v("${TEZ_HOME}/lib/$jar:${HADOOP_CLASSPATH}")]),t._v("\ndone\n")])])]),a("p",[t._v("7.在hive-site.xml中配置参数。")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hive.user.install.directory"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("/user/"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v('\n     If hive (in tez mode only) cannot find a usable hive jar in "hive.jar.directory",\n     it will upload the hive jar to "hive.user.install.directory/user.name"\n     and use it to run queries.\n   '),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("hive.execution.engine"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("tez"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     Expects one of [mr, tez, spark].\n     Chooses execution engine. Options are: mr (Map reduce, default), tez,     spark.       While MR\n   remains the default engine for historical reasons, it is itself a historical engine\n   and is deprecated in Hive 2 line. It may be removed without further warning.\n   "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("property")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("8.hive启动后执行。")]),t._v(" "),a("div",{staticClass:"language-ini extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ini"}},[a("code",[t._v("set hive.execution.engine"),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),t._v("tez;  #即可运行hive on tez任务。")]),t._v("\n")])])]),a("p",[t._v("补充：hive2.x默认计算引擎为tez，编辑/usr/hive/conf/hive-site.xml")]),t._v(" "),a("h2",{attrs:{id:"tez实际使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tez实际使用"}},[t._v("#")]),t._v(" Tez实际使用")]),t._v(" "),a("p",[t._v("配置tez到hive中，安装过程省略。")]),t._v(" "),a("p",[t._v("准备数据：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" user_match_temp "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\nuser_name string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nopponent string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nresult "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\ncreate_time "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("timestamp")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),t._v(" format delimited "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fields")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("terminated")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("','")]),t._v("\nstored "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" textfile\nlocation "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/project/rhett/user_match_temp/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("执行查询：")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("CREATE")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TABLE")]),t._v(" user_match_temp "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\nuser_name string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nopponent string"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nresult "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\ncreate_time "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("timestamp")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),t._v(" format delimited "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fields")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("terminated")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("','")]),t._v("\nstored "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" textfile\nlocation "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/project/rhett/user_match_temp/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("在tez界面可以查看对应的任务所有的DAG都在这里：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200719111357919-1719621467.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("在上图可以查看到整个任务的执行调度情况。上图显示了执行结果，执行用户，执行语句，执行在yarn的applicationID还有队列。这里dag id也是惟一的id，点击dag name就会显示DAG的整个过程：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200719111842829-612844187.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("上图显示了 DAG的概述界面，运行进展，包含了2个Vertex，其中map vertex执行7个任务，reducer vertex执行2个任务，并且都是成功的，最下面是执行的完整sql语句。在最上面有一个下载的按钮，这个下载之后是一个zip的压缩包，压缩包主要是5个json文件，包含运行的任务的情况，dag的情况，task_attempts情况，tasks情况，vertex情况。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200719112627921-659764973.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("执行的DAG图形：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200719113509032-279509035.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("还可以查看所有的tez的所有任务：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/dp/tez/sum/1415006-20200719114956419-1039683615.png"),alt:"wxmp"}}),t._v(" "),a("h2",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),a("p",[t._v("感谢大神分享：")]),t._v(" "),a("p",[t._v("https://zhuanlan.zhihu.com/p/63315907")]),t._v(" "),a("p",[t._v("https://blog.csdn.net/hqwang4/article/details/78090087")]),t._v(" "),a("p",[t._v("https://cloud.tencent.com/developer/article/1625679")]),t._v(" "),a("p",[t._v("https://cwiki.apache.org/confluence/display/TEZ/How+initial+task+parallelism+works")]),t._v(" "),a("p",[t._v("https://www.jianshu.com/p/167ba0464a44")]),t._v(" "),a("h2",{attrs:{id:"参考文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[t._v("#")]),t._v(" 参考文章")]),t._v(" "),a("ul",[a("li",[t._v("https://www.cnblogs.com/boanxin/p/13336930.html")])])])}),[],!1,null,null,null);s.default=n.exports}}]);