(window.webpackJsonp=window.webpackJsonp||[]).push([[481],{996:function(s,a,t){"use strict";t.r(a);var e=t(53),r=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("本文主要是介绍 Hive-综合知识连载 ，主要包含 Hive 表类型，Hive数据抽样，Hive计算引擎。")])]),s._v(" "),t("p"),t("div",{staticClass:"table-of-contents"},[t("ul",[t("li",[t("a",{attrs:{href:"#hive-综合知识连载"}},[s._v("Hive-综合知识连载")])]),t("li",[t("a",{attrs:{href:"#大数据之hive-二-hive-表类型"}},[s._v("大数据之Hive（二）：Hive 表类型")]),t("ul",[t("li",[t("a",{attrs:{href:"#_2-1-hive-数据类型"}},[s._v("2.1 Hive 数据类型")])]),t("li",[t("a",{attrs:{href:"#_2-2-hive-内部表"}},[s._v("2.2 Hive 内部表")])]),t("li",[t("a",{attrs:{href:"#_2-3-hive-外部表"}},[s._v("2.3 Hive 外部表")])]),t("li",[t("a",{attrs:{href:"#_2-4-hive-分区表"}},[s._v("2.4 Hive 分区表")])]),t("li",[t("a",{attrs:{href:"#_2-5-hive-分桶表"}},[s._v("2.5 Hive 分桶表")])]),t("li",[t("a",{attrs:{href:"#_2-6-hive-视图"}},[s._v("2.6 Hive 视图")])])])]),t("li",[t("a",{attrs:{href:"#【-】"}},[s._v("【----------------------------】")])]),t("li",[t("a",{attrs:{href:"#大数据之hive-三-hive数据抽样"}},[s._v("大数据之Hive（三）：Hive数据抽样")]),t("ul",[t("li",[t("a",{attrs:{href:"#_3-1-随机抽样"}},[s._v("3.1 随机抽样")])]),t("li",[t("a",{attrs:{href:"#_3-2-块抽样"}},[s._v("3.2 块抽样")])]),t("li",[t("a",{attrs:{href:"#_3-3-桶表抽样"}},[s._v("3.3 桶表抽样")])])])]),t("li",[t("a",{attrs:{href:"#【-】"}},[s._v("【----------------------------】")])]),t("li",[t("a",{attrs:{href:"#大数据之hive-四-hive计算引擎"}},[s._v("大数据之Hive（四）：Hive计算引擎")]),t("ul",[t("li",[t("a",{attrs:{href:"#_4-1-mr计算引擎"}},[s._v("4.1 MR计算引擎")])]),t("li",[t("a",{attrs:{href:"#_4-2-tez计算引擎"}},[s._v("4.2 Tez计算引擎")])]),t("li",[t("a",{attrs:{href:"#_4-3-spark计算引擎"}},[s._v("4.3 Spark计算引擎")])])])]),t("li",[t("a",{attrs:{href:"#参考文章"}},[s._v("参考文章")])])])]),t("p"),s._v(" "),t("h2",{attrs:{id:"hive-综合知识连载"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hive-综合知识连载"}},[s._v("#")]),s._v(" Hive-综合知识连载")]),s._v(" "),t("h2",{attrs:{id:"大数据之hive-二-hive-表类型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据之hive-二-hive-表类型"}},[s._v("#")]),s._v(" 大数据之Hive（二）：Hive 表类型")]),s._v(" "),t("h3",{attrs:{id:"_2-1-hive-数据类型"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-hive-数据类型"}},[s._v("#")]),s._v(" 2.1 Hive 数据类型")]),s._v(" "),t("p",[s._v("Hive的基本数据类型有："),t("code",[s._v("TINYINT，SAMLLINT，INT，BIGINT，BOOLEAN，FLOAT，DOUBLE，STRING，TIMESTAMP(V0.8.0+)和BINARY(V0.8.0+)")]),s._v("。")]),s._v(" "),t("p",[s._v("Hive的集合类型有："),t("code",[s._v("STRUCT，MAP和ARRAY")]),s._v("。")]),s._v(" "),t("p",[s._v("Hive主要有四种数据模型(即表)：内部表、外部表、分区表和桶表。")]),s._v(" "),t("p",[s._v("表的元数据保存传统的数据库的表中，"),t("strong",[s._v("当前hive只支持Derby和MySQL数据库")]),s._v("。")]),s._v(" "),t("h3",{attrs:{id:"_2-2-hive-内部表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-hive-内部表"}},[s._v("#")]),s._v(" 2.2 Hive 内部表")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("Hive中的内部表和传统数据库中的表在概念上是类似的，Hive的每个表都有自己的存储目录，除了外部表外，所有的表数据都存放在配置在"),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("hive-site.xml"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("文件的"),t("span",{pre:!0,attrs:{class:"token variable"}},[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("$"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("hive.metastore.warehouse.dir"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("/table_name"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("目录下。\n")])])]),t("p",[s._v("创建内部表：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("IF")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXISTS")]),s._v(" students"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("user_no "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("name STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sex STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  \n         grade STRING COMMOT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'班级'")]),s._v("）COMMONT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'学生表'")]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ROW")]),s._v(" FORMAT DELIMITED \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FIELDS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TERMINATED")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("','")]),s._v("\nSTORE "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" TEXTFILE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("      \n")])])]),t("h3",{attrs:{id:"_2-3-hive-外部表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-hive-外部表"}},[s._v("#")]),s._v(" 2.3 Hive 外部表")]),s._v(" "),t("p",[s._v("被external修饰的为外部表（external table），外部表指向已经存在在Hadoop HDFS上的数据，除了在删除外部表时只删除元数据而不会删除表数据外，其他和内部表很像。")]),s._v(" "),t("p",[s._v("创建外部表：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" EXTERNAL "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("IF")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXISTS")]),s._v(" students"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("user_no "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("name STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sex STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  \n         class STRING COMMOT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'班级'")]),s._v("）COMMONT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'学生表'")]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ROW")]),s._v(" FORMAT DELIMITED  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FIELDS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TERMINATED")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("','")]),s._v("  \nSTORE "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" SEQUENCEFILE \nLOCATION "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/usr/test/data/students.txt'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("   \n")])])]),t("h3",{attrs:{id:"_2-4-hive-分区表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-hive-分区表"}},[s._v("#")]),s._v(" 2.4 Hive 分区表")]),s._v(" "),t("p",[s._v("分区表的每一个分区都对应数据库中相应分区列的一个索引，但是其组织方式和传统的关系型数据库不同。在Hive中，分区表的每一个分区都对应表下的一个目录，所有的分区的数据都存储在对应的目录中。")]),s._v(" "),t("p",[s._v("比如说，分区表partitinTable有包含nation(国家)、ds(日期)和city(城市)3个分区，其中nation = china，ds = 20130506，city = Shanghai则对应HDFS上的目录为：")]),s._v(" "),t("p",[t("code",[s._v("/datawarehouse/partitinTable/nation=china/city=Shanghai/ds=20130506/")]),s._v("。")]),s._v(" "),t("p",[t("strong",[s._v("分区中定义的变量名不能和表中的列相同")]),s._v("。")]),s._v(" "),t("p",[s._v("创建分区表：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("IF")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXISTS")]),s._v(" students"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("user_no "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("name STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sex STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n         class STRING COMMOT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'班级'")]),s._v("）COMMONT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'学生表'")]),s._v("  \nPARTITIONED "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ds STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("country STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ROW")]),s._v(" FORMAT DELIMITED  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FIELDS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TERMINATED")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("','")]),s._v("  \nSTORE "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" SEQUENCEFILE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("h3",{attrs:{id:"_2-5-hive-分桶表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-hive-分桶表"}},[s._v("#")]),s._v(" 2.5 Hive 分桶表")]),s._v(" "),t("p",[s._v("桶表就是对指定列进行哈希(hash)计算，然后会根据hash值进行切分数据，将具有不同hash值的数据写到每个桶对应的文件中。")]),s._v(" "),t("p",[s._v("将数据按照指定的字段进行分成多个桶中去，说白了就是将数据按照字段进行划分，可以将数据按照字段划分到"),t("strong",[s._v("多个文件")]),s._v("当中去。")]),s._v(" "),t("p",[s._v("创建分桶表：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("IF")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXISTS")]),s._v(" students"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("user_no "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("name STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sex STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  \n         class STRING COMMOT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'班级'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("score "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SMALLINT")]),s._v(" COMMOT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'总分'")]),s._v("）COMMONT "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'学生表'")]),s._v("  \nPARTITIONED "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ds STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("country STRING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CLUSTERED")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("user_no"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" SORTED "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("score"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),s._v(" BUCKETS  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ROW")]),s._v(" FORMAT DELIMITED  \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FIELDS")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TERMINATED")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("','")]),s._v("  \nSTORE "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" SEQUENCEFILE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("      \n")])])]),t("h3",{attrs:{id:"_2-6-hive-视图"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-hive-视图"}},[s._v("#")]),s._v(" 2.6 Hive 视图")]),s._v(" "),t("p",[s._v("在 Hive 中，视图是逻辑数据结构，可以通过隐藏复杂数据操作（Joins, 子查询, 过滤,数据扁平化）来于简化查询操作。")]),s._v(" "),t("p",[s._v("与关系数据库不同的是，Hive视图并不存储数据或者实例化。一旦创建 HIve 视图，它的 schema 也会立刻确定下来。对底层表后续的更改(如 增加新列)并不会影响视图的 schema。如果底层表被删除或者改变，之后对视图的查询将会 failed。基于以上 Hive view 的特性，我们在ETL和数据仓库中"),t("strong",[s._v("对于经常变化的表应慎重使用视图")]),s._v("。")]),s._v(" "),t("p",[s._v("创建视图：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VIEW")]),s._v(" employee_skills\n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" name"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" skills_score"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'DB'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" DB"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\nskills_score"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Perl'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" Perl"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \nskills_score"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Python'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" Python"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\nskills_score"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Sales'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" Sales"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \nskills_score"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'HR'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" HR \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" employee"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("创建视图的时候是不会触发 MapReduce 的 Job，因为只存在元数据的改变。")]),s._v(" "),t("p",[s._v("但是，当对视图进行查询的时候依然会触发一个 MapReduce Job 进程：SHOW CREATE TABLE 或者 DESC FORMATTED TABLE 语句来显示通过  CREATE VIEW  语句创建的视图。以下是对Hive 视图的 DDL操作：")]),s._v(" "),t("p",[s._v("更改视图的属性：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VIEW")]),s._v(" employee_skills \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SET")]),s._v(" TBLPROPERTIES "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'comment'")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'This is a view'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("重新定义视图：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VIEW")]),s._v(" employee_skills "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" employee "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])]),t("p",[s._v("删除视图：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DROP")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VIEW")]),s._v(" employee_skills"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("h2",{attrs:{id:"【-】"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#【-】"}},[s._v("#")]),s._v(" 【----------------------------】")]),s._v(" "),t("h2",{attrs:{id:"大数据之hive-三-hive数据抽样"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据之hive-三-hive数据抽样"}},[s._v("#")]),s._v(" 大数据之Hive（三）：Hive数据抽样")]),s._v(" "),t("p",[s._v("当数据规模不断膨胀时，我们需要找到一个数据的子集来加快数据分析效率。因此我们就需要通过筛选和分析数据集为了进行"),t("strong",[s._v("模式 & 趋势识别")]),s._v("。目前来说有三种方式来进行抽样：随机抽样，桶表抽样，和块抽样。")]),s._v(" "),t("h3",{attrs:{id:"_3-1-随机抽样"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-随机抽样"}},[s._v("#")]),s._v(" 3.1 随机抽样")]),s._v(" "),t("p",[s._v("关键词："),t("strong",[s._v("rand()函数")]),s._v("。")]),s._v(" "),t("p",[s._v("使用rand()函数进行随机抽样，limit关键字限制抽样返回的数据，其中rand函数前的distribute和sort关键字可以保证数据在mapper和reducer阶段是随机分布的。")]),s._v(" "),t("p",[s._v("案例如下：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" table_name \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" col"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xxx \ndistribute "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" sort "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" num"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("p",[s._v("使用order 关键词:")]),s._v(" "),t("p",[s._v("案例如下：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" table_name \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" col"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("xxx \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("order")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("limit")]),s._v(" num"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("p",[s._v("经测试对比，千万级数据中进行随机抽样 order by方式耗时更长，大约多30秒左右。")]),s._v(" "),t("h3",{attrs:{id:"_3-2-块抽样"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-块抽样"}},[s._v("#")]),s._v(" 3.2 块抽样")]),s._v(" "),t("p",[s._v("关键词："),t("strong",[s._v("tablesample()函数")]),s._v("。")]),s._v(" "),t("ol",[t("li",[s._v("tablesample(n percent) 根据hive表数据的大小按比例抽取数据，并保存到新的hive表中。如：抽取原hive表中10%的数据")])]),s._v(" "),t("blockquote",[t("p",[s._v("注意：测试过程中发现，select语句不能带where条件且不支持子查询，可通过新建中间表或使用随机抽样解决。")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" xxx tablesample"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("percent")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 数字与"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("percent")]),s._v("之间要有空格\n")])])]),t("ol",[t("li",[s._v("tablesample(nM) 指定抽样数据的大小，单位为M。")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" xxx tablesample"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v("M"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 数字与M之间不要有空格\n")])])]),t("ol",[t("li",[s._v("tablesample(n rows) 指定抽样数据的行数，其中n代表每个map任务均取n行数据，map数量可通过hive表的简单查询语句确认（关键词：number of mappers: x)")])]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" xxx tablesample"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 数字与"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("rows")]),s._v("之间要有空格\n")])])]),t("h3",{attrs:{id:"_3-3-桶表抽样"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-桶表抽样"}},[s._v("#")]),s._v(" 3.3 桶表抽样")]),s._v(" "),t("p",[s._v("关键词："),t("strong",[s._v("tablesample (bucket x out of y [on colname])")]),s._v("。")]),s._v(" "),t("p",[s._v("其中x是要抽样的桶编号，桶编号从1开始，colname表示抽样的列，y表示桶的数量。")]),s._v(" "),t("p",[s._v("hive中分桶其实就是根据某一个字段Hash取模，放入指定数据的桶中，比如将表table_1按照ID分成100个桶，其算法是hash(id) % 100，这样，hash(id) % 100 = 0的数据被放到第一个桶中，hash(id) % 100 = 1的记录被放到第二个桶中。创建分桶表的关键语句为：CLUSTER BY语句。")]),s._v(" "),t("p",[s._v("例如：将表随机分成10组，抽取其中的第一个桶的数据：")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" table_01 \ntablesample"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("bucket "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("out")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("of")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("on")]),s._v(" rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("h2",{attrs:{id:"【-】-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#【-】-2"}},[s._v("#")]),s._v(" 【----------------------------】")]),s._v(" "),t("h2",{attrs:{id:"大数据之hive-四-hive计算引擎"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#大数据之hive-四-hive计算引擎"}},[s._v("#")]),s._v(" 大数据之Hive（四）：Hive计算引擎")]),s._v(" "),t("p",[s._v("目前Hive支持MapReduce、Tez和Spark 三种计算引擎。")]),s._v(" "),t("h3",{attrs:{id:"_4-1-mr计算引擎"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-mr计算引擎"}},[s._v("#")]),s._v(" 4.1 MR计算引擎")]),s._v(" "),t("p",[s._v("MR运行的完整过程：")]),s._v(" "),t("p",[s._v("Map在读取数据时，先将数据拆分成若干数据，并读取到Map方法中被处理。数据在输出的时候，被分成若干分区并写入内存缓存（buffer）中，内存缓存被数据填充到一定程度会溢出到磁盘并排序，当Map执行完后会将一个机器上输出的临时文件进行归并存入到HDFS中。")]),s._v(" "),t("p",[s._v("当Reduce启动时，会启动一个线程去读取Map输出的数据，并写入到启动Reduce机器的内存中，在数据溢出到磁盘时会对数据进行再次排序。当读取数据完成后会将临时文件进行合并，作为Reduce函数的数据源。")]),s._v(" "),t("h3",{attrs:{id:"_4-2-tez计算引擎"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-tez计算引擎"}},[s._v("#")]),s._v(" 4.2 Tez计算引擎")]),s._v(" "),t("p",[s._v("Apache Tez是进行大规模数据处理且支持DAG作业的计算框架，它直接源于MapReduce框架，除了能够支持MapReduce特性，还支持新的作业形式，并允许不同类型的作业能够在一个集群中运行。")]),s._v(" "),t("p",[s._v("Tez将原有的Map和Reduce两个操作简化为一个概念——Vertex，并将原有的计算处理节点拆分成多个组成部分：Vertex Input、Vertex Output、Sorting、Shuffling和Merging。计算节点之间的数据通信被统称为Edge，这些分解后的元操作可以任意灵活组合，产生新的操作，这些操作经过一些控制程序组装后，可形成一个大的DAG作业。")]),s._v(" "),t("p",[s._v("通过允许Apache Hive运行复杂的DAG任务，Tez可以用来处理数据，之前需要多个MR jobs，现在一个Tez任务中。")]),s._v(" "),t("img",{staticClass:"zoom-custom-imgs",attrs:{src:s.$withBase("/assets/img/dw/hive/lianzai11-1.png"),alt:"wxmp"}}),s._v(" "),t("p",[t("strong",[s._v("Tez和MapReduce作业的比较")]),s._v("：")]),s._v(" "),t("ul",[t("li",[s._v("Tez绕过了MapReduce很多不必要的中间的数据存储和读取的过程，直接在一个作业中表达了MapReduce需要多个作业共同协作才能完成的事情。")]),s._v(" "),t("li",[s._v("Tez和MapReduce一样都运行使用YARN作为资源调度和管理。但与MapReduce on YARN不同，Tez on YARN并不是将作业提交到ResourceManager，而是提交到AMPoolServer的服务上，AMPoolServer存放着若干已经预先启动ApplicationMaster的服务。")]),s._v(" "),t("li",[s._v("当用户提交一个作业上来后，AMPoolServer从中选择一个ApplicationMaster用于管理用户提交上来的作业，这样既可以节省ResourceManager创建ApplicationMaster的时间，而又能够重用每个ApplicationMaster的资源，节省了资源释放和创建时间。")])]),s._v(" "),t("p",[t("strong",[s._v("Tez相比于MapReduce有几点重大改进")]),s._v("：")]),s._v(" "),t("ul",[t("li",[s._v("当查询需要有多个reduce逻辑时，Hive的MapReduce引擎会将计划分解，每个Redcue提交一个MR作业。这个链中的所有MR作业都需要逐个调度，每个作业都必须从HDFS中重新读取上一个作业的输出并重新洗牌。而在Tez中，几个reduce接收器可以直接连接，数据可以流水线传输，而不需要临时HDFS文件，这种模式称为MRR（Map-reduce-reduce*）。")]),s._v(" "),t("li",[s._v("Tez还允许一次发送整个查询计划，实现应用程序动态规划，从而使框架能够更智能地分配资源，并通过各个阶段流水线传输数据。对于更复杂的查询来说，这是一个巨大的改进，因为它消除了IO/sync障碍和各个阶段之间的调度开销。")]),s._v(" "),t("li",[s._v("在MapReduce计算引擎中，无论数据大小，在洗牌阶段都以相同的方式执行，将数据序列化到磁盘，再由下游的程序去拉取，并反序列化。Tez可以允许小数据集完全在内存中处理，而MapReduce中没有这样的优化。仓库查询经常需要在处理完大量的数据后对小型数据集进行排序或聚合，Tez的优化也能极大地提升效率。")])]),s._v(" "),t("h3",{attrs:{id:"_4-3-spark计算引擎"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-spark计算引擎"}},[s._v("#")]),s._v(" 4.3 Spark计算引擎")]),s._v(" "),t("p",[s._v("Apache Spark是专为大规模数据处理而设计的快速、通用支持DAG（有向无环图）作业的计算引擎，类似于Hadoop MapReduce的通用并行框架，可用来构建大型的、低延迟的数据分析应用程序。")]),s._v(" "),t("p",[s._v("Spark是用于"),t("strong",[s._v("大规模数据处理")]),s._v("的统一分析引擎，基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了"),t("strong",[s._v("高容错性")]),s._v("和"),t("strong",[s._v("高可伸缩性")]),s._v("，允许用户将Spark部署在大量硬件之上，形成集群。")]),s._v(" "),t("p",[t("strong",[s._v("Spark运行流程")])]),s._v(" "),t("img",{staticClass:"zoom-custom-imgs",attrs:{src:s.$withBase("/assets/img/dw/hive/lianzai11-2.png"),alt:"wxmp"}}),s._v(" "),t("p",[s._v("Spark运行流程")]),s._v(" "),t("p",[s._v("Spark具有以下几个特性。")]),s._v(" "),t("p",[s._v("1．"),t("strong",[s._v("高效性")])]),s._v(" "),t("p",[s._v("Spark会将作业构成一个DAG，优化了大型作业一些重复且浪费资源的操作，对查询进行了优化，重新编写了物理执行引擎，如可以实现MRR模式。")]),s._v(" "),t("p",[s._v("2．"),t("strong",[s._v("易用性")])]),s._v(" "),t("p",[s._v("Spark不同于MapReducer只提供两种简单的编程接口，它提供了多种编程接口去操作数据，这些操作接口如果使用MapReduce去实现，需要更多的代码。Spark的操作接口可以分为两类：transformation（转换）和action（执行）。Transformation包含map、flatmap、distinct、reduceByKey和join等转换操作；Action包含reduce、collect、count和first等操作。")]),s._v(" "),t("p",[s._v("3．"),t("strong",[s._v("通用性")])]),s._v(" "),t("p",[s._v("Spark针对实时计算、批处理、交互式查询，提供了统一的解决方案。但在批处理方面相比于MapReduce处理同样的数据，Spark所要求的硬件设施更高，MapReduce在相同的设备下所能处理的数据量会比Spark多。所以在实际工作中，Spark在批处理方面只能算是MapReduce的一种补充。")]),s._v(" "),t("p",[s._v("4．"),t("strong",[s._v("兼容性")])]),s._v(" "),t("p",[s._v("Spark和MapReduce一样有丰富的产品生态做支撑。例如Spark可以使用YARN作为资源管理器，Spark也可以处理Hbase和HDFS上的数据。")]),s._v(" "),t("h2",{attrs:{id:"参考文章"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[s._v("#")]),s._v(" 参考文章")]),s._v(" "),t("ul",[t("li",[s._v("https://blog.csdn.net/weixin_44291548/article/details/119764694")]),s._v(" "),t("li",[s._v("https://blog.csdn.net/weixin_44291548/article/details/119764765")]),s._v(" "),t("li",[s._v("https://blog.csdn.net/weixin_44291548/article/details/119764782")]),s._v(" "),t("li",[s._v("https://blog.csdn.net/weixin_44291548/article/details/119764835")])])])}),[],!1,null,null,null);a.default=r.exports}}]);