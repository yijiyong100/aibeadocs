(window.webpackJsonp=window.webpackJsonp||[]).push([[68],{584:function(t,s,a){"use strict";a.r(s);var n=a(53),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("本文主要是介绍 Python机器学习-逻辑回归分类 。")])]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#一、逻辑回归-二分类"}},[t._v("一、逻辑回归：二分类")]),a("ul",[a("li",[a("a",{attrs:{href:"#_1-1-理解逻辑回归"}},[t._v("1.1 理解逻辑回归")])]),a("li",[a("a",{attrs:{href:"#_1-2-代码实践-导入数据集"}},[t._v("1.2 代码实践 - 导入数据集")])]),a("li",[a("a",{attrs:{href:"#_1-3-观察数据"}},[t._v("1.3 观察数据")])]),a("li",[a("a",{attrs:{href:"#_1-4-训练模型"}},[t._v("1.4 训练模型")])])])]),a("li",[a("a",{attrs:{href:"#二、模型性能评估-准确率、精确度、召回率"}},[t._v("二、模型性能评估：准确率、精确度、召回率")])]),a("li",[a("a",{attrs:{href:"#三、softmax-多分类"}},[t._v("三、Softmax：多分类")]),a("ul",[a("li",[a("a",{attrs:{href:"#_3-1-理解softmax多元逻辑回归"}},[t._v("3.1 理解softmax多元逻辑回归")])]),a("li",[a("a",{attrs:{href:"#_3-2-代码实践-导入数据集"}},[t._v("3.2 代码实践 - 导入数据集")])]),a("li",[a("a",{attrs:{href:"#_3-3-观察数据"}},[t._v("3.3 观察数据")])]),a("li",[a("a",{attrs:{href:"#_3-4-训练模型"}},[t._v("3.4 训练模型")])]),a("li",[a("a",{attrs:{href:"#_3-5-拓展-绘制花瓣分类"}},[t._v("3.5 拓展：绘制花瓣分类")])])])]),a("li",[a("a",{attrs:{href:"#四、小结"}},[t._v("四、小结")]),a("ul",[a("li",[a("a",{attrs:{href:"#参考文章"}},[t._v("参考文章")])])])])])]),a("p"),t._v(" "),a("p",[t._v("说到，我们可以用线性回归做预测，但显然现实生活中不止有预测的问题还有分类的问题。我们可以从预测值的类型上简单区分："),a("strong",[t._v("连续变量的预测为回归，离散变量的预测为分类")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"一、逻辑回归-二分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、逻辑回归-二分类"}},[t._v("#")]),t._v(" 一、逻辑回归：二分类")]),t._v(" "),a("h3",{attrs:{id:"_1-1-理解逻辑回归"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-理解逻辑回归"}},[t._v("#")]),t._v(" 1.1 理解逻辑回归")]),t._v(" "),a("p",[t._v("我们把连续的预测值进行人工定义，边界的一边定义为1，另一边定义为0。这样我们就把回归问题转换成了分类问题。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-1.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("如上图，我们把连续的变量分布"),a("strong",[t._v("压制")]),t._v("在0-1的范围内，并以0.5作为我们分类决策的"),a("strong",[t._v("边界")]),t._v("，大于0.5的概率则判别为1，小于0.5的概率则判别为0。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-2.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("我们无法使用无穷大和负无穷大进行算术运算，我们通过逻辑回归函数（Sigmoid函数/S型函数/Logistic函数）可以讲数值计算限定在0-1之间。")]),t._v(" "),a("p",[t._v("σ(x)=11+e−xσ(x)=11+e−x")]),t._v(" "),a("p",[t._v("以上就是逻辑回归的简单解释。下面我们应用真实的数据案例来进行二分类代码实践。")]),t._v(" "),a("h3",{attrs:{id:"_1-2-代码实践-导入数据集"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-代码实践-导入数据集"}},[t._v("#")]),t._v(" 1.2 代码实践 - 导入数据集")]),t._v(" "),a("p",[t._v("添加引用：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" seaborn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" sns\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n")])])]),a("p",[t._v("导入数据集（大家不用在意这个域名）：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("df "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://blog.caiyongji.com/assets/hearing_test.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"right"}},[t._v("age")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("physical_score")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("test_result")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("33")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("40.7")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("50")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("37.2")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("52")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("24.7")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("56")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("31")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("35")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("42.9")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")])])])]),t._v(" "),a("p",[t._v("该数据集，对5000名参与者进行了一项实验，以研究年龄和身体健康对听力损失的影响，尤其是听高音的能力。此数据显示了研究结果对参与者进行了身体能力的评估和评分，然后必须进行音频测试（通过/不通过），以评估他们听到高频的能力。")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("特征")]),t._v("：1. 年龄 2. 健康得分")]),t._v(" "),a("li",[a("strong",[t._v("标签")]),t._v("：（1通过/0不通过）")])]),t._v(" "),a("h3",{attrs:{id:"_1-3-观察数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-观察数据"}},[t._v("#")]),t._v(" 1.3 观察数据")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatterplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'physical_score'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test_result'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们用"),a("code",[t._v("seaborn")]),t._v("绘制年龄和健康得分特征对应测试结果的散点图。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-3.png"),alt:"wxmp"}}),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pairplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test_result'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们通过"),a("code",[t._v("pairplot")]),t._v("方法绘制特征两两之间的对应关系。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-4.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("我们可以大致做出判断，当年龄超过60很难通过测试，通过测试者普遍健康得分超过30。")]),t._v(" "),a("h3",{attrs:{id:"_1-4-训练模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-4-训练模型"}},[t._v("#")]),t._v(" 1.4 训练模型")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_test_split\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("preprocessing "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StandardScaler\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LogisticRegression\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" accuracy_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("classification_report"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("plot_confusion_matrix\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#准备数据")]),t._v("\nX "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("drop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test_result'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test_result'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nX_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_test_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscaler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StandardScaler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscaled_X_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scaler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscaled_X_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scaler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#定义模型")]),t._v("\nlog_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#训练模型")]),t._v("\nlog_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scaled_X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#预测数据")]),t._v("\ny_pred "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" log_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scaled_X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\naccuracy_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们经过准备数据，定义模型为"),a("code",[t._v("LogisticRegression")]),t._v("逻辑回归模型，通过"),a("code",[t._v("fit")]),t._v("方法拟合训练数据，最后通过"),a("code",[t._v("predict")]),t._v("方法进行预测。\n最终我们调用"),a("code",[t._v("accuracy_score")]),t._v("方法得到模型的准确率为92.2%。")]),t._v(" "),a("h2",{attrs:{id:"二、模型性能评估-准确率、精确度、召回率"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、模型性能评估-准确率、精确度、召回率"}},[t._v("#")]),t._v(" 二、模型性能评估：准确率、精确度、召回率")]),t._v(" "),a("p",[t._v("我们是如何得到准确率是92.2%的呢？我们调用"),a("code",[t._v("plot_confusion_matrix")]),t._v("方法绘制混淆矩阵。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("plot_confusion_matrix"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("log_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("scaled_X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们观察500个测试实例，得到矩阵如下：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-5.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("我们对以上矩阵进行定义如下：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("真正类TP(True Positive)")]),t._v(" ：预测为正，实际结果为正。如，上图右下角285。")]),t._v(" "),a("li",[a("strong",[t._v("真负类TN(True Negative)")]),t._v(" ：预测为负，实际结果为负。如，上图左上角176。")]),t._v(" "),a("li",[a("strong",[t._v("假正类FP(False Positive)")]),t._v(" ：预测为正，实际结果为负。如，上图左下角19。")]),t._v(" "),a("li",[a("strong",[t._v("假负类FN(False Negative)")]),t._v(" ：预测为负，实际结果为正。如，上图右上角20。")])]),t._v(" "),a("p",[t._v("更多公式部分，可以请参见原文：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-x1.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("我们调用"),a("code",[t._v("classification_report")]),t._v("方法可验证结果。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("classification_report"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-6.png"),alt:"wxmp"}}),t._v(" "),a("h2",{attrs:{id:"三、softmax-多分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、softmax-多分类"}},[t._v("#")]),t._v(" 三、Softmax：多分类")]),t._v(" "),a("h3",{attrs:{id:"_3-1-理解softmax多元逻辑回归"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-理解softmax多元逻辑回归"}},[t._v("#")]),t._v(" 3.1 理解softmax多元逻辑回归")]),t._v(" "),a("p",[t._v("Logistic回归和Softmax回归都是基于线性回归的分类模型，两者无本质区别，都是从伯努利分结合最大对数似然估计。")]),t._v(" "),a("p",[a("strong",[t._v("最大似然估计")]),t._v("：简单来说，最大似然估计就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。")]),t._v(" "),a("p",[a("em",[t._v("术语“概率”(probability)和“似然”(likelihood)在英语中经常互换使用，但是它们在统计学中的含义却大不相同。给定具有一些参数θ的统计模型，用“概率”一词描述未来的结果x的合理性（知道参数值θ），而用“似然”一词表示描述在知道结果x之后，一组特定的参数值θ的合理性。")])]),t._v(" "),a("p",[t._v("Softmax回归模型首先计算出每个类的分数，然后对这些分数应用softmax函数，估计每个类的概率。我们预测具有最高估计概率的类，简单来说就是找得分最高的类。")]),t._v(" "),a("h3",{attrs:{id:"_3-2-代码实践-导入数据集"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-代码实践-导入数据集"}},[t._v("#")]),t._v(" 3.2 代码实践 - 导入数据集")]),t._v(" "),a("p",[t._v("导入数据集（大家不用在意这个域名）：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("df "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://blog.caiyongji.com/assets/iris.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"right"}},[t._v("sepal_length")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("sepal_width")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("petal_length")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("petal_width")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("species")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("5.1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3.5")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1.4")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0.2")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("setosa")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("4.9")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1.4")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0.2")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("setosa")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("4.7")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3.2")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1.3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0.2")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("setosa")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("4.6")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3.1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1.5")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0.2")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("setosa")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("5")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3.6")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1.4")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0.2")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("setosa")])])])]),t._v(" "),a("p",[t._v("该数据集，包含150个鸢尾花样本数据，数据特征包含花瓣的长度和宽度和萼片的长度和宽度，包含三个属种的鸢尾花，分别是山鸢尾(setosa)、变色鸢尾(versicolor)和维吉尼亚鸢尾(virginica)。")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("特征")]),t._v("：1. 花萼长度 2. 花萼宽度 3. 花瓣长度 4 花萼宽度")]),t._v(" "),a("li",[a("strong",[t._v("标签")]),t._v("：种类：山鸢尾(setosa)、变色鸢尾(versicolor)和维吉尼亚鸢尾(virginica)")])]),t._v(" "),a("h3",{attrs:{id:"_3-3-观察数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-观察数据"}},[t._v("#")]),t._v(" 3.3 观察数据")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatterplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sepal_length'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sepal_width'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们用"),a("code",[t._v("seaborn")]),t._v("绘制"),a("strong",[t._v("花萼")]),t._v("长度和宽度特征对应鸢尾花种类的散点图。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-7.png"),alt:"wxmp"}}),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatterplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'petal_length'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'petal_width'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们用"),a("code",[t._v("seaborn")]),t._v("绘制"),a("strong",[t._v("花瓣")]),t._v("长度和宽度特征对应鸢尾花种类的散点图。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-8.png"),alt:"wxmp"}}),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pairplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们通过"),a("code",[t._v("pairplot")]),t._v("方法绘制特征两两之间的对应关系。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-9.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("我们可以大致做出判断，综合考虑花瓣和花萼尺寸最小的为山鸢尾花，中等尺寸的为变色鸢尾花，尺寸最大的为维吉尼亚鸢尾花。")]),t._v(" "),a("h3",{attrs:{id:"_3-4-训练模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-训练模型"}},[t._v("#")]),t._v(" 3.4 训练模型")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#准备数据")]),t._v("\nX "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("drop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nX_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_test_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.25")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscaler "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StandardScaler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscaled_X_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scaler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscaled_X_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scaler"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#定义模型")]),t._v("\nsoftmax_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("multi_class"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"multinomial"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("solver"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lbfgs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#训练模型")]),t._v("\nsoftmax_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scaled_X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#预测数据")]),t._v("\ny_pred "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" softmax_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scaled_X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\naccuracy_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_pred"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们经过准备数据，定义模型"),a("code",[t._v("LogisticRegression")]),t._v("的"),a("code",[t._v('multi_class="multinomial"')]),t._v("多元逻辑回归模型，设置求解器为"),a("code",[t._v("lbfgs")]),t._v("，通过"),a("code",[t._v("fit")]),t._v("方法拟合训练数据，最后通过"),a("code",[t._v("predict")]),t._v("方法进行预测。")]),t._v(" "),a("p",[t._v("最终我们调用"),a("code",[t._v("accuracy_score")]),t._v("方法得到模型的准确率为92.1%。")]),t._v(" "),a("p",[t._v("我们调用"),a("code",[t._v("classification_report")]),t._v("方法查看准确率、精确度、召回率。")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("print(classification_report(y_test,y_pred))\n")])])]),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-10.png"),alt:"wxmp"}}),t._v(" "),a("h3",{attrs:{id:"_3-5-拓展-绘制花瓣分类"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-5-拓展-绘制花瓣分类"}},[t._v("#")]),t._v(" 3.5 拓展：绘制花瓣分类")]),t._v(" "),a("p",[t._v("我们仅提取花瓣长度和花瓣宽度的特征来绘制鸢尾花的分类图像。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#提取特征")]),t._v("\nX "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'petal_length'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'petal_width'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"species"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("factorize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'setosa'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'versicolor'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'virginica'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#定义模型")]),t._v("\nsoftmax_reg "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("multi_class"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"multinomial"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("solver"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"lbfgs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#训练模型")]),t._v("\nsoftmax_reg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#随机测试数据")]),t._v("\nx0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("meshgrid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linspace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linspace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nX_new "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("c_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("x0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ravel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ravel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#预测")]),t._v("\ny_proba "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" softmax_reg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict_proba"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_new"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny_predict "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" softmax_reg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_new"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#绘制图像")]),t._v("\nzz1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y_proba"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nzz "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y_predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("figsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"g^"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Iris virginica"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Iris versicolor"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"yo"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" label"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Iris setosa"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("colors "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ListedColormap\ncustom_cmap "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ListedColormap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#fafab0'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#9898ff'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#a0faa0'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contourf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" zz"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cmap"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("custom_cmap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncontour "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contour"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" zz1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cmap"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("plt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("brg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("clabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("contour"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inline"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fontsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xlabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Petal length"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fontsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ylabel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Petal width"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fontsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("legend"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loc"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"center left"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fontsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("14")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("axis"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("得到鸢尾花根据花瓣分类的图像如下：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/logisticregression-11.png"),alt:"wxmp"}}),t._v(" "),a("h2",{attrs:{id:"四、小结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四、小结"}},[t._v("#")]),t._v(" 四、小结")]),t._v(" "),a("p",[t._v("相比于概念的理解，本文更侧重上手实践，通过动手编程你应该有“手热”的感觉了。截至到本文，你应该对机器学习的概念有了一定的掌握，我们简单梳理一下：")]),t._v(" "),a("ul",[a("li",[a("ol",[a("li",[t._v("机器学习的分类")])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"2"}},[a("li",[t._v("机器学习的工业化流程")])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"3"}},[a("li",[t._v("特征、标签、实例、模型的概念")])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"4"}},[a("li",[t._v("过拟合、欠拟合")])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"5"}},[a("li",[t._v("损失函数、最小二乘法")])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"6"}},[a("li",[t._v("梯度下降、学习率 7.线性回归、逻辑回归、多项式回归、逐步回归、岭回归、套索(Lasso)回归、弹性网络(ElasticNet)回归是最常用的回归技术")])])]),t._v(" "),a("li",[a("ol",{attrs:{start:"7"}},[a("li",[t._v("Sigmoid函数、Softmax函数、最大似然估计")])])])]),t._v(" "),a("h3",{attrs:{id:"参考文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[t._v("#")]),t._v(" 参考文章")]),t._v(" "),a("ul",[a("li",[t._v("https://blog.caiyongji.com/2021/02/01/machine-learning-3.html")])])])}),[],!1,null,null,null);s.default=e.exports}}]);