(window.webpackJsonp=window.webpackJsonp||[]).push([[70],{586:function(t,s,a){"use strict";a.r(s);var e=a(53),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("本文主要是介绍 Python机器学习-决策树随机森林 。")])]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#机器学习-五-通俗易懂决策树与随机森林及代码实践"}},[t._v("机器学习(五)：通俗易懂决策树与随机森林及代码实践")])]),a("li",[a("a",{attrs:{href:"#一、决策树"}},[t._v("一、决策树")]),a("ul",[a("li",[a("a",{attrs:{href:"#_1-1-什么是决策树"}},[t._v("1.1 什么是决策树")])]),a("li",[a("a",{attrs:{href:"#_1-2-决策树代码实践"}},[t._v("1.2 决策树代码实践")])]),a("li",[a("a",{attrs:{href:"#_1-3-基尼不纯度"}},[t._v("1.3 基尼不纯度")])])])]),a("li",[a("a",{attrs:{href:"#二、随机森林"}},[t._v("二、随机森林")]),a("ul",[a("li",[a("a",{attrs:{href:"#_2-1-大数定理与随机森林"}},[t._v("2.1 大数定理与随机森林")])]),a("li",[a("a",{attrs:{href:"#_2-2-随机森林代码实践"}},[t._v("2.2 随机森林代码实践")])])])]),a("li",[a("a",{attrs:{href:"#总结"}},[t._v("总结")])]),a("li",[a("a",{attrs:{href:"#参考文章"}},[t._v("参考文章")])])])]),a("p"),t._v(" "),a("h2",{attrs:{id:"机器学习-五-通俗易懂决策树与随机森林及代码实践"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#机器学习-五-通俗易懂决策树与随机森林及代码实践"}},[t._v("#")]),t._v(" 机器学习(五)：通俗易懂决策树与随机森林及代码实践")]),t._v(" "),a("p",[t._v("与SVM一样，决策树是通用的机器学习算法。随机森林，顾名思义，将决策树分类器集成到一起就形成了更强大的机器学习算法。它们都是很基础但很强大的机器学习工具，虽然我们现在有更先进的算法工具来训练模型，但决策树与随机森林因其简单灵活依然广受喜爱，建议大家学习。")]),t._v(" "),a("h2",{attrs:{id:"一、决策树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、决策树"}},[t._v("#")]),t._v(" 一、决策树")]),t._v(" "),a("h3",{attrs:{id:"_1-1-什么是决策树"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-什么是决策树"}},[t._v("#")]),t._v(" 1.1 什么是决策树")]),t._v(" "),a("p",[t._v("我们可以把决策树想象成IF/ELSE判别式深度嵌套的二叉树形结构。以我们在"),a("a",{attrs:{href:"https://mp.weixin.qq.com/s/cEbGM0_Lrt8elfubxSF9jg",target:"_blank",rel:"noopener noreferrer"}},[t._v("《机器学习(三)：理解逻辑回归及二分类、多分类代码实践》"),a("OutboundLink")],1),t._v("所举的鸢尾花数据集为例。")]),t._v(" "),a("p",[t._v("我们曾用"),a("code",[t._v("seaborn")]),t._v("绘制花瓣长度和宽度特征对应鸢尾花种类的散点图，如下：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/decisiontreecase-1.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("当花瓣长度小于2.45则为山鸢尾(setosa)，剩下的我们判断花瓣宽度小于1.75则为变色鸢尾(versicolor)剩下的为维吉尼亚鸢尾(virginica)。那么我用导图画一下这种判别式的树形结构如下：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/decisiontreecase-2.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("因此，当我们面对任意鸢尾花的样本，我们只需要"),a("strong",[t._v("从根节点到叶子节点遍历决策树")]),t._v("，就可以得到鸢尾花的分类结论。")]),t._v(" "),a("p",[t._v("这就是决策树。")]),t._v(" "),a("h3",{attrs:{id:"_1-2-决策树代码实践"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-决策树代码实践"}},[t._v("#")]),t._v(" 1.2 决策树代码实践")]),t._v(" "),a("p",[t._v("我们导入数据集（大家不用在意这个域名），并训练模型：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tree "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" DecisionTreeClassifier\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#引入数据集")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://blog.caiyongji.com/assets/iris.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#决策树模型")]),t._v("\nX "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'petal_length'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'petal_width'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_numpy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\ntree_clf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DecisionTreeClassifier"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("max_depth"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("42")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntree_clf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们来可视化决策树：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tree "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" plot_tree\nplt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("figure"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("figsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplot_tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tree_clf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("filled"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/decisiontreecase-3.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("如上图，我们可以看到根节点总实例数为150时，由"),a("code",[t._v("value = [50, 50, 50]")]),t._v("可知，实际样本分类为50个山鸢尾花实例、50个变色鸢尾花实例、50个维吉尼亚鸢尾花实例。我们再看最末尾右侧的叶子节点（紫色），由"),a("code",[t._v("value = [0, 1, 45]")]),t._v("可知，实际样本分类为0个山鸢尾花实例、1个变色鸢尾花实例、45个维吉尼亚鸢尾花实例。")]),t._v(" "),a("p",[t._v("那么gini = 0.043是什么意思呢？")]),t._v(" "),a("h3",{attrs:{id:"_1-3-基尼不纯度"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-3-基尼不纯度"}},[t._v("#")]),t._v(" 1.3 基尼不纯度")]),t._v(" "),a("p",[t._v("显然我们进行分类时，每一个类别实际混入其他类的数量越少分类就越"),a("strong",[t._v("纯粹")]),t._v("，这种纯度我们通过如下公式表示：")]),t._v(" "),a("p",[t._v("更多公式部分，可以请参见原文：")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/decisiontreecase-x1.png"),alt:"wxmp"}}),t._v(" "),a("p",[t._v("我们计算维吉尼亚鸢尾花节点（紫色）的gini系数"),a("code",[t._v("1-((0/46)**2 + (1/46)**2 + (45/46)**2) = 0.04253308128544431 ≈0.043")]),t._v(" 。")]),t._v(" "),a("p",[t._v("我们使用基尼(gini)不纯度来衡量决策树的好坏。那么我们通过最小化基尼不纯度min(gini)来求解X[0],X[1]（即，花瓣长度宽度特征）边界的过程就决策树模型的训练过程。")]),t._v(" "),a("h2",{attrs:{id:"二、随机森林"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、随机森林"}},[t._v("#")]),t._v(" 二、随机森林")]),t._v(" "),a("h3",{attrs:{id:"_2-1-大数定理与随机森林"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-大数定理与随机森林"}},[t._v("#")]),t._v(" 2.1 大数定理与随机森林")]),t._v(" "),a("p",[t._v("其实随机森林很简单，我们把决策树随机组合在一起就是随机森林，它比单个的决策树更有效。")]),t._v(" "),a("p",[t._v("凭什么？")]),t._v(" "),a("p",[t._v("假设我们有一枚不均匀的硬币，投掷它有51%的概率为正面，49%的概率为背面，那么当投掷1000次时，“大多数为正面”这件事的概率为75%。投掷10000次时，“大多数为正面”这件事的概率为97%。这就是大数定理，它体现的是群体智慧。"),a("em",[t._v("质量不够，数量来凑")]),t._v("。由此可知，当前寻找最佳模型的方法不止是技巧的比拼，也同样是算力的比拼。")]),t._v(" "),a("h3",{attrs:{id:"_2-2-随机森林代码实践"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-随机森林代码实践"}},[t._v("#")]),t._v(" 2.2 随机森林代码实践")]),t._v(" "),a("h4",{attrs:{id:"_2-2-1-引入新的数据集"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-1-引入新的数据集"}},[t._v("#")]),t._v(" 2.2.1. 引入新的数据集")]),t._v(" "),a("p",[t._v("添加引用：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" seaborn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" sns\n")])])]),a("p",[t._v("导入数据集（大家不用在意这个域名）：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("df "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://blog.caiyongji.com/assets/penguins_size.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("species")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("island")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("culmen_length_mm")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("culmen_depth_mm")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("flipper_length_mm")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("body_mass_g")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("sex")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("Adelie")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Torgersen")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("39.1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("18.7")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("181")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3750")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("MALE")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("Adelie")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Torgersen")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("39.5")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("17.4")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("186")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3800")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("FEMALE")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("Adelie")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Torgersen")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("40.3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("18")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("195")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3250")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("FEMALE")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("Adelie")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Torgersen")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("36.7")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("19.3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("193")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3450")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("FEMALE")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("Adelie")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("Torgersen")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("39.3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("20.6")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("190")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3650")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("MALE")])])])]),t._v(" "),a("p",[t._v("企鹅数据集包含特征和标签如下：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("特征")]),t._v("：所在岛屿island、鸟喙长度culmen_length_mm、鸟喙深度culmen_depth_mm、脚蹼长度flipper_length_mm、体重(g)、性别")]),t._v(" "),a("li",[a("strong",[t._v("标签")]),t._v("：物种species：Chinstrap, Adélie, or Gentoo")])]),t._v(" "),a("h4",{attrs:{id:"_2-2-2-观察数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-2-观察数据"}},[t._v("#")]),t._v(" 2.2.2 观察数据")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pairplot"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hue"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们通过pairplot方法绘制特征两两之间的对应关系。")]),t._v(" "),a("img",{staticClass:"zoom-custom-imgs",attrs:{src:t.$withBase("/assets/img/ad/pymlcase/decisiontreecase-4.png"),alt:"wxmp"}}),t._v(" "),a("h4",{attrs:{id:"_2-2-3-预处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-3-预处理"}},[t._v("#")]),t._v(" 2.2.3 预处理")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("X "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_dummies"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("drop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("drop_first"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'species'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nX"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("head"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("注意，"),a("code",[t._v("get_dummies")]),t._v("方法将字符串属性的列转换成了数字属性的多个列。如，岛屿island和性别sex分别转换成了island_Dream、island_Torgersen和sex_FEMALE、sex_MALE。这是一种独热编码的关系，比如sex_FEMALE与sex_MALE属性独立，在空间内没有向量关系。")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"right"}},[t._v("culmen_length_mm")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("culmen_depth_mm")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("flipper_length_mm")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("body_mass_g")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("island_Dream")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("island_Torgersen")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("sex_FEMALE")]),t._v(" "),a("th",{staticStyle:{"text-align":"right"}},[t._v("sex_MALE")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("39.1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("18.7")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("181")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3750")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("39.5")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("17.4")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("186")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3800")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("40.3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("18")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("195")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3250")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("36.7")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("19.3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("193")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3450")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"right"}},[t._v("39.3")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("20.6")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("190")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("3650")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("0")]),t._v(" "),a("td",{staticStyle:{"text-align":"right"}},[t._v("1")])])])]),t._v(" "),a("h4",{attrs:{id:"_2-2-4-训练数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-4-训练数据"}},[t._v("#")]),t._v(" 2.2.4 训练数据")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#训练")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_test_split\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ensemble "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RandomForestClassifier\nX_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_test_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RandomForestClassifier"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n_estimators"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("max_features"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'auto'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#预测")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" accuracy_score\npreds "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\naccuracy_score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("preds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("使用随机森林分类器"),a("code",[t._v("RandomForestClassifier")]),t._v("训练，得到模型精度为97%。")]),t._v(" "),a("h4",{attrs:{id:"_2-2-5-网格搜索与adaboost提升法-拓展"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-5-网格搜索与adaboost提升法-拓展"}},[t._v("#")]),t._v(" 2.2.5 网格搜索与AdaBoost提升法（拓展）")]),t._v(" "),a("p",[t._v("我们使用"),a("code",[t._v("AdaBoostClassifier")]),t._v("分类器集成数个决策树分类器"),a("code",[t._v("DecisionTreeClassifier")]),t._v("进行分类。并使用网格搜索方法"),a("code",[t._v("GridSearchCV")]),t._v("来寻找最优参数。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" GridSearchCV\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ensemble "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AdaBoostClassifier\n\nada_clf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AdaBoostClassifier"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("DecisionTreeClassifier"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("max_depth"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" random_state"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nada_clf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nparam_grid "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'n_estimators'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("25")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("35")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("40")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'learning_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'algorithm'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'SAMME'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'SAMME.R'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\ngrid "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" GridSearchCV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ada_clf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("param_grid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngrid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"grid.best_params_ = "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("grid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("best_params_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('", grid.best_score_ ="')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("grid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("best_score_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("这是一种集成学习技术，输出如下：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("grid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("best_params_ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'algorithm'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'SAMME'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'learning_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'n_estimators'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" grid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("best_score_ "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.9914893617021276")]),t._v("\n")])])]),a("h2",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),a("p",[t._v("二叉树是决策树的核心逻辑，随机森林是大数定理的应用实现。这种基本思想即使不用数学公式也可以很容易的解释清楚，这也是我做这个系列课程（文章）的主要风格特点。我认为，数学是对现实世界的解释，但现实世界并不能被数学"),a("strong",[t._v("完全解释")]),t._v("。像谷歌AI主管Laurence Moroney所说：")]),t._v(" "),a("p",[t._v("很多人害怕数学，害怕大量的深度的微积分知识。其实我们可以实现编码而不考虑数学，我们可以使用TensorFlow中高(层)级的API，来解决问题，如自然语言处理，图像分类，计算机视觉序列模型等而无需理解深刻的数学。就像你使用JAVA却不一定非要掌握它是如何编译的。未来，AI只是每个开发者技术栈(toolbox)中的一部分，就像HTML, CSS, JAVA。")]),t._v(" "),a("p",[t._v("希望那一天可以早点到来吧……")]),t._v(" "),a("h2",{attrs:{id:"参考文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[t._v("#")]),t._v(" 参考文章")]),t._v(" "),a("ul",[a("li",[t._v("https://blog.caiyongji.com/2021/02/25/machine-learning-5.html")])])])}),[],!1,null,null,null);s.default=n.exports}}]);