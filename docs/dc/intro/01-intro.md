---
title: 数据采集-常用工具介绍
---

::: tip
本文主要是介绍 数据采集-常用工具 。
:::

[[toc]]


## (一) kettle

说明：是国外开源ETL工具，支持数据库、FTP、文件、rest接口、hdfs、hive等平台的灵敏据进行抽取、转换、传输等操作，Java编写跨平台，C/S架构，不支持浏览器模式。

### 特点：

易用性：有可视化设计器进行可视化操作，使用简单。

功能强大：不仅能进行数据传输，能同时进行数据清洗转换等操作。

支持多种源：支持各种数据库、FTP、文件、rest接口、hdfs、Hive等源。

部署方便：独立部署，不依赖第三方产品。

### 适用场景：

数据量及增量不大，业务规则变化较快，要求可视化操作，对技术人员的技术门槛要求低。

## (二) sqoop

说明：Apache开源软件，主要用于在HADOOP(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递。

### 特点：

数据吞吐量大：依赖hadoop集群可进行大批量数据集成。

操作有技术要求：sqoop操作没有可视化设计器，对使用人员有较专业的技术要求。

多种交互方式：命令行，web UI，rest API。

部署不方便：sqoop依赖大数据集群，使用sqoop要求数据传输的的源要与大数据集群的所有节点能进行通信。

### 适用场景：

适用于能与大数据集群直接通信的关系数据库间的大批量数据传输。

## (三) dataX

说明：是阿里开源软件异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。

### 特点：

易用性：没有界面，以执行脚本方式运行，对使用人员技术要求较高。

性能：数据抽取性能高。

部署：可独立部署

### 适用场景：

在异构数据库/文件系统之间高速交换数据。

## (四) flume

说明：flume是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的系统。

### 特点：

分布式：flume分布式集群部署，扩展性好。

可靠性好: 当节点出现故障时，日志能够被传送到其他节点上而不会丢失。

易用性：flume配置使用较繁琐，对使用人员专业技术要求非常高。

实时采集：flume采集流模式进行数据实时采集。

### 适用场景：

适用于日志文件实时采集。


## (五)Logstash 简介


其实 Logstash 的作用就是一个数据收集器，将各种格式各种渠道的数据通过它收集解析之后格式化输出到 Elasticsearch ，最后再由 Kibana 提供的比较友好的 Web 界面进行汇总、分析、搜索。


## 参考文章
* https://blog.csdn.net/weixin_39824898/article/details/112474940